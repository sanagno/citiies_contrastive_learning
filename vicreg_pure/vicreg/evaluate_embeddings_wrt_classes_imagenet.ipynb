{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34444cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from geopy.geocoders import Nominatim\n",
    "import re\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sklearn\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import math\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb4d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import signal\n",
    "import sys\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import resnet\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "\n",
    "import glob\n",
    "from geopy.geocoders import Nominatim\n",
    "import re\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import math\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True   #OTHERWISE TRUNCATED IMAGE FILE ERROR SOMEWHERE IN ENUMERATE(DATALOADER)!!!!\n",
    "\n",
    "import resnet\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from munkres import Munkres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37120c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_preds(cluster_assignments, y_true, n_clusters):\n",
    "    '''\n",
    "    Computes the predicted labels, where label assignments now\n",
    "    correspond to the actual labels in y_true (as estimated by Munkres)\n",
    "\n",
    "    cluster_assignments:    array of labels, outputted by kmeans\n",
    "    y_true:                 true labels\n",
    "    n_clusters:             number of clusters in the dataset\n",
    "\n",
    "    returns:    a tuple containing the accuracy and confusion matrix,\n",
    "                in that order\n",
    "    '''\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_true, cluster_assignments, labels=None)\n",
    "    # compute accuracy based on optimal 1:1 assignment of clusters to labels\n",
    "    cost_matrix = calculate_cost_matrix(confusion_matrix, n_clusters)\n",
    "    indices = Munkres().compute(cost_matrix)\n",
    "    kmeans_to_true_cluster_labels = get_cluster_labels_from_indices(indices)\n",
    "    y_pred = kmeans_to_true_cluster_labels[cluster_assignments]\n",
    "    return y_pred, confusion_matrix \n",
    "\n",
    "def calculate_cost_matrix(C, n_clusters):\n",
    "    cost_matrix = np.zeros((n_clusters, n_clusters))\n",
    "\n",
    "    # cost_matrix[i,j] will be the cost of assigning cluster i to label j\n",
    "    for j in range(n_clusters):\n",
    "        s = np.sum(C[:,j]) # number of examples in cluster i\n",
    "        for i in range(n_clusters):\n",
    "            t = C[i,j]\n",
    "            cost_matrix[j,i] = s-t\n",
    "    return cost_matrix\n",
    "\n",
    "def get_cluster_labels_from_indices(indices):\n",
    "    n_clusters = len(indices)\n",
    "    clusterLabels = np.zeros(n_clusters)\n",
    "    for i in range(n_clusters):\n",
    "        clusterLabels[i] = indices[i][1]\n",
    "    return clusterLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4290e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee23f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transforms = torchvision.transforms.Compose([torchvision.transforms.RandomResizedCrop(224), torchvision.transforms.RandomHorizontalFlip(), torchvision.transforms.ToTensor(),normalize])\n",
    "\n",
    "dataset = datasets.ImageFolder('./ImageNet/ILSVRC/Data/CLS-LOC/val' , transforms)\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset, batch_size = batch_size, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ba3e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12268863488, 12806062080)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.current_device()\n",
    "torch.cuda.set_device(3)\n",
    "print(torch.cuda.mem_get_info(torch.cuda.current_device()))\n",
    "device = torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e44f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_model_pretrained = torchvision.models.resnet50(pretrained=True)\n",
    "torch.save(supervised_model_pretrained.state_dict(), 'resnet50_imagenet_pretrained_supervised.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fba5a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone, embedding = resnet.__dict__['resnet50'](zero_init_residual=True)\n",
    "state_dict = torch.load('resnet50_imagenet_pretrained_supervised.pth', map_location=\"cpu\")\n",
    "if \"model\" in state_dict:\n",
    "    state_dict = state_dict[\"model\"]\n",
    "    state_dict = {key.replace(\"module.backbone.\", \"\"): value for (key, value) in state_dict.items()}\n",
    "backbone.load_state_dict(state_dict, strict=False)\n",
    "backbone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7052870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding)\n",
    "backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f1c147a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n",
      "22000\n",
      "22500\n",
      "23000\n",
      "23500\n",
      "24000\n",
      "24500\n",
      "25000\n",
      "25500\n",
      "26000\n",
      "26500\n",
      "27000\n",
      "27500\n",
      "28000\n",
      "28500\n",
      "29000\n",
      "29500\n",
      "30000\n",
      "30500\n",
      "31000\n",
      "31500\n",
      "32000\n",
      "32500\n",
      "33000\n",
      "33500\n",
      "34000\n",
      "34500\n",
      "35000\n",
      "35500\n",
      "36000\n",
      "36500\n",
      "37000\n",
      "37500\n",
      "38000\n",
      "38500\n",
      "39000\n",
      "39500\n",
      "40000\n",
      "40500\n",
      "41000\n",
      "41500\n",
      "42000\n",
      "42500\n",
      "43000\n",
      "43500\n",
      "44000\n",
      "44500\n",
      "45000\n",
      "45500\n",
      "46000\n",
      "46500\n",
      "47000\n",
      "47500\n",
      "48000\n",
      "48500\n",
      "49000\n",
      "49500\n"
     ]
    }
   ],
   "source": [
    "labels_list = []\n",
    "embeddings_list = []\n",
    "\n",
    "labels_unseen_list = []\n",
    "embeddings_unseen_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        \n",
    "        if i == 50000:\n",
    "            break\n",
    "            \n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        if i%4 == 0:\n",
    "            \n",
    "            embedding = backbone(inputs.to(device))\n",
    "            embeddings_unseen_list.append(embedding)\n",
    "            labels_unseen_list.append(labels)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            embedding = backbone(inputs.to(device))\n",
    "            embeddings_list.append(embedding)\n",
    "            labels_list.append(labels)\n",
    "            \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d3c59ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14875932 0.40740678 0.24900784 ... 0.42377618 0.62659913 0.26762429]\n",
      " [0.15100792 0.57644802 0.06908274 ... 0.32252085 1.0731976  0.4173148 ]\n",
      " [0.14548095 0.86708254 0.20886353 ... 0.20139341 1.05986702 0.19876178]\n",
      " ...\n",
      " [0.08778701 0.33687139 1.03078735 ... 0.24490468 0.23621872 0.15081446]\n",
      " [0.24522467 0.36625695 0.32675669 ... 0.25291982 0.05003487 0.1373997 ]\n",
      " [0.26443723 0.60494483 1.97403979 ... 0.34973338 0.31702667 0.34852833]]\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "  84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n",
      " 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n",
      " 126. 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139.\n",
      " 140. 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153.\n",
      " 154. 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167.\n",
      " 168. 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181.\n",
      " 182. 183. 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195.\n",
      " 196. 197. 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209.\n",
      " 210. 211. 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223.\n",
      " 224. 225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237.\n",
      " 238. 239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251.\n",
      " 252. 253. 254. 255. 256. 257. 258. 259. 260. 261. 262. 263. 264. 265.\n",
      " 266. 267. 268. 269. 270. 271. 272. 273. 274. 275. 276. 277. 278. 279.\n",
      " 280. 281. 282. 283. 284. 285. 286. 287. 288. 289. 290. 291. 292. 293.\n",
      " 294. 295. 296. 297. 298. 299. 300. 301. 302. 303. 304. 305. 306. 307.\n",
      " 308. 309. 310. 311. 312. 313. 314. 315. 316. 317. 318. 319. 320. 321.\n",
      " 322. 323. 324. 325. 326. 327. 328. 329. 330. 331. 332. 333. 334. 335.\n",
      " 336. 337. 338. 339. 340. 341. 342. 343. 344. 345. 346. 347. 348. 349.\n",
      " 350. 351. 352. 353. 354. 355. 356. 357. 358. 359. 360. 361. 362. 363.\n",
      " 364. 365. 366. 367. 368. 369. 370. 371. 372. 373. 374. 375. 376. 377.\n",
      " 378. 379. 380. 381. 382. 383. 384. 385. 386. 387. 388. 389. 390. 391.\n",
      " 392. 393. 394. 395. 396. 397. 398. 399. 400. 401. 402. 403. 404. 405.\n",
      " 406. 407. 408. 409. 410. 411. 412. 413. 414. 415. 416. 417. 418. 419.\n",
      " 420. 421. 422. 423. 424. 425. 426. 427. 428. 429. 430. 431. 432. 433.\n",
      " 434. 435. 436. 437. 438. 439. 440. 441. 442. 443. 444. 445. 446. 447.\n",
      " 448. 449. 450. 451. 452. 453. 454. 455. 456. 457. 458. 459. 460. 461.\n",
      " 462. 463. 464. 465. 466. 467. 468. 469. 470. 471. 472. 473. 474. 475.\n",
      " 476. 477. 478. 479. 480. 481. 482. 483. 484. 485. 486. 487. 488. 489.\n",
      " 490. 491. 492. 493. 494. 495. 496. 497. 498. 499. 500. 501. 502. 503.\n",
      " 504. 505. 506. 507. 508. 509. 510. 511. 512. 513. 514. 515. 516. 517.\n",
      " 518. 519. 520. 521. 522. 523. 524. 525. 526. 527. 528. 529. 530. 531.\n",
      " 532. 533. 534. 535. 536. 537. 538. 539. 540. 541. 542. 543. 544. 545.\n",
      " 546. 547. 548. 549. 550. 551. 552. 553. 554. 555. 556. 557. 558. 559.\n",
      " 560. 561. 562. 563. 564. 565. 566. 567. 568. 569. 570. 571. 572. 573.\n",
      " 574. 575. 576. 577. 578. 579. 580. 581. 582. 583. 584. 585. 586. 587.\n",
      " 588. 589. 590. 591. 592. 593. 594. 595. 596. 597. 598. 599. 600. 601.\n",
      " 602. 603. 604. 605. 606. 607. 608. 609. 610. 611. 612. 613. 614. 615.\n",
      " 616. 617. 618. 619. 620. 621. 622. 623. 624. 625. 626. 627. 628. 629.\n",
      " 630. 631. 632. 633. 634. 635. 636. 637. 638. 639. 640. 641. 642. 643.\n",
      " 644. 645. 646. 647. 648. 649. 650. 651. 652. 653. 654. 655. 656. 657.\n",
      " 658. 659. 660. 661. 662. 663. 664. 665. 666. 667. 668. 669. 670. 671.\n",
      " 672. 673. 674. 675. 676. 677. 678. 679. 680. 681. 682. 683. 684. 685.\n",
      " 686. 687. 688. 689. 690. 691. 692. 693. 694. 695. 696. 697. 698. 699.\n",
      " 700. 701. 702. 703. 704. 705. 706. 707. 708. 709. 710. 711. 712. 713.\n",
      " 714. 715. 716. 717. 718. 719. 720. 721. 722. 723. 724. 725. 726. 727.\n",
      " 728. 729. 730. 731. 732. 733. 734. 735. 736. 737. 738. 739. 740. 741.\n",
      " 742. 743. 744. 745. 746. 747. 748. 749. 750. 751. 752. 753. 754. 755.\n",
      " 756. 757. 758. 759. 760. 761. 762. 763. 764. 765. 766. 767. 768. 769.\n",
      " 770. 771. 772. 773. 774. 775. 776. 777. 778. 779. 780. 781. 782. 783.\n",
      " 784. 785. 786. 787. 788. 789. 790. 791. 792. 793. 794. 795. 796. 797.\n",
      " 798. 799. 800. 801. 802. 803. 804. 805. 806. 807. 808. 809. 810. 811.\n",
      " 812. 813. 814. 815. 816. 817. 818. 819. 820. 821. 822. 823. 824. 825.\n",
      " 826. 827. 828. 829. 830. 831. 832. 833. 834. 835. 836. 837. 838. 839.\n",
      " 840. 841. 842. 843. 844. 845. 846. 847. 848. 849. 850. 851. 852. 853.\n",
      " 854. 855. 856. 857. 858. 859. 860. 861. 862. 863. 864. 865. 866. 867.\n",
      " 868. 869. 870. 871. 872. 873. 874. 875. 876. 877. 878. 879. 880. 881.\n",
      " 882. 883. 884. 885. 886. 887. 888. 889. 890. 891. 892. 893. 894. 895.\n",
      " 896. 897. 898. 899. 900. 901. 902. 903. 904. 905. 906. 907. 908. 909.\n",
      " 910. 911. 912. 913. 914. 915. 916. 917. 918. 919. 920. 921. 922. 923.\n",
      " 924. 925. 926. 927. 928. 929. 930. 931. 932. 933. 934. 935. 936. 937.\n",
      " 938. 939. 940. 941. 942. 943. 944. 945. 946. 947. 948. 949. 950. 951.\n",
      " 952. 953. 954. 955. 956. 957. 958. 959. 960. 961. 962. 963. 964. 965.\n",
      " 966. 967. 968. 969. 970. 971. 972. 973. 974. 975. 976. 977. 978. 979.\n",
      " 980. 981. 982. 983. 984. 985. 986. 987. 988. 989. 990. 991. 992. 993.\n",
      " 994. 995. 996. 997. 998. 999.]\n",
      "[[0.44182488 0.15303479 0.12645964 ... 0.28049049 0.88026887 0.53171641]\n",
      " [0.03740757 0.34985149 0.38955975 ... 0.06550678 0.33117694 0.22765315]\n",
      " [0.30357459 0.53781545 0.2005505  ... 0.07402524 0.34682354 0.20791489]\n",
      " ...\n",
      " [0.40609333 0.54102761 0.43587345 ... 0.3030937  0.01270484 1.39897931]\n",
      " [0.07913039 0.14274192 0.75967175 ... 0.34730536 0.45179495 0.74191493]\n",
      " [0.32506564 0.38684285 2.04378343 ... 0.13303126 0.36846662 0.75627124]]\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "  84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n",
      " 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n",
      " 126. 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139.\n",
      " 140. 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153.\n",
      " 154. 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167.\n",
      " 168. 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181.\n",
      " 182. 183. 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195.\n",
      " 196. 197. 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209.\n",
      " 210. 211. 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223.\n",
      " 224. 225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237.\n",
      " 238. 239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251.\n",
      " 252. 253. 254. 255. 256. 257. 258. 259. 260. 261. 262. 263. 264. 265.\n",
      " 266. 267. 268. 269. 270. 271. 272. 273. 274. 275. 276. 277. 278. 279.\n",
      " 280. 281. 282. 283. 284. 285. 286. 287. 288. 289. 290. 291. 292. 293.\n",
      " 294. 295. 296. 297. 298. 299. 300. 301. 302. 303. 304. 305. 306. 307.\n",
      " 308. 309. 310. 311. 312. 313. 314. 315. 316. 317. 318. 319. 320. 321.\n",
      " 322. 323. 324. 325. 326. 327. 328. 329. 330. 331. 332. 333. 334. 335.\n",
      " 336. 337. 338. 339. 340. 341. 342. 343. 344. 345. 346. 347. 348. 349.\n",
      " 350. 351. 352. 353. 354. 355. 356. 357. 358. 359. 360. 361. 362. 363.\n",
      " 364. 365. 366. 367. 368. 369. 370. 371. 372. 373. 374. 375. 376. 377.\n",
      " 378. 379. 380. 381. 382. 383. 384. 385. 386. 387. 388. 389. 390. 391.\n",
      " 392. 393. 394. 395. 396. 397. 398. 399. 400. 401. 402. 403. 404. 405.\n",
      " 406. 407. 408. 409. 410. 411. 412. 413. 414. 415. 416. 417. 418. 419.\n",
      " 420. 421. 422. 423. 424. 425. 426. 427. 428. 429. 430. 431. 432. 433.\n",
      " 434. 435. 436. 437. 438. 439. 440. 441. 442. 443. 444. 445. 446. 447.\n",
      " 448. 449. 450. 451. 452. 453. 454. 455. 456. 457. 458. 459. 460. 461.\n",
      " 462. 463. 464. 465. 466. 467. 468. 469. 470. 471. 472. 473. 474. 475.\n",
      " 476. 477. 478. 479. 480. 481. 482. 483. 484. 485. 486. 487. 488. 489.\n",
      " 490. 491. 492. 493. 494. 495. 496. 497. 498. 499. 500. 501. 502. 503.\n",
      " 504. 505. 506. 507. 508. 509. 510. 511. 512. 513. 514. 515. 516. 517.\n",
      " 518. 519. 520. 521. 522. 523. 524. 525. 526. 527. 528. 529. 530. 531.\n",
      " 532. 533. 534. 535. 536. 537. 538. 539. 540. 541. 542. 543. 544. 545.\n",
      " 546. 547. 548. 549. 550. 551. 552. 553. 554. 555. 556. 557. 558. 559.\n",
      " 560. 561. 562. 563. 564. 565. 566. 567. 568. 569. 570. 571. 572. 573.\n",
      " 574. 575. 576. 577. 578. 579. 580. 581. 582. 583. 584. 585. 586. 587.\n",
      " 588. 589. 590. 591. 592. 593. 594. 595. 596. 597. 598. 599. 600. 601.\n",
      " 602. 603. 604. 605. 606. 607. 608. 609. 610. 611. 612. 613. 614. 615.\n",
      " 616. 617. 618. 619. 620. 621. 622. 623. 624. 625. 626. 627. 628. 629.\n",
      " 630. 631. 632. 633. 634. 635. 636. 637. 638. 639. 640. 641. 642. 643.\n",
      " 644. 645. 646. 647. 648. 649. 650. 651. 652. 653. 654. 655. 656. 657.\n",
      " 658. 659. 660. 661. 662. 663. 664. 665. 666. 667. 668. 669. 670. 671.\n",
      " 672. 673. 674. 675. 676. 677. 678. 679. 680. 681. 682. 683. 684. 685.\n",
      " 686. 687. 688. 689. 690. 691. 692. 693. 694. 695. 696. 697. 698. 699.\n",
      " 700. 701. 702. 703. 704. 705. 706. 707. 708. 709. 710. 711. 712. 713.\n",
      " 714. 715. 716. 717. 718. 719. 720. 721. 722. 723. 724. 725. 726. 727.\n",
      " 728. 729. 730. 731. 732. 733. 734. 735. 736. 737. 738. 739. 740. 741.\n",
      " 742. 743. 744. 745. 746. 747. 748. 749. 750. 751. 752. 753. 754. 755.\n",
      " 756. 757. 758. 759. 760. 761. 762. 763. 764. 765. 766. 767. 768. 769.\n",
      " 770. 771. 772. 773. 774. 775. 776. 777. 778. 779. 780. 781. 782. 783.\n",
      " 784. 785. 786. 787. 788. 789. 790. 791. 792. 793. 794. 795. 796. 797.\n",
      " 798. 799. 800. 801. 802. 803. 804. 805. 806. 807. 808. 809. 810. 811.\n",
      " 812. 813. 814. 815. 816. 817. 818. 819. 820. 821. 822. 823. 824. 825.\n",
      " 826. 827. 828. 829. 830. 831. 832. 833. 834. 835. 836. 837. 838. 839.\n",
      " 840. 841. 842. 843. 844. 845. 846. 847. 848. 849. 850. 851. 852. 853.\n",
      " 854. 855. 856. 857. 858. 859. 860. 861. 862. 863. 864. 865. 866. 867.\n",
      " 868. 869. 870. 871. 872. 873. 874. 875. 876. 877. 878. 879. 880. 881.\n",
      " 882. 883. 884. 885. 886. 887. 888. 889. 890. 891. 892. 893. 894. 895.\n",
      " 896. 897. 898. 899. 900. 901. 902. 903. 904. 905. 906. 907. 908. 909.\n",
      " 910. 911. 912. 913. 914. 915. 916. 917. 918. 919. 920. 921. 922. 923.\n",
      " 924. 925. 926. 927. 928. 929. 930. 931. 932. 933. 934. 935. 936. 937.\n",
      " 938. 939. 940. 941. 942. 943. 944. 945. 946. 947. 948. 949. 950. 951.\n",
      " 952. 953. 954. 955. 956. 957. 958. 959. 960. 961. 962. 963. 964. 965.\n",
      " 966. 967. 968. 969. 970. 971. 972. 973. 974. 975. 976. 977. 978. 979.\n",
      " 980. 981. 982. 983. 984. 985. 986. 987. 988. 989. 990. 991. 992. 993.\n",
      " 994. 995. 996. 997. 998. 999.]\n"
     ]
    }
   ],
   "source": [
    "embeddings_seen_arr = np.zeros((int(3*len(dataloader)/4), 2048))\n",
    "counter = 0\n",
    "for embedding in embeddings_list:\n",
    "    embeddings_seen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "\n",
    "print(embeddings_seen_arr)\n",
    "labels_seen_arr = np.zeros(int(3*len(dataloader)/4))\n",
    "counter = 0\n",
    "for i in labels_list:\n",
    "    labels_seen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(np.unique(labels_seen_arr))\n",
    "\n",
    "embeddings_unseen_arr = np.zeros((int(len(dataloader)/4), 2048))\n",
    "counter = 0\n",
    "for embedding in embeddings_unseen_list:\n",
    "    embeddings_unseen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "\n",
    "print(embeddings_unseen_arr)\n",
    "labels_unseen_arr = np.zeros(int(len(dataloader)/4))\n",
    "counter = 0\n",
    "for i in labels_unseen_list:\n",
    "    labels_unseen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(np.unique(labels_unseen_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4645602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#JUST TRY DELETE LATER\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embeddings_unseen_arr_trial = embeddings_unseen_arr[0:180,:]\n",
    "labels_unseen_arr_trial = labels_unseen_arr[0:180]\n",
    "\n",
    "#pca = PCA(n_components=2)\n",
    "#pca.fit(embeddings_unseen_arr)\n",
    "#print(pca.explained_variance_ratio_)\n",
    "\n",
    "#embeddings_reduced = pca.transform(embeddings_unseen_arr)\n",
    "#print(embeddings_reduced)\n",
    "\n",
    "u_labels = np.unique(labels_unseen_arr_trial)\n",
    "print(u_labels)\n",
    "\n",
    "embeddings_reduced = TSNE(n_components=2, learning_rate='auto',init='random', perplexity = 10.0).fit_transform(embeddings_unseen_arr_trial)\n",
    "\n",
    "for i in u_labels:\n",
    "    \n",
    "    plt.scatter(embeddings_reduced[labels_unseen_arr_trial == i , 0] , embeddings_reduced[labels_unseen_arr_trial == i , 1] , label = i)\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9146f3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53104\n",
      "Accuracy: 0.5348\n",
      "Accuracy: 0.56032\n",
      "Accuracy: 0.57928\n",
      "Accuracy: 0.58632\n",
      "Accuracy: 0.58416\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.57856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbours = [1, 3, 5, 10, 20, 30, 40, 50]\n",
    "\n",
    "for k in n_neighbours:\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(embeddings_seen_arr, labels_seen_arr)\n",
    "    labels_predicted = knn.predict(embeddings_unseen_arr)\n",
    "\n",
    "    #print('Accuracy' + str(k) + ':', np.sum(labels_unseen_arr == labels_predicted)/len(labels_unseen_arr))\n",
    "    print('Accuracy:', knn.score(embeddings_unseen_arr, labels_unseen_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cd153ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[328 199 199 ... 239 239 123]\n",
      "0.9985074901992159\n",
      "0.474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=1000, random_state=0).fit(embeddings_seen_arr)\n",
    "labels_predicted = kmeans.predict(embeddings_unseen_arr)\n",
    "print(labels_predicted)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.rand_score(labels_unseen_arr, labels_predicted))\n",
    "\n",
    "truth = labels_unseen_arr\n",
    "pred=labels_predicted\n",
    "print(np.sum( get_y_preds(pred, truth, 1000)[0] == truth )/len(truth) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfe03937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /local/home/bsoyuer/.cache/torch/hub/facebookresearch_vicreg_main\n"
     ]
    }
   ],
   "source": [
    "vicreg_model_pretrained = torch.hub.load('facebookresearch/vicreg:main', 'resnet50')\n",
    "torch.save(vicreg_model_pretrained.state_dict(), 'resnet50_imagenet_pretrained_vicreg.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de8edc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone, embedding = resnet.__dict__['resnet50'](zero_init_residual=True)\n",
    "state_dict = torch.load('resnet50_imagenet_pretrained_vicreg.pth', map_location=\"cpu\")\n",
    "if \"model\" in state_dict:\n",
    "    state_dict = state_dict[\"model\"]\n",
    "    state_dict = {key.replace(\"module.backbone.\", \"\"): value for (key, value) in state_dict.items()}\n",
    "backbone.load_state_dict(state_dict, strict=False)\n",
    "backbone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e55c550d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding)\n",
    "backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "297bb401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n",
      "22000\n",
      "22500\n",
      "23000\n",
      "23500\n",
      "24000\n",
      "24500\n",
      "25000\n",
      "25500\n",
      "26000\n",
      "26500\n",
      "27000\n",
      "27500\n",
      "28000\n",
      "28500\n",
      "29000\n",
      "29500\n",
      "30000\n",
      "30500\n",
      "31000\n",
      "31500\n",
      "32000\n",
      "32500\n",
      "33000\n",
      "33500\n",
      "34000\n",
      "34500\n",
      "35000\n",
      "35500\n",
      "36000\n",
      "36500\n",
      "37000\n",
      "37500\n",
      "38000\n",
      "38500\n",
      "39000\n",
      "39500\n",
      "40000\n",
      "40500\n",
      "41000\n",
      "41500\n",
      "42000\n",
      "42500\n",
      "43000\n",
      "43500\n",
      "44000\n",
      "44500\n",
      "45000\n",
      "45500\n",
      "46000\n",
      "46500\n",
      "47000\n",
      "47500\n",
      "48000\n",
      "48500\n",
      "49000\n",
      "49500\n"
     ]
    }
   ],
   "source": [
    "labels_list = []\n",
    "embeddings_list = []\n",
    "\n",
    "labels_unseen_list = []\n",
    "embeddings_unseen_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        \n",
    "        #if i == 50000:\n",
    "            #break\n",
    "            \n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        if i%4 == 0:\n",
    "            embedding = backbone(inputs.to(device))\n",
    "            embeddings_unseen_list.append(embedding)\n",
    "            labels_unseen_list.append(labels)\n",
    "            \n",
    "        else:\n",
    "            embedding = backbone(inputs.to(device))\n",
    "            embeddings_list.append(embedding)\n",
    "            labels_list.append(labels)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c94851cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1175919  0.178287   0.         ... 0.65092319 0.         0.01470529]\n",
      " [0.         0.01578594 0.         ... 0.         0.         0.13610066]\n",
      " [0.03547306 0.00303839 0.         ... 0.13677892 0.17592302 0.        ]\n",
      " ...\n",
      " [0.64179617 0.00686585 0.         ... 0.92202634 0.00403233 0.28097665]\n",
      " [0.38417003 0.         0.         ... 0.07829548 0.         2.59024048]\n",
      " [0.75951803 0.17255424 0.         ... 0.01579968 0.05882057 0.03095703]]\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "  84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n",
      " 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n",
      " 126. 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139.\n",
      " 140. 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153.\n",
      " 154. 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167.\n",
      " 168. 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181.\n",
      " 182. 183. 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195.\n",
      " 196. 197. 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209.\n",
      " 210. 211. 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223.\n",
      " 224. 225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237.\n",
      " 238. 239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251.\n",
      " 252. 253. 254. 255. 256. 257. 258. 259. 260. 261. 262. 263. 264. 265.\n",
      " 266. 267. 268. 269. 270. 271. 272. 273. 274. 275. 276. 277. 278. 279.\n",
      " 280. 281. 282. 283. 284. 285. 286. 287. 288. 289. 290. 291. 292. 293.\n",
      " 294. 295. 296. 297. 298. 299. 300. 301. 302. 303. 304. 305. 306. 307.\n",
      " 308. 309. 310. 311. 312. 313. 314. 315. 316. 317. 318. 319. 320. 321.\n",
      " 322. 323. 324. 325. 326. 327. 328. 329. 330. 331. 332. 333. 334. 335.\n",
      " 336. 337. 338. 339. 340. 341. 342. 343. 344. 345. 346. 347. 348. 349.\n",
      " 350. 351. 352. 353. 354. 355. 356. 357. 358. 359. 360. 361. 362. 363.\n",
      " 364. 365. 366. 367. 368. 369. 370. 371. 372. 373. 374. 375. 376. 377.\n",
      " 378. 379. 380. 381. 382. 383. 384. 385. 386. 387. 388. 389. 390. 391.\n",
      " 392. 393. 394. 395. 396. 397. 398. 399. 400. 401. 402. 403. 404. 405.\n",
      " 406. 407. 408. 409. 410. 411. 412. 413. 414. 415. 416. 417. 418. 419.\n",
      " 420. 421. 422. 423. 424. 425. 426. 427. 428. 429. 430. 431. 432. 433.\n",
      " 434. 435. 436. 437. 438. 439. 440. 441. 442. 443. 444. 445. 446. 447.\n",
      " 448. 449. 450. 451. 452. 453. 454. 455. 456. 457. 458. 459. 460. 461.\n",
      " 462. 463. 464. 465. 466. 467. 468. 469. 470. 471. 472. 473. 474. 475.\n",
      " 476. 477. 478. 479. 480. 481. 482. 483. 484. 485. 486. 487. 488. 489.\n",
      " 490. 491. 492. 493. 494. 495. 496. 497. 498. 499. 500. 501. 502. 503.\n",
      " 504. 505. 506. 507. 508. 509. 510. 511. 512. 513. 514. 515. 516. 517.\n",
      " 518. 519. 520. 521. 522. 523. 524. 525. 526. 527. 528. 529. 530. 531.\n",
      " 532. 533. 534. 535. 536. 537. 538. 539. 540. 541. 542. 543. 544. 545.\n",
      " 546. 547. 548. 549. 550. 551. 552. 553. 554. 555. 556. 557. 558. 559.\n",
      " 560. 561. 562. 563. 564. 565. 566. 567. 568. 569. 570. 571. 572. 573.\n",
      " 574. 575. 576. 577. 578. 579. 580. 581. 582. 583. 584. 585. 586. 587.\n",
      " 588. 589. 590. 591. 592. 593. 594. 595. 596. 597. 598. 599. 600. 601.\n",
      " 602. 603. 604. 605. 606. 607. 608. 609. 610. 611. 612. 613. 614. 615.\n",
      " 616. 617. 618. 619. 620. 621. 622. 623. 624. 625. 626. 627. 628. 629.\n",
      " 630. 631. 632. 633. 634. 635. 636. 637. 638. 639. 640. 641. 642. 643.\n",
      " 644. 645. 646. 647. 648. 649. 650. 651. 652. 653. 654. 655. 656. 657.\n",
      " 658. 659. 660. 661. 662. 663. 664. 665. 666. 667. 668. 669. 670. 671.\n",
      " 672. 673. 674. 675. 676. 677. 678. 679. 680. 681. 682. 683. 684. 685.\n",
      " 686. 687. 688. 689. 690. 691. 692. 693. 694. 695. 696. 697. 698. 699.\n",
      " 700. 701. 702. 703. 704. 705. 706. 707. 708. 709. 710. 711. 712. 713.\n",
      " 714. 715. 716. 717. 718. 719. 720. 721. 722. 723. 724. 725. 726. 727.\n",
      " 728. 729. 730. 731. 732. 733. 734. 735. 736. 737. 738. 739. 740. 741.\n",
      " 742. 743. 744. 745. 746. 747. 748. 749. 750. 751. 752. 753. 754. 755.\n",
      " 756. 757. 758. 759. 760. 761. 762. 763. 764. 765. 766. 767. 768. 769.\n",
      " 770. 771. 772. 773. 774. 775. 776. 777. 778. 779. 780. 781. 782. 783.\n",
      " 784. 785. 786. 787. 788. 789. 790. 791. 792. 793. 794. 795. 796. 797.\n",
      " 798. 799. 800. 801. 802. 803. 804. 805. 806. 807. 808. 809. 810. 811.\n",
      " 812. 813. 814. 815. 816. 817. 818. 819. 820. 821. 822. 823. 824. 825.\n",
      " 826. 827. 828. 829. 830. 831. 832. 833. 834. 835. 836. 837. 838. 839.\n",
      " 840. 841. 842. 843. 844. 845. 846. 847. 848. 849. 850. 851. 852. 853.\n",
      " 854. 855. 856. 857. 858. 859. 860. 861. 862. 863. 864. 865. 866. 867.\n",
      " 868. 869. 870. 871. 872. 873. 874. 875. 876. 877. 878. 879. 880. 881.\n",
      " 882. 883. 884. 885. 886. 887. 888. 889. 890. 891. 892. 893. 894. 895.\n",
      " 896. 897. 898. 899. 900. 901. 902. 903. 904. 905. 906. 907. 908. 909.\n",
      " 910. 911. 912. 913. 914. 915. 916. 917. 918. 919. 920. 921. 922. 923.\n",
      " 924. 925. 926. 927. 928. 929. 930. 931. 932. 933. 934. 935. 936. 937.\n",
      " 938. 939. 940. 941. 942. 943. 944. 945. 946. 947. 948. 949. 950. 951.\n",
      " 952. 953. 954. 955. 956. 957. 958. 959. 960. 961. 962. 963. 964. 965.\n",
      " 966. 967. 968. 969. 970. 971. 972. 973. 974. 975. 976. 977. 978. 979.\n",
      " 980. 981. 982. 983. 984. 985. 986. 987. 988. 989. 990. 991. 992. 993.\n",
      " 994. 995. 996. 997. 998. 999.]\n",
      "[[0.08253729 0.64876604 0.         ... 0.14106196 0.07329769 0.52666855]\n",
      " [0.01982168 0.56948513 0.         ... 0.24748755 0.49740112 0.06558616]\n",
      " [0.15730518 0.08002573 0.         ... 0.32769576 0.09553516 0.        ]\n",
      " ...\n",
      " [0.64697582 0.36528793 0.         ... 0.         0.         0.98660165]\n",
      " [0.07545825 0.3996866  0.         ... 0.05723232 0.         0.6095649 ]\n",
      " [0.02926878 0.1889782  0.18549831 ... 0.13249403 0.         0.27114734]]\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "  84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n",
      " 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n",
      " 126. 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139.\n",
      " 140. 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153.\n",
      " 154. 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167.\n",
      " 168. 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181.\n",
      " 182. 183. 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195.\n",
      " 196. 197. 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209.\n",
      " 210. 211. 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223.\n",
      " 224. 225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237.\n",
      " 238. 239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251.\n",
      " 252. 253. 254. 255. 256. 257. 258. 259. 260. 261. 262. 263. 264. 265.\n",
      " 266. 267. 268. 269. 270. 271. 272. 273. 274. 275. 276. 277. 278. 279.\n",
      " 280. 281. 282. 283. 284. 285. 286. 287. 288. 289. 290. 291. 292. 293.\n",
      " 294. 295. 296. 297. 298. 299. 300. 301. 302. 303. 304. 305. 306. 307.\n",
      " 308. 309. 310. 311. 312. 313. 314. 315. 316. 317. 318. 319. 320. 321.\n",
      " 322. 323. 324. 325. 326. 327. 328. 329. 330. 331. 332. 333. 334. 335.\n",
      " 336. 337. 338. 339. 340. 341. 342. 343. 344. 345. 346. 347. 348. 349.\n",
      " 350. 351. 352. 353. 354. 355. 356. 357. 358. 359. 360. 361. 362. 363.\n",
      " 364. 365. 366. 367. 368. 369. 370. 371. 372. 373. 374. 375. 376. 377.\n",
      " 378. 379. 380. 381. 382. 383. 384. 385. 386. 387. 388. 389. 390. 391.\n",
      " 392. 393. 394. 395. 396. 397. 398. 399. 400. 401. 402. 403. 404. 405.\n",
      " 406. 407. 408. 409. 410. 411. 412. 413. 414. 415. 416. 417. 418. 419.\n",
      " 420. 421. 422. 423. 424. 425. 426. 427. 428. 429. 430. 431. 432. 433.\n",
      " 434. 435. 436. 437. 438. 439. 440. 441. 442. 443. 444. 445. 446. 447.\n",
      " 448. 449. 450. 451. 452. 453. 454. 455. 456. 457. 458. 459. 460. 461.\n",
      " 462. 463. 464. 465. 466. 467. 468. 469. 470. 471. 472. 473. 474. 475.\n",
      " 476. 477. 478. 479. 480. 481. 482. 483. 484. 485. 486. 487. 488. 489.\n",
      " 490. 491. 492. 493. 494. 495. 496. 497. 498. 499. 500. 501. 502. 503.\n",
      " 504. 505. 506. 507. 508. 509. 510. 511. 512. 513. 514. 515. 516. 517.\n",
      " 518. 519. 520. 521. 522. 523. 524. 525. 526. 527. 528. 529. 530. 531.\n",
      " 532. 533. 534. 535. 536. 537. 538. 539. 540. 541. 542. 543. 544. 545.\n",
      " 546. 547. 548. 549. 550. 551. 552. 553. 554. 555. 556. 557. 558. 559.\n",
      " 560. 561. 562. 563. 564. 565. 566. 567. 568. 569. 570. 571. 572. 573.\n",
      " 574. 575. 576. 577. 578. 579. 580. 581. 582. 583. 584. 585. 586. 587.\n",
      " 588. 589. 590. 591. 592. 593. 594. 595. 596. 597. 598. 599. 600. 601.\n",
      " 602. 603. 604. 605. 606. 607. 608. 609. 610. 611. 612. 613. 614. 615.\n",
      " 616. 617. 618. 619. 620. 621. 622. 623. 624. 625. 626. 627. 628. 629.\n",
      " 630. 631. 632. 633. 634. 635. 636. 637. 638. 639. 640. 641. 642. 643.\n",
      " 644. 645. 646. 647. 648. 649. 650. 651. 652. 653. 654. 655. 656. 657.\n",
      " 658. 659. 660. 661. 662. 663. 664. 665. 666. 667. 668. 669. 670. 671.\n",
      " 672. 673. 674. 675. 676. 677. 678. 679. 680. 681. 682. 683. 684. 685.\n",
      " 686. 687. 688. 689. 690. 691. 692. 693. 694. 695. 696. 697. 698. 699.\n",
      " 700. 701. 702. 703. 704. 705. 706. 707. 708. 709. 710. 711. 712. 713.\n",
      " 714. 715. 716. 717. 718. 719. 720. 721. 722. 723. 724. 725. 726. 727.\n",
      " 728. 729. 730. 731. 732. 733. 734. 735. 736. 737. 738. 739. 740. 741.\n",
      " 742. 743. 744. 745. 746. 747. 748. 749. 750. 751. 752. 753. 754. 755.\n",
      " 756. 757. 758. 759. 760. 761. 762. 763. 764. 765. 766. 767. 768. 769.\n",
      " 770. 771. 772. 773. 774. 775. 776. 777. 778. 779. 780. 781. 782. 783.\n",
      " 784. 785. 786. 787. 788. 789. 790. 791. 792. 793. 794. 795. 796. 797.\n",
      " 798. 799. 800. 801. 802. 803. 804. 805. 806. 807. 808. 809. 810. 811.\n",
      " 812. 813. 814. 815. 816. 817. 818. 819. 820. 821. 822. 823. 824. 825.\n",
      " 826. 827. 828. 829. 830. 831. 832. 833. 834. 835. 836. 837. 838. 839.\n",
      " 840. 841. 842. 843. 844. 845. 846. 847. 848. 849. 850. 851. 852. 853.\n",
      " 854. 855. 856. 857. 858. 859. 860. 861. 862. 863. 864. 865. 866. 867.\n",
      " 868. 869. 870. 871. 872. 873. 874. 875. 876. 877. 878. 879. 880. 881.\n",
      " 882. 883. 884. 885. 886. 887. 888. 889. 890. 891. 892. 893. 894. 895.\n",
      " 896. 897. 898. 899. 900. 901. 902. 903. 904. 905. 906. 907. 908. 909.\n",
      " 910. 911. 912. 913. 914. 915. 916. 917. 918. 919. 920. 921. 922. 923.\n",
      " 924. 925. 926. 927. 928. 929. 930. 931. 932. 933. 934. 935. 936. 937.\n",
      " 938. 939. 940. 941. 942. 943. 944. 945. 946. 947. 948. 949. 950. 951.\n",
      " 952. 953. 954. 955. 956. 957. 958. 959. 960. 961. 962. 963. 964. 965.\n",
      " 966. 967. 968. 969. 970. 971. 972. 973. 974. 975. 976. 977. 978. 979.\n",
      " 980. 981. 982. 983. 984. 985. 986. 987. 988. 989. 990. 991. 992. 993.\n",
      " 994. 995. 996. 997. 998. 999.]\n"
     ]
    }
   ],
   "source": [
    "embeddings_seen_arr = np.zeros((int(3*len(dataloader)/4), 2048))\n",
    "counter = 0\n",
    "for embedding in embeddings_list:\n",
    "    embeddings_seen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "\n",
    "print(embeddings_seen_arr)\n",
    "labels_seen_arr = np.zeros(int(3*len(dataloader)/4))\n",
    "counter = 0\n",
    "for i in labels_list:\n",
    "    labels_seen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(np.unique(labels_seen_arr))\n",
    "\n",
    "embeddings_unseen_arr = np.zeros((int(len(dataloader)/4), 2048))\n",
    "counter = 0\n",
    "for embedding in embeddings_unseen_list:\n",
    "    embeddings_unseen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "\n",
    "print(embeddings_unseen_arr)\n",
    "labels_unseen_arr = np.zeros(int(len(dataloader)/4))\n",
    "counter = 0\n",
    "for i in labels_unseen_list:\n",
    "    labels_unseen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(np.unique(labels_unseen_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a74e58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42552\n",
      "Accuracy: 0.41096\n",
      "Accuracy: 0.43504\n",
      "Accuracy: 0.45112\n",
      "Accuracy: 0.46\n",
      "Accuracy: 0.45696\n",
      "Accuracy: 0.4556\n",
      "Accuracy: 0.45544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbours = [1, 3, 5, 10, 20, 30, 40, 50]\n",
    "\n",
    "for k in n_neighbours:\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(embeddings_seen_arr, labels_seen_arr)\n",
    "    labels_predicted = knn.predict(embeddings_unseen_arr)\n",
    "\n",
    "    #print('Accuracy' + str(k) + ':', np.sum(labels_unseen_arr == labels_predicted)/len(labels_unseen_arr))\n",
    "    print('Accuracy:', knn.score(embeddings_unseen_arr, labels_unseen_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67aa0a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA0d0lEQVR4nO3de3Rc9XXo8e+WNJaEjCWMrWgkmxo5xtiALmaphEdMg5XatIoiQhLHLfdC03T5chdpbLfQ2LBCHVgpTiAB59F2+TbJde4lJV68jOpk2UR2EiJeMRjEww/AIcG2hA1GA35I1uN3/5g58jzOmTkzc2bmzGh/1tKSdGY08xOPfX7av/3bPzHGoJRSqjSVFXoASimlckeDvFJKlTAN8kopVcI0yCulVAnTIK+UUiWsotADiDZt2jQza9asQg9DKaWKyvPPP/+uMWa63WO+CvKzZs1i586dhR6GUkoVFRH5g9Njmq5RSqkSpkFeKaVKmAZ5pZQqYVkHeRGpEpHnROQlEXlVRL4euT5VRJ4Qkdcjn8/KfrhKKaXS4cVMfghYZIz5b8DFwDUichmwGug2xswBuiPfK6WUyqOsq2tMuMPZsci3gciHATqBT0SubwR+BXw12/dTKtd6e3vp7u4mFApRW1tLW1sbLS0thR6WUhnxJCcvIuUi8iJwGHjCGPMs8BFjTB9A5HO9F++lVC719vbS1dVFKBQCIBQK0dXVRW9vb4FHplRmPAnyxphRY8zFwAzgUhG50O3PishyEdkpIjuPHDnixXCUylh3dzfDw8Mx14aHh+nu7i7QiJTKjqfVNcaYAcJpmWuAd0QkCBD5fNjhZzYYY1qNMa3Tp9tu2FIqb6wZvNvrSvld1jl5EZkODBtjBkSkGvgk8E3gceBGYF3k8+Zs30spr9jl3QFEBLuDdGpra/M9RKU84UVbgyCwUUTKCf9lsMkY818i8jSwSUS+BPwR+LwH76VU1qy8u5WWCYVCPPbYY44BPhAIjN8ElCo2XlTX9AILbK6/B+j/Gcp37PLuY2Njts8VETo6OrS6RhUt3fGqJpx08uvGGA3wqqhpkFcTTjr5dc3Fq2KnQV5NOG1tbQQCgZhrZWVllJeXx1zTXLwqBb7qJ69UPljpF7vqmkx3uuouWeVXYldNUCitra1GDw1Rfhcf0OfMmcNLL70Us5gbCAR0wVbljYg8b4xptXtM0zVKpcGu7cHOnTt1l6zyLQ3ySqXBrvzSie6SVX6gOXmlXOrr38x5c39MZeVxhoZqeOv3F3PkSLPj87UyR/mBBnmlXOjr38yePbdTVXUSgKqq48w57xkA20CfTWVOX/9m9r95L4NDfVRVBmmefQvBhs7MB68mNE3XKOXC/jfvZWzsZMy18vJRZp37IoFAgNbW1vGZe21tbcaLrtbNZHDoEGAYHDrEnj2309evrZ9UZnQmr3Li4f6j3L2/j4NDwzRVBljTHOSzDVMLPayMDQ712V6vrDzOFVd2MTb2Yy69NPtZt93NZGzsJPvfvFdn8yojOpNXnnu4/yi37H2bA0PDGODA0DC37H2bh/uPFnpoGauqDNpeFxHGxo7g1azb6WbidF2pVDTIK8/dvb+Pk2Ox+y9Ojhnu3l+8gap59i2UlVXHXRXCJ12eZs26M+V0M3G6rlQqGuSV5w4O2ZcYOl33g77+zfT0LKR7+0fp6VmYMBsPNnRy/vnfoKqyEZDIZ/uNhNnMuu1uJmVl1TTPviXj11QTm+bkleeaKgMcsAnoTZUBm2cXnrXYaeXCrbSLxanSpadnYWSBNFY2s27rtbW6RnlFg7zy3JrmILfsfTsmZVNdJqxp9mfKwWmxc9++uxgbG7QN/sGGTppn3xJzcwBvZt3Bhk4N6sozGuRVRuyqZ4Dxa3UV5VSJYWB0zPfVNU7plZGR9xOuRVe66KxbFQMN8iptVvWMNVM/MDTMyt1/BBGGIw3v3h8ZpbpM+P68c3wb3C1VlUHbtIuT6JuCzrqV3+nCq0qbXfXMMIwHeEuxVNQ4LXZWlNfZPl8rXVQx0Zm8SsouLZNOlYyfK2osTmkXICc5d6XySYO8cmSXlrll79vUVZTz/sioq9fwa0VNvGRplz177mZ09AhDQzUcfucKzp56LsGGPA9QqQxpkFeOnDY1VYmhukwSHovn54oat44cPpenejpi2gsfOtQFoAeCqKKgOXnlyCnVMjA6xr1zZzIjySy9HLh37kzfL7qmYtc/Xg8EUcVEg7xy5JRqaaoM8NmGqey84gLE4WfHoOgDPDgf/KEHgqhioUFeOVrTHKS6LDaMx6dgkt0ISoHTwR8iQm9vb55Ho1T6NCevHFkz8WQtg4ttd2u62tra6OrqSkjZGGPo6orNzccf8N3W1qZ5e1VwGuRVUp9tmJo07eLmRpBLuT5FyQrSjz76KCZuH4CVm29paRk/4Nu6GYRCoYSbgFKFoEFeZS3VjSBXkjUW8zrQP/LII7aPWbn5ZAu0GuRVIWUd5EVkJvAToIHwetsGY8x6EZkK/AyYBbwFLDXGJDYDUSpDTo3FXnvtH9j/5r1Zz+qj0y8ikjCTh9M5e12gVX7lxcLrCPCPxph5wGXAzSIyH1gNdBtj5gDdke+V8kyyvu3ZntJkpV+sIG0X4KMP63ZaoHW6rlS+ZB3kjTF9xpgXIl9/COwGmoBOYGPkaRuBa7N9L6Wipeohk84pTfGHhjz//L8mpF8gXFUDiYd1t7W1EQjEVhRF3wSUKhRPc/IiMgtYADwLfMQY0wfhG4GI1Dv8zHJgOcA555zj5XBUibPr5x7PzSlNdrn9phnvcOLEZRw50hzzXGMMa9euTXgNK9hrdY3yG8+CvIhMBh4GVhpjPrBmPKkYYzYAGwBaW1uT75NXKkpsYzH7VsFuOkba5fbLy0eZde6LCUE+WfqlpaVFg7ryHU82Q4lIgHCAf8AYY5UhvCMiwcjjQeCwF++lVLRgQydXXvkk8+d/J+OzUZ1m+5WVx2O+1/SLKkZZB3kJT9l/COw2xnwn6qHHgRsjX98IZLYCppQLdgdtn3/+N1xV1zjN9svLp4/P3ONz8EoVC7GrGkjrBUQ+DjwJvEy4hBLgNsJ5+U3AOcAfgc8bY44me63W1lazc+fOrMajVLric/IQ/ivA7U1CqUITkeeNMa12j2WdkzfG/BYc+1Tp37bK99ye1Zrr3bVK5YLueFWK1Ge15mt3rVJe0y6USrngtLvWbR2+UoWiQV4pF5wqcNzU4RebUFcXry9qY/e8+by+qI1QpNGaKk4a5JVywakCx00dfjEJdXXR97U7GDl0CIxh5NAh+r52hwb6IqZBXikXmmffknEdfjE5fN/9mMHBmGtmcJDD991fmAGprOnCq1IuuK3AKXYjffbpJ6fryv80yCvlUqoKnFJQEQyGUzU216OFuro4fN/9jPT1UREMUr9qJbUdHfkapkqDpmuUUuPqV61EqqpirklVFfWrVo5/r3n74qIzeaVyoFg3Tlmz8WSz9GR5+2xm84/tOsg9W/dyaOAkjXXV3LpkLtcuaCrY65QKDfJKeazYN07VdnQkDda5yNs/tusgax55mZPDowAcHDjJmkdeBkgrQLt9nYl0I9B0jVIe8+PGqcd2HeTKdds5d/UWrly3ncd2Hcz4teLz86muu3HP1r3jgdlycniUe7bu9fx1rBvBwYGTGE7fCLL5Z+JnGuRVQT3cf5TWp14luONFWp96lYf7k/aw8434k6Sijxn028Ypr4Oam7x9ug4N2B/84nQ9m9fx6oZSLDTIq4J5uP8ot+x9mwNDwxjgwNAwt+x92/eB3krHhA8qMQnnyfpt45TboOZ2p2ttRwfBu+6korERRKhobCR4151Z5eMb66rTup7N63h1QykWGuRVwdy9v4+TY7Gtrk+OGe7e7++a7FTpGL9tnHIT1JwqZvq+/nXbwF/b0cGc7d3M2/0a9atWcvi++7Nqg3DrkrlUB8pjrlUHyrl1yVzPX8erG0qx0CCv8io6PXNgKPGgbAjP6FPN5guZ5kmVjsnmAJNccBPUnCpmBv7zwaSlkl6VU167oIm7r7uIprpqBGiqq+bu6y5KezHUzet4dUMpFlkfGuIlPTSktFnpmfjZu53qMuHeuTP5bMNUV68TEGFymTAwOkZTZYA1zUHbn/VCT89ChzNly5k//x7fVdDEV5xAOKhFB7/d8+aDy1hQ0djInO3dALy+qM1285T1vEJvknKqoim16pqcHhqilFt26RknVtrGLlDbvc6wMbw/Gr5m5faBnAT65tm3JJwkFTbqy1JJK3glC2pOO13tRJdKJiubtGb1QEECfapyymIO6unQdI3Km4MO6Zl0n+/mdXKZ27fSMVCe8FihSyWdXLugiZ7Vi/j9unZ6Vi9KCHB2FTOI/YFv0aWSqcomC9ncbKJV0TjRIK/ypqkyYHs9MVQmf77T9Xjp3lTSEZ6pj9k+Vow95u0qZuqWfSFlqaTtzSFOoZqbTbQqGica5FXetJ19ZsJhwNVlwn9vnEp1mSRcX9NsP0tc0xxMeL4dtzeDTPmtVDJbVsXM3p8+wd8svp0rTray4U+/wPC0esdSyZibg4Py2tr0DiHp3QT3XQhr68Kfezdl9PtMtCoaJxrkVV483H+UTf3vE51JF2Bpw1l8c+453Dt3JjMqAwgwozLguOgK4Tx79PPPqignPpwnu0l4xW+lkl6I3zj1yNkX8YWr17D3p08wZ3u3bW7dujk03vOtxJl/IMDosWPuq296N0HXVyD0NmDCn7u+knagf2zXQU6cGkm4XspVNE60ukblRetTr9qWTM6oDLDziguyfv2H+49y9/4+Dg4N57y6JlqxNiKLFl1pUibCqE1MaKqrpmf1opSvFd+CePTECczAQMLzoit0Ytx3YSTAx6mdCatecfPr2FYTAdRVB1j76QtKcsFVq2tUwWWziOrGZxum5iWox8ukx3ym5Xu56OEeHxDtAjy4z2PHNzfbPW++7fMc8/ShA+ldt2G34ApQU1lRkgE+FU3XqLzIdhG1VGTaRyZXPdydAmK8TPPYyZqZ2bZRqJ1h/0JO123ogmssDfIqL+wWS3OVN/dz07NMy/pydfaqm8CXTR7bqZnZ5D+7yv6mNakTAnE3lEA1tN3h+j11wTWWBnmVF/GLpakWVzPl96Znmc4yc3X2qlPgKxfJqr2AxamZ2bFf/8b+pvXwM9Dx3XAOHgl/7vgutCx1/Z4TrW1BKpqTV3mTj7x5sqZnhcjZx2usq+agTUC3C7Zb9m9h/Qvr6T/ez79NKWNqKDGtkk0PdwgHxFQtD7JldwjJoX/6qu1zR/r6wgE9jaAez80O34lEg7wqKble4M2WU1CNn2Vu2b+FtU+tZXA0PNv9v382xk2/gMqoXyPbHu5QuIDo9sDwTE2ktgWpeBLkReRHwKeAw8aYCyPXpgI/A2YBbwFLjTHve/F+SjlpqgzYlmr6ZYHXbVBd/8L68QAP0HNBOTDK//h1GVM/GPOsusYaU74DYv2qlfR97Y6YlI0XNy16N0H3neFqnNoZ4Vx+Fn8VlAJP6uRF5CrgGPCTqCD/LeCoMWadiKwGzjLG2P+NFqF18ipbdh0qk3W09KuWjS0Y7P/fDNYE6T/eT0NNAysuWUF7c3ueR+cNz0tCrY1Uw1HpsEB1Yk6/BG8EyerkPdsMJSKzgP+KCvJ7gU8YY/pEJAj8yhiTdOVDg7zyQqE2Rnlp8UOL6TueelG1qryKtVesLdpAn0z0moSrG5qbjVRubwRFJlmQz2V1zUeMMX0Akc/1DoNbLiI7RWTnkSNHcjgcNVF8tmEqO6+4gL6rL2bnFRcUXYAHWHHJCqrKkzf+AhgcHWT9C+vzMKIcSNKjxlqT6Dveh8HQd7yPtU+tZcv+Lc6v52YjVfedsQEewt9335n57+FzBS+hNMZsMMa0GmNap0+fXujhKFUYcQGv/dhx1l6xlmBNEEEI1jgvSPYf78/fOL2SokdN/JoEuLihudlI5cGO2mKTyyD/TiRNQ+Tz4Ry+l1LFyyHgtR87zrbPbaP3xl62fW6bY6BvqGnI21DdHvadUooZtdONK+kNre2O1BupPNhRW2xyGeQfB26MfH0jsDmH76VU8XKZQrBL4VSVV7HikhW5HiHgcWuFFDNqpxtX0htay9LxjVT7TlzFxnd/yA/efoCNDzax79nIzcHNjaDEeBLkReQ/gaeBuSJyQES+BKwD/lxEXgf+PPK9UiqeyxRCe3N7Qgonn4uunrZWSDGjdryhTftY8l7zLUvZd8Uv2TH4jxwbmQoIx44OseOBPeFAH3UjyHRHbbHxpE7eGPNXDg+1efH6SpW02hkOVSGJgbC9uT3nQd2pS6anrRXa7rCvconMqK3fMaa6ZtrHaO/536d/xsrjQ0yQfnrzm4ycij21a+TUGE9vfpPzPtaQ9Y7aYqM7XpUqtBQBL1fsShSHQxc7Hn59QQa7VB1r4a0gm6RePeGGdt+FzmmtqJ87dnTIdixO10udBnmlCs1FwPNafNsEq0SRdz/PyeHYQ1ysLpk/T3OXqpXDt55v5fCB04E+7ndMWhvvMq01eWqlbUCfPLXS/udLnAZ5pfwgzykEpxLFsZouIPGkrkMDJ8d3o7rdpeqYw//nf6D2jTUJNzLHGw+R9I3LtNblnbPZ8cCemJRNxaQyLu+cbf8Po8RpkFdqAnIqRSwLDNhet7pk2nWUdOKYwz9RbptPT1Yb397cbpvW2neqjacP/i+O3bSdyVMrubxzdjjvTjg3f+zoUML1iUaDvFITUENNg23bhNpJ9YwEylN2yXTDsdPkGZHXjsunp6yNj0tr7aOTHR/cwMhI+DAaq4oG4LyPNRRNUM/0OEi3Cr7jVSmVH/ue7WfjbT384KbtXPfcPzHvvctiHq8qr2LNZf/A3dddRFNdddaHhtieClU+Rn3Lh6cvROXTXdXGtywN96FZO8DTp5aPB3iLVUVTLDI9DjIdOpNXagLY92x/TJ569IMyPnFiGTWBM3h+yo6ERU4vZpIxOfxDh6g4Y4T6lg+pnRVVIROVT19xyYqYnDwk3+xVClU0yY6D9Go2r0FeqQnArnbcjAif6FvKj/8+dw3OxnP4Tt0f48pEK8srx4N8XWUdqy9d7bgvoBSqaFo/eIKfTdpEo7zLITONb40s5fGxj3t66Lima5SaALyY9W7Zv4XFDy2mZWMLix9anLwjZLwUO02typrQqdD4jwyODDq8WNjlnbOpmBQbwoqqiqZ3E+sm/ZAZZe9SJjCj7F3WBf6DT5f91tNDx3Umr9QEkO2sN2V5oxtJykRTVtbYKPoqmu47qSb238kZcoqvBjbxuyVf9uxtNMgrNQFkWzueSRBOR0ZdJymuKpoEDpu7GuU9ra5RSqXnvI81cPX154/P3CdPreTq6893HSAzDcJuZdR1stg5NGkTj9se60xela4SPMszG9nMep3q6pMF4XTqv9OtrLGkfUSgn+SpZ5HO5FVpSnHykEpPur3s06r/7t1E++avsrbvIMFRg4CrNsoZHRHoJ3lqe+zZQd5e0IO8lWfcHOqs0pLOrPnKdds5aFMG2FRXTc/qRacvZHGwttNh58GaINs+t83dL1Uikh3krekaVZom4FmeuZZOL3unOu+E68lOxUoR5HOxTpDrFgOFoOkaVZom4FmefuJU551wPYubsdeLtfloMVAIGuRVaZqAZ3n6ya1L5lIdKI+5ZtvoLIubsddn3iZrMVDMNMir0uTDszz7+jfT07OQ7u0fpadnIX39pXu2/bULmtw1OsviZtze3E7nRzspk3AYK5MyOj/amXF1jdsUU6iri9cXtbF73nxeX9SW2UHmeaQ5eVW6fHSWZ1//ZvbsuZ2xsXDAeGffDF55eJiRE91MnlpVXDs1Xbp2QVPqfHYWp2Jt2b+FzW9sZsyEN3iNmTE2v7GZBfULMgr0jXXVtovF0SmmlKdd+ZBW1yiVBz09CxkcCvdWD/3hUvp33oAZPd1SoGJSWVqbk5T31TVWTt5K2VRM2UVV/VYkECIYqSY67+++Y98jv7GROdu70/8lPKLVNcozRb35pIAGh04HoyMvfyYmwMPpPuiFDvK9vb10d3cTCoWora2lra2NlpaWgo7JidfVNdZfHfds3cvhsaeoCj4CZcPA6V49G/uOITY/63QKlh9okFeuedKkaoKqqgyOz+RHTpxt+5xC90Hv7e2lq6uL4eFwYAuFQnRF8s1+DPSZ7MJNxUoxLX5oHX3Hh2MeGxwd5P0p5UwNjSb83OHz2njuth5fNkrThdc07H5yBxtu/iLfXtbBhpu/yO4ndxR6SHmVrEmVSq559i2UlYVzuxVnvGf7nEL3Qe/u7h4P8Jbh4WG6uwuXhkjG6+qaaE5/Dfy/PzMJp131N13O7hnXjt+krWMI9z3rTV+fbGmQd2n3kzvYtuH7fPjuETCGD989wrYN359QgT7XTaoykVWP8zwKNnRy/vnfoKqykekXPYaUn4p53A990EOhUFrXC629uZ21V6wlWBNEEFetENxy+mvgzUubCN51JxWNjSBCRWMjf2j5a0ZH/XsMoaZrXHrywZ8wcir2z+mRU0M8+eBPmLfw6gKNKr+mTJoSc6hD9PVCKLb0UbChk2BDJ1wJ++b3+64Pem1trW1Ar62tLcBo3ElnF24q0etNUyZNIVAWYHjs9F821l8Jtc3tMZU0227abvt6hU6/WTTIu/The++mdb0UidgtOTlfz7Vc9zjPJT/2QW9ra4vJyQMEAgHa2toKOKr8iJ8whE6FqJAK6irrCA2FYooM4osPrpvyT4x+kJgUKXT6zaJB3qUzz54WTtXEM4YNN3+RhctuKPkZfWjI4c95h+u55sf0UdHq3URL951cNHyAD2UKT5jL+WPtZb6urvGS3YRhxIxQXVHNk8ueHL9m99fj9oaf8YkTyzAjpyc7fki/WXKekxeRa0Rkr4i8ISKrc/1+ubJw2Q1UTLK/M0+U/LxfDnaw8vAG+z0eJX3QRC5EtWUWDFNMiM8Gfs2qtqYJEeDB/YTB7maw++xn+N3cxzM+kCXXcjqTF5Fy4AfAnwMHgN+JyOPGmNdy+b65YM3Sn3zwJ7Yz+omQn8/0YAcvxc+k4uV7PCUhi06QpcJtOabTzeD5KTv48d/7s8os1zP5S4E3jDH7jTGngAeBzhy/Z87MW3g1y3/wY3DIQZd6fj6X1Qxu2c2kLIUYT0nQtsyuyzH98tdsOnKdk28Cok9uOAB8LPoJIrIcWA5wzjnn5Hg43nDKz5959rQCjCa/vKxmyITTTEqQCXdQhGdqZzgcsDJx2jJb/02n2s3t9NfsVTOuYvFDi325EzzXQd5uyhuTSDXGbAA2QLh3TY7Hk9TuJ3eE0zHvvcuZZ09zXExduOwGtm34fkxJZcWkShYuuyGfw52QcrHLccLL01mjfudmAmN3M7hqxlVsfmNzYinvH5+hfdejBT9jONdB/gAwM+r7GUBidx8fsDY7WYHbWkwFEgJ9TH4+xQ1BecsP6wIlJ4tOkBNR/M1g8UOL7Ut533yY9lDkwBHrjGHI+z/XnHahFJEKYB/QBhwEfgf8tTHmVbvnF7IL5Yabv2ifgpk2PZyHVwV3fNdhPtj6FiMDg7w3KcSPpj3KnsYDvvrTWE08LRtbbCu9xBh634pLg+XojOGCdaE0xoyIyJeBrUA58COnAF9outkpM6GuLg7fdz8jfX1UBIPUr1qZk77ax3cdZuCR1zHDYwjCtFN1fPXIl6hbOIea5nrP308ptxxTiCOJjcwKsZid881QxpifAz/P9ftky+1iqtu8/USQzwMUPtj6FmZ4LOaaGR7jg61vUbNAg7wqHNsUojGseH8g8ckFWMzWBmURdpudohdTdz+5gx/83V/x8+9/e0I3KYt2+L77xwO8xQwOcvi++z1/r9EB+z4gTteVyhfb0uJZn6H9VFwKp0CL2drWICLZYmr8omy0ibAJyonTQQnpHKBg5dlHB4Yor6tkypJZtjPz8rpK24BeXueP/iBqYrOtzJl6kS8WszXIR5m38GrbYG3XgTLaRM3bVwSD9kehBYOufj46zw7hWfnAI68DJAT6KUtmxTwXQAJlTFkyK8PRK5VjPjljWNM1LqQK4hNhE5Sd+lUrEw5QkKoq6letdPXzyfLs8WoW1FN33ZzxmXt5XSV1183RfLxSKehM3gXHDpRM7E1Q1uJqptU16ebZaxbUa1BXKk0a5F2w2+EKUDn5TNr+ZjnzFl7tOrdcamo7OjKupEmWZ9cqJqW8oUE+CStwnzlQwWc+uoKXjv6afe88lxB00sktF2L8fr3xOOXZj8064Xr3sVIqOQ3yDuIDd9lJ4ZIpi1j0N/8zIVD6sYbbrzeeaNY44m9EW/7jqzk9arG3t5fu7m5CoRC1tbUT5mAMNTFpkHeQTuD2Yw23H288duzy7Lncfdzb2xtzxF0oFKKrqwtAA70qSRrkHaQTuP1Yw+3ljSff+fFctnLu7u6OOcMUYHh4mO7ubg3yqiRpkHeQTuD2Yw23VzeedLpzJpPO+kC6rZz3PdvP05vf5NjRISZPreTyztmOR6+FQg7n1DpcV6rYaZ28gylLZiGB2H88ToE7WQ337id3sOHmL/LtZR1suPmLeWuBYDf+obJT7F/wflqvY7cRzMqPu2WtD1g3HWt94Piuw7bPn7fwahYv/zJnTpsOIpw5bTqLl3/Z9qay79l+djywh2NHw6997OgQOx7Yw75n7Q8Xqa2tTeu6UsVOZ/IOnBYFnWafdrllr2bBmahZUM+Lh3dR/dtBpg2fxZGKo/yf+s08c+QV1u4fcd2a14v8eCbrA067j+M9vflNRk7FvvbIqTGe3vym7Wy+ra0tJicPEAgEaGtrc/OrKFV0NMgnke3mm2Sz4HyUAn79w2/T99G4PjKj4VNt3AZ5L/LjuVyYtmbwbq9beXetrlEThQb5HCp0j3qn81Cdrttxyo9fvfBG+tY95+qvHKf1gROjho239STNoacyeWqlbUCfPNV57aGlpUWDupowNCefQ06z3Xz1uvHiZHm7/Phftv89Z7wacJ1jt1sfGDGG1wZHx3PoD2x6jSvXbefc1Vu4ct12Htt10NX4Lu+cTcWk2NeumFTG5Z2zXf+OSpUyncnnkJcHfmdSxujVeajx+fG+dc8xOhw7e06WY49e3xgZGOLkaDjAHxwO99seOTXGH3/Vx8Ep4XEeHDjJmkdeBuDaBU1Jx2b9BeC2ukapiUaDfA55deB3pgu4difLe3EeaiY5dmt94wc3bbd9/MzYtVNODo9yz9a9KYM8hAO9BnWl7GmQzzG3VSLJZLOAa3uYQZayqcF3yqF/IIkHIR8aOJnZAJVS4zQnXwQKvYAbL509BPHscugjAr+pGkl4bmNddVbjBHhs18GMcv1KlQqdyReBXG7zd8NuR2nTdXMy6nBpl0OvuPgs/vDyHyGq20B1oJxbl8zNatyP7TrImkde5uTwKJCY68+2Udljuw5yz9a9HBo4SWNdNbcumesqvaRUPmmQLwJeLuCmy9pRam04sqphrr7+fM5bfWnarxe/gHzpX9zAvIXzqZlT63nAvGfr3vEAb7Fy/c3l72XVqCzVDUQpv9AgXwS8WsDNRLo7SpNJtoB87cKrPQ+OTjn9QwMns25UluwGokFe+YkG+SLhxQJuJtLdUZpMvncAN9ZVc9Am0DfWVWfdqCzZDUQpP9Eg7xOhrq6UZ6V6ddJTOjX3mewodZL2AnLvJui+E0IHoHYGtN0BLUtdv9+tS+bGpFTgdK7/9796yTagxzcqc8q7J7uBKOUnWl3jA6GuLvq+dgcjhw6BMYwcOkTf1+4gFMkRQ/qdHJ1YKZMP3z0CxoynTJy6Y3q5ozStHcC9m6DrKxB6GzDhz11fCV936doFTdx93UU01VUjQFNdNXdfdxHXLmiira2NQCAQ8/z4RmVW3v3gwEkMp/Puj+06yK1L5lIdKI/5eS8Wi5Xyms7kfeDwffdjBgdjrpnBQQ7fd//4bN6rk57STZkk21Ga7i7ctBaQu++E4biZ8vDJ8PU0ZvPXLmiyzZG7aVSWLO/es3rR+HO0ukb5mQZ5Hxjp60t53c0uUzfpnExq7u12lGayCzetBeTQAfvBOF3PQKpGZany7k43EKX8JKsgLyKfB9YC84BLjTE7ox5bA3wJGAW+YozZms17lbKKYDCcqrG5bkm1y9Ttwd1e1dxnuojqagG5dxNIGZjRxMdqZ6Q1zmxo3l2Vgmxz8q8A1wG/ib4oIvOBZcAFwDXAv4pIeeKPK4D6VSuRqqqYa1JVRf2qlePfp9plmiydE23hshuomBS7aJpJzX3OduFauXi7AB+oDi++5kk2eXfdaav8IquZvDFmN4CIxD/UCTxojBkCfi8ibwCXAk9n836lysq7p6quoULGd4WWnVFBbcfs8Vm626ZhXtXc52wXrl0uHkDKoeO7aeXjs2WlYtLNu+tGKeUnucrJNwHPRH1/IHItgYgsB5YDnHPOOTkajv/VdnQkBvWI+FQMkDBrT6dpmBc19znbheuUczdjeQ3wlkzy7rpRSvlJynSNiPxSRF6x+ehM9mM21xLbDALGmA3GmFZjTOv06dPdjntCcZOKyaZpWCbSOWw7LU459zzm4rOlG6WUn6ScyRtjPpnB6x4AZkZ9PwNIXFlUrrhJxaR78LgXcrILt+2OcE4+OmWT51x8tnTBVvlJrtI1jwM/FZHvAI3AHOC5HL1XSTu+63D47yKbv4PiUzHZHjzuC1ZKJoudrvmQrANlsp22SuVbtiWUnwG+B0wHtojIi8aYJcaYV0VkE/AaMALcbIxduYQ37FrhFtNJQU717VYu3i7A5zIVU3AtS30X1KOlWljNdMFWqVwQY2xT5QXR2tpqdu7cmfqJUeJb4UJ42/3V15/vOtC76RuTK3aLqhIooy6qX3sCgbOWzk05ay/2m59fXbluu206pqmuenwnrEV7zqt8EJHnjTGtdo8Vfe+aZK1w3XDTNyaXki2qOp6ZanAV4Hc8sGe8uZjVB37fs/2ejHsiswvwkLiwmqz3jVL5UvRBPp1WuKGuLl5f1MbuefN5fVHb+AzeqW9MPiRbVHU6M9XNWarZ3vyUvcd2HbQtHYPEhVWnUsq1j7+qG6VU3hR9kHdqeRt/3WnGbtdOAJz7yXgtWSDPpizSyz7w6rR7tu61rQUWGF9YtXa7Os34B04O6+xe5U3RB3m3rXCdZuyU23dbiO4bk0vJAnnNgnrqrpvDWHUFBjgxanh5eIyDcTN0O25vfnnXuwnuuxDW1oU/p9E62A+cat0N4UXX6BSNW9ZGKaVyoeiD/Hkfa+Dq688fD16Tp1baLro6zczN6CiDcTVG8X1jcskK5NaMvryukrrr5ozn3A+eGuMX7w3x+MAwT3w4wpsDw65y67Y3vwrD5ZM2FC7AetAjvtCcat2bItftUjRu6EYplSsl0Wr49enP88Al6+k/3k9DTQPTpq/gPNpjnuPU6fHdKfDTTwh//SvDtA9gpL6OP7n1trxV10Dy+vZMz1hN6AM/eZTLJ/0b59EdfoIVYCF/5Yoe9YgvpFQ18KmCdZnAmE2+RzdKqVwp+iC/Zf8W1j61lsHRcCqm73gfa59aC0B78+lAX79qJX1fuyMmZTNYEQ7wPReU03NB+Fqw5ky25THAp5JNbj2mD/x9F0Zm0FHyHWDz0CM+11LVwDvtdrXYBXjdKKVyqeiD/PoX1o8HeMvg6CC3/fY21jy5hoaaBlZcsoL2uE6PR8404wE+Wv9xf5UYenbGqh8CbO2MxBuNdb2IJGtaZjfTt1MuwpgxWjuvcq7og7xTUB4z4RRHzMw+qtPjiocW03c8MU/fUOOvzUKXd8623eyV9hmrfgiwJdCXJpX4mb7TVsMxY/j9unaHR5XyTtEvvLoJyoOjg6x/YX3MtRWXrKCqPPagjqryKlZcssLT8WXL7cJySm13hANqtHwH2Jal4Z7wtTMBCX/Oc4/4fLh2QRM9qxfx+3Xt4wuy8TQHr/Kl6IO8XbC2Ez/jb29uZ+0VawnWBBGEYE2QtVesjcnj+4FnrQn8EmBblsKqV2DtQPhziQX4eNmcLqWUF4q+dw2EF1/XvxCurhGR8VRNtGBNkG2f2+bFMIH89IVx6stz/mUNvPXKe4XpSdO7KfMOkdn8bBHT/jUq15L1rimJIB8tvtoGwmmYTGbpToHci6Zobmy8rcdVFU0u3tuWVecen1N38xdBNj+rlEqqpBuUxfMqDZOswVe++sK4bUGQt540yercc/mzSqmMFX11jZ325vasc+vJAnm++sI4lU/m471tZVOGaVfZ4/ZnlVIZK7mZvBt23SjjJQvk+eoLY9eawEleetJkev5q7ybsj/118bNKqayUXJDfsn8Lix9aTMvGFhY/tJgt+7fEPO62f3yyQO62KVq27MonL7yqMS/vbSvTMszuO7E/x11KqkZeKT8qqXSNmxYHTt0o/3DPv3DL0PfG+9986Yp/YHBble0mpIS+MDmscIlpTRARnF1XmBOfMj1/1TElY9wt2Pq8Iie6eqa2OoAIDJwY1koa5QslVV2z2GEXa3T55O5588HmdzbAF9acvudVlVdxS91dDD51ZtEcn+d0VmzB2fXNgXCt/qpXnH+uCCpy4s97jVcdKOfu6y7SQK9yKll1TUnN5J1aHERfT9aNMtrg6CA/HPwO2/7Fu9r6XIo/K3Z0YCh8CDipjwrMuUzbGRRB18pUrYWtXvEa5FWhlFSQb6hpSNmPJlk3yni5aFYWXXtfWVOOIAweH8n6L4VkZ8UWPMi7TfPEp2aKoCLHTR947RWvCqmkgvyKS1bYboSK7kdTG9eNsiIYZNMVg/TM+SDh9bxuVha/iWro+OkZoFWHD2QU6JOdFesLLUuTz77jUzOhtwlX5NikE31UkZOqtbD1HKUKpaSqa9xuhKrt6GDO9m7m7X6NOdu7+fjf3pa0WZmbkks37Grvo2WzqSmbQ799wS41gyGh9NJnXSvtetNE0z41qtBKaiYPmW2Eam9up2bH8wQ2bKIuNMpAbTnDyzv4RHP7eMmlld6xSi6BtE+PcrNhKdNNTVOWzIrJyYP7Q799IVkFTu1M31bXxLcW1uoa5TclF+QzEerqouF7j2IGw+mTqaFR5HuPEqpf4Fhyefi++9MO8m52sGa6qcnKu/uyusYNx373KSpwfCDZISJKFZoGeZxr5628vR2n68nYHQASLdtNTcnOivU9uwocgFPHw/l6H83elSomJZWTz1SyQF4RDNo+5nQ9mfgdrJU15VTVhO+zGR8GUiqsfvfVU2OvnzwaDv69mwozLqWKnM7kca6drwgGbUsupaqK+lUrM3ovux2sKqJlaXgB9uTR2Os+q41XqphkNZMXkXtEZI+I9IrIoyJSF/XYGhF5Q0T2isiSrEeapWQVMvWrViJVsdU1ViCv7eggeNedVDQ2ggjD9XVs/NQZLDx6u21vHJWB3k3hXbFr64qiNl6pYpJtuuYJ4EJjTAuwD1gDICLzgWXABcA1wL+KiHOdWY6lakoWH8grGhsJ3nXn+MKqVXK5f8s9fGn5CP815wMMZrw3jgb6LFj18aG3sW9iFuGj2niliolnvWtE5DPA54wx14vIGgBjzN2Rx7YCa40xTyd7DS9OhrLz+qI2+3RMYyNztne7fh03vXFUmpz62kTzWb8apfwmXydD/S3wi8jXTUD0/7kHItfsBrdcRHaKyM4jR454OJzTvKqQcdMbR6UpVRpGyk/n5HXxVam0pQzyIvJLEXnF5qMz6jm3AyPAA9Ylm5ey/ZPBGLPBGNNqjGmdPn16Jr9Dgvj8e3ltre3z0q2QcWpz4HX7gwnFKQ1TPTU8gzeR1g+ht7XKRqkMpAzyxphPGmMutPnYDCAiNwKfAq43p3M/B4CZUS8zA0jMl+SAXf599NgxJBCIeV4mFTIrLlmRtP2ByoDTQSSgZ8Iq5YFsq2uuAb4KfNoYcyLqoceBZSJSKSLnAnOA57J5L7fsNjYxMgI1NQkLq+/U/ykbb+vhBzdtZ+NtPex7NjbtEv8XwcdfHfPkkHAVxaqPr50JSPhzx3fh5Pv2z9cqG6XSktXCq4i8AVQC70UuPWOMuSny2O2E8/QjwEpjzC/sX+U0LxZenQ4FQYR5u18b/za+IySEd5xaG5Lie9ZAePYfXXWjcijTg0aUmoBytvBqjPmoMWamMebiyMdNUY99wxgz2xgz102A94rbHap2HSGju0Ama3WQTKozZpVLmZ4nq5SKUXJtDZJtbIrm1CjMup5JRY51xmzf8T6to8+WUxpHyyiVSkvJtTWwOxTE2rkazakjpNVXxqnVgThU6gCsf2F9zIElED5GcP0L6zVvn4lUB40opVIquZk8JB4KYpdDv7xzNhWTYn/96C6Q9atWQoXNPfD4ccdDQ7SOXinlNyUZ5N2I7wgZ3wWytqOD8smTE37ODA875uW1jl4p5Tcll65JR6qOkKOhkO11p7y8mzNmlVIqnybsTN6NdHvJR58xC1AmZeM5eV18VUoVwoQI8pkexO22Uidae3P7+M7YMRMu0dQqG6VUoZR8kE/VZjiZVC2InSSrslFKqXwq+Zx8tgdx13Z0pL3DVatslFJ+UfIzeS8P4nZLq2yUUn5R8kHey4O43dJulUopvyj5IJ/J4mm2oqtstFulUqqQSj4n77bNgdfam9s1qCulCq7kgzxktniqlFKloOTTNUopNZFpkFdKqRKmQV4ppUqYBnmllCphGuSVUqqEZXWQt9dE5Ajwh0KPA5gGvFvoQaShmMZbTGMFHW+uFdN4/TzWPzHGTLd7wFdB3i9EZKfTyed+VEzjLaaxgo4314ppvMU01miarlFKqRKmQV4ppUqYBnl7Gwo9gDQV03iLaayg4821YhpvMY11nObklVKqhOlMXimlSpgGeaWUKmEa5CNE5C4R6RWRF0Vkm4g0Rj22RkTeEJG9IrKkkOO0iMg9IrInMuZHRaQu6jE/jvfzIvKqiIyJSGvcY74bL4CIXBMZ0xsisrrQ44knIj8SkcMi8krUtaki8oSIvB75fFYhx2gRkZkiskNEdkf+O1gRue7X8VaJyHMi8lJkvF+PXPfleJMyxuhHeF1iStTXXwH+PfL1fOAloBI4F3gTKPfBeBcDFZGvvwl80+fjnQfMBX4FtEZd9+t4yyNjaQYmRcY4v9DjihvjVcAlwCtR174FrI58vdr676LQH0AQuCTy9ZnAvsi/e7+OV4DJka8DwLPAZX4db7IPnclHGGM+iPq2BrBWpDuBB40xQ8aY3wNvAJfme3zxjDHbjDEjkW+fAWZEvvbreHcbY/baPOTL8RIewxvGmP3GmFPAg4TH6hvGmN8AR+MudwIbI19vBK7N55icGGP6jDEvRL7+ENgNNOHf8RpjzLHIt4HIh8Gn401Gg3wUEfmGiLwNXA/cEbncBLwd9bQDkWt+8rfALyJfF8N4o/l1vH4dVyofMcb0QTiwAvUFHk8CEZkFLCA8O/bteEWkXEReBA4DTxhjfD1eJxMqyIvIL0XkFZuPTgBjzO3GmJnAA8CXrR+zeam81J2mGm/kObcDI4TH7Pvx2v2YzTU/1PX6dVxFTUQmAw8DK+P+evYdY8yoMeZiwn8lXyoiFxZ4SBmZEMf/WYwxn3T51J8CW4B/JjyDmxn12AzgkMdDs5VqvCJyI/ApoM1EkoT4eLwOCjbeFPw6rlTeEZGgMaZPRIKEZ6G+ICIBwgH+AWPMI5HLvh2vxRgzICK/Aq6hCMYbb0LN5JMRkTlR334a2BP5+nFgmYhUisi5wBzguXyPL56IXAN8Ffi0MeZE1EO+HG8Sfh3v74A5InKuiEwClhEeq989DtwY+fpGYHMBxzJORAT4IbDbGPOdqIf8Ot7pVsWaiFQDnyQcE3w53qQKvfLrlw/CM4xXgF6gC2iKeux2wpUWe4G/KPRYI2N6g3DO+MXIx7/7fLyfITw7HgLeAbb6ebyRcf0l4SqQN4HbCz0em/H9J9AHDEf+2X4JOBvoBl6PfJ5a6HFGxvpxwumu3qj/Zv/Sx+NtAXZFxvsKcEfkui/Hm+xD2xoopVQJ03SNUkqVMA3ySilVwjTIK6VUCdMgr5RSJUyDvFJKlTAN8kopVcI0yCulVAn7/2iyJ1q1KnxsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#JUST TRY DELETE LATER\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embeddings_unseen_arr_trial = embeddings_unseen_arr[0:180,:]\n",
    "labels_unseen_arr_trial = labels_unseen_arr[0:180]\n",
    "\n",
    "#pca = PCA(n_components=2)\n",
    "#pca.fit(embeddings_unseen_arr)\n",
    "#print(pca.explained_variance_ratio_)\n",
    "\n",
    "#embeddings_reduced = pca.transform(embeddings_unseen_arr)\n",
    "#print(embeddings_reduced)\n",
    "\n",
    "u_labels = np.unique(labels_unseen_arr_trial)\n",
    "print(u_labels)\n",
    "\n",
    "embeddings_reduced = TSNE(n_components=2, learning_rate='auto',init='random', perplexity = 10.0).fit_transform(embeddings_unseen_arr_trial)\n",
    "\n",
    "for i in u_labels:\n",
    "    \n",
    "    plt.scatter(embeddings_reduced[labels_unseen_arr_trial == i , 0] , embeddings_reduced[labels_unseen_arr_trial == i , 1] , label = i)\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f01ae5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[244 381 381 ... 187 740 297]\n",
      "0.9980117577406192\n",
      "0.31992\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=1000, random_state=36).fit(embeddings_seen_arr)\n",
    "labels_predicted = kmeans.predict(embeddings_unseen_arr)\n",
    "print(labels_predicted)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.rand_score(labels_unseen_arr, labels_predicted))\n",
    "\n",
    "truth = labels_unseen_arr\n",
    "pred=labels_predicted\n",
    "print(np.sum( get_y_preds(pred, truth, 1000)[0] == truth )/len(truth) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98d54fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37500, 2048)\n",
      "(12500, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_seen_arr.shape)\n",
    "print(embeddings_unseen_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8382c4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34444cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from geopy.geocoders import Nominatim\n",
    "import re\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sklearn\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import math\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb4d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import signal\n",
    "import sys\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import resnet\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "\n",
    "import glob\n",
    "from geopy.geocoders import Nominatim\n",
    "import re\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import math\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True   #OTHERWISE TRUNCATED IMAGE FILE ERROR SOMEWHERE IN ENUMERATE(DATALOADER)!!!!\n",
    "\n",
    "import resnet\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from munkres import Munkres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37120c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_preds(cluster_assignments, y_true, n_clusters):\n",
    "    '''\n",
    "    Computes the predicted labels, where label assignments now\n",
    "    correspond to the actual labels in y_true (as estimated by Munkres)\n",
    "\n",
    "    cluster_assignments:    array of labels, outputted by kmeans\n",
    "    y_true:                 true labels\n",
    "    n_clusters:             number of clusters in the dataset\n",
    "\n",
    "    returns:    a tuple containing the accuracy and confusion matrix,\n",
    "                in that order\n",
    "    '''\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_true, cluster_assignments, labels=None)\n",
    "    # compute accuracy based on optimal 1:1 assignment of clusters to labels\n",
    "    cost_matrix = calculate_cost_matrix(confusion_matrix, n_clusters)\n",
    "    indices = Munkres().compute(cost_matrix)\n",
    "    kmeans_to_true_cluster_labels = get_cluster_labels_from_indices(indices)\n",
    "    y_pred = kmeans_to_true_cluster_labels[cluster_assignments]\n",
    "    return y_pred, confusion_matrix \n",
    "\n",
    "def calculate_cost_matrix(C, n_clusters):\n",
    "    cost_matrix = np.zeros((n_clusters, n_clusters))\n",
    "\n",
    "    # cost_matrix[i,j] will be the cost of assigning cluster i to label j\n",
    "    for j in range(n_clusters):\n",
    "        s = np.sum(C[:,j]) # number of examples in cluster i\n",
    "        for i in range(n_clusters):\n",
    "            t = C[i,j]\n",
    "            cost_matrix[j,i] = s-t\n",
    "    return cost_matrix\n",
    "\n",
    "def get_cluster_labels_from_indices(indices):\n",
    "    n_clusters = len(indices)\n",
    "    clusterLabels = np.zeros(n_clusters)\n",
    "    for i in range(n_clusters):\n",
    "        clusterLabels[i] = indices[i][1]\n",
    "    return clusterLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4290e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee23f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transforms = torchvision.transforms.Compose([torchvision.transforms.RandomResizedCrop(224), torchvision.transforms.RandomHorizontalFlip(), torchvision.transforms.ToTensor(),normalize])\n",
    "\n",
    "dataset = datasets.ImageFolder('./ImageNet/ILSVRC/Data/CLS-LOC/val' , transforms)\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset, batch_size = batch_size, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ba3e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12268863488, 12806062080)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.current_device()\n",
    "torch.cuda.set_device(3)\n",
    "print(torch.cuda.mem_get_info(torch.cuda.current_device()))\n",
    "device = torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e44f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_model_pretrained = torchvision.models.resnet50(pretrained=True)\n",
    "torch.save(supervised_model_pretrained.state_dict(), 'resnet50_imagenet_pretrained_supervised.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fba5a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone, embedding = resnet.__dict__['resnet50'](zero_init_residual=True)\n",
    "state_dict = torch.load('resnet50_imagenet_pretrained_supervised.pth', map_location=\"cpu\")\n",
    "if \"model\" in state_dict:\n",
    "    state_dict = state_dict[\"model\"]\n",
    "    state_dict = {key.replace(\"module.backbone.\", \"\"): value for (key, value) in state_dict.items()}\n",
    "backbone.load_state_dict(state_dict, strict=False)\n",
    "backbone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7052870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding)\n",
    "backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f1c147a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n",
      "22000\n",
      "22500\n",
      "23000\n",
      "23500\n",
      "24000\n",
      "24500\n",
      "25000\n",
      "25500\n",
      "26000\n",
      "26500\n",
      "27000\n",
      "27500\n",
      "28000\n",
      "28500\n",
      "29000\n",
      "29500\n",
      "30000\n",
      "30500\n",
      "31000\n",
      "31500\n",
      "32000\n",
      "32500\n",
      "33000\n",
      "33500\n",
      "34000\n",
      "34500\n",
      "35000\n",
      "35500\n",
      "36000\n",
      "36500\n",
      "37000\n",
      "37500\n",
      "38000\n",
      "38500\n",
      "39000\n",
      "39500\n",
      "40000\n",
      "40500\n",
      "41000\n",
      "41500\n",
      "42000\n",
      "42500\n",
      "43000\n",
      "43500\n",
      "44000\n",
      "44500\n",
      "45000\n",
      "45500\n",
      "46000\n",
      "46500\n",
      "47000\n",
      "47500\n",
      "48000\n",
      "48500\n",
      "49000\n",
      "49500\n"
     ]
    }
   ],
   "source": [
    "labels_list = []\n",
    "embeddings_list = []\n",
    "\n",
    "labels_unseen_list = []\n",
    "embeddings_unseen_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        \n",
    "        if i == 50000:\n",
    "            break\n",
    "            \n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        if i%4 == 0:\n",
    "            \n",
    "            embedding = backbone(inputs.to(device))\n",
    "            embeddings_unseen_list.append(embedding)\n",
    "            labels_unseen_list.append(labels)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            embedding = backbone(inputs.to(device))\n",
    "            embeddings_list.append(embedding)\n",
    "            labels_list.append(labels)\n",
    "            \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d3c59ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10350746 1.23026168 0.0622509  ... 0.08556541 0.34479108 0.19806416]\n",
      " [0.16166294 0.68360037 0.26697323 ... 0.47139898 0.9612242  0.51035392]\n",
      " [0.15703374 0.65859485 0.07245462 ... 0.07701835 1.09075344 0.25835705]\n",
      " ...\n",
      " [0.07042772 0.16572952 0.70349813 ... 0.11476289 0.307917   0.36962593]\n",
      " [0.54724646 0.3867752  0.44822991 ... 0.48657951 0.2726247  0.15543227]\n",
      " [0.05331063 1.06046677 1.04001153 ... 0.36516449 0.26445934 0.59484512]]\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "  84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n",
      " 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n",
      " 126. 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139.\n",
      " 140. 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153.\n",
      " 154. 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167.\n",
      " 168. 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181.\n",
      " 182. 183. 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195.\n",
      " 196. 197. 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209.\n",
      " 210. 211. 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223.\n",
      " 224. 225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237.\n",
      " 238. 239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251.\n",
      " 252. 253. 254. 255. 256. 257. 258. 259. 260. 261. 262. 263. 264. 265.\n",
      " 266. 267. 268. 269. 270. 271. 272. 273. 274. 275. 276. 277. 278. 279.\n",
      " 280. 281. 282. 283. 284. 285. 286. 287. 288. 289. 290. 291. 292. 293.\n",
      " 294. 295. 296. 297. 298. 299. 300. 301. 302. 303. 304. 305. 306. 307.\n",
      " 308. 309. 310. 311. 312. 313. 314. 315. 316. 317. 318. 319. 320. 321.\n",
      " 322. 323. 324. 325. 326. 327. 328. 329. 330. 331. 332. 333. 334. 335.\n",
      " 336. 337. 338. 339. 340. 341. 342. 343. 344. 345. 346. 347. 348. 349.\n",
      " 350. 351. 352. 353. 354. 355. 356. 357. 358. 359. 360. 361. 362. 363.\n",
      " 364. 365. 366. 367. 368. 369. 370. 371. 372. 373. 374. 375. 376. 377.\n",
      " 378. 379. 380. 381. 382. 383. 384. 385. 386. 387. 388. 389. 390. 391.\n",
      " 392. 393. 394. 395. 396. 397. 398. 399. 400. 401. 402. 403. 404. 405.\n",
      " 406. 407. 408. 409. 410. 411. 412. 413. 414. 415. 416. 417. 418. 419.\n",
      " 420. 421. 422. 423. 424. 425. 426. 427. 428. 429. 430. 431. 432. 433.\n",
      " 434. 435. 436. 437. 438. 439. 440. 441. 442. 443. 444. 445. 446. 447.\n",
      " 448. 449. 450. 451. 452. 453. 454. 455. 456. 457. 458. 459. 460. 461.\n",
      " 462. 463. 464. 465. 466. 467. 468. 469. 470. 471. 472. 473. 474. 475.\n",
      " 476. 477. 478. 479. 480. 481. 482. 483. 484. 485. 486. 487. 488. 489.\n",
      " 490. 491. 492. 493. 494. 495. 496. 497. 498. 499. 500. 501. 502. 503.\n",
      " 504. 505. 506. 507. 508. 509. 510. 511. 512. 513. 514. 515. 516. 517.\n",
      " 518. 519. 520. 521. 522. 523. 524. 525. 526. 527. 528. 529. 530. 531.\n",
      " 532. 533. 534. 535. 536. 537. 538. 539. 540. 541. 542. 543. 544. 545.\n",
      " 546. 547. 548. 549. 550. 551. 552. 553. 554. 555. 556. 557. 558. 559.\n",
      " 560. 561. 562. 563. 564. 565. 566. 567. 568. 569. 570. 571. 572. 573.\n",
      " 574. 575. 576. 577. 578. 579. 580. 581. 582. 583. 584. 585. 586. 587.\n",
      " 588. 589. 590. 591. 592. 593. 594. 595. 596. 597. 598. 599. 600. 601.\n",
      " 602. 603. 604. 605. 606. 607. 608. 609. 610. 611. 612. 613. 614. 615.\n",
      " 616. 617. 618. 619. 620. 621. 622. 623. 624. 625. 626. 627. 628. 629.\n",
      " 630. 631. 632. 633. 634. 635. 636. 637. 638. 639. 640. 641. 642. 643.\n",
      " 644. 645. 646. 647. 648. 649. 650. 651. 652. 653. 654. 655. 656. 657.\n",
      " 658. 659. 660. 661. 662. 663. 664. 665. 666. 667. 668. 669. 670. 671.\n",
      " 672. 673. 674. 675. 676. 677. 678. 679. 680. 681. 682. 683. 684. 685.\n",
      " 686. 687. 688. 689. 690. 691. 692. 693. 694. 695. 696. 697. 698. 699.\n",
      " 700. 701. 702. 703. 704. 705. 706. 707. 708. 709. 710. 711. 712. 713.\n",
      " 714. 715. 716. 717. 718. 719. 720. 721. 722. 723. 724. 725. 726. 727.\n",
      " 728. 729. 730. 731. 732. 733. 734. 735. 736. 737. 738. 739. 740. 741.\n",
      " 742. 743. 744. 745. 746. 747. 748. 749. 750. 751. 752. 753. 754. 755.\n",
      " 756. 757. 758. 759. 760. 761. 762. 763. 764. 765. 766. 767. 768. 769.\n",
      " 770. 771. 772. 773. 774. 775. 776. 777. 778. 779. 780. 781. 782. 783.\n",
      " 784. 785. 786. 787. 788. 789. 790. 791. 792. 793. 794. 795. 796. 797.\n",
      " 798. 799. 800. 801. 802. 803. 804. 805. 806. 807. 808. 809. 810. 811.\n",
      " 812. 813. 814. 815. 816. 817. 818. 819. 820. 821. 822. 823. 824. 825.\n",
      " 826. 827. 828. 829. 830. 831. 832. 833. 834. 835. 836. 837. 838. 839.\n",
      " 840. 841. 842. 843. 844. 845. 846. 847. 848. 849. 850. 851. 852. 853.\n",
      " 854. 855. 856. 857. 858. 859. 860. 861. 862. 863. 864. 865. 866. 867.\n",
      " 868. 869. 870. 871. 872. 873. 874. 875. 876. 877. 878. 879. 880. 881.\n",
      " 882. 883. 884. 885. 886. 887. 888. 889. 890. 891. 892. 893. 894. 895.\n",
      " 896. 897. 898. 899. 900. 901. 902. 903. 904. 905. 906. 907. 908. 909.\n",
      " 910. 911. 912. 913. 914. 915. 916. 917. 918. 919. 920. 921. 922. 923.\n",
      " 924. 925. 926. 927. 928. 929. 930. 931. 932. 933. 934. 935. 936. 937.\n",
      " 938. 939. 940. 941. 942. 943. 944. 945. 946. 947. 948. 949. 950. 951.\n",
      " 952. 953. 954. 955. 956. 957. 958. 959. 960. 961. 962. 963. 964. 965.\n",
      " 966. 967. 968. 969. 970. 971. 972. 973. 974. 975. 976. 977. 978. 979.\n",
      " 980. 981. 982. 983. 984. 985. 986. 987. 988. 989. 990. 991. 992. 993.\n",
      " 994. 995. 996. 997. 998. 999.]\n",
      "[[0.2193263  0.16946872 0.14229542 ... 0.40691325 0.67335683 0.37439653]\n",
      " [0.21950282 0.00754056 0.04291112 ... 0.08069811 0.3115949  0.39966792]\n",
      " [0.32337454 0.49473104 0.18866198 ... 0.03412032 0.40412471 0.21802548]\n",
      " ...\n",
      " [0.07619379 0.57904673 0.23704325 ... 0.06543512 0.         0.53995687]\n",
      " [0.04536218 0.63976812 0.49095428 ... 0.0426586  0.57608223 0.83113158]\n",
      " [0.187852   0.21328241 0.74516881 ... 0.25959876 0.63180119 0.33039364]]\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "  84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n",
      " 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n",
      " 126. 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139.\n",
      " 140. 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153.\n",
      " 154. 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167.\n",
      " 168. 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181.\n",
      " 182. 183. 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195.\n",
      " 196. 197. 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209.\n",
      " 210. 211. 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223.\n",
      " 224. 225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237.\n",
      " 238. 239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251.\n",
      " 252. 253. 254. 255. 256. 257. 258. 259. 260. 261. 262. 263. 264. 265.\n",
      " 266. 267. 268. 269. 270. 271. 272. 273. 274. 275. 276. 277. 278. 279.\n",
      " 280. 281. 282. 283. 284. 285. 286. 287. 288. 289. 290. 291. 292. 293.\n",
      " 294. 295. 296. 297. 298. 299. 300. 301. 302. 303. 304. 305. 306. 307.\n",
      " 308. 309. 310. 311. 312. 313. 314. 315. 316. 317. 318. 319. 320. 321.\n",
      " 322. 323. 324. 325. 326. 327. 328. 329. 330. 331. 332. 333. 334. 335.\n",
      " 336. 337. 338. 339. 340. 341. 342. 343. 344. 345. 346. 347. 348. 349.\n",
      " 350. 351. 352. 353. 354. 355. 356. 357. 358. 359. 360. 361. 362. 363.\n",
      " 364. 365. 366. 367. 368. 369. 370. 371. 372. 373. 374. 375. 376. 377.\n",
      " 378. 379. 380. 381. 382. 383. 384. 385. 386. 387. 388. 389. 390. 391.\n",
      " 392. 393. 394. 395. 396. 397. 398. 399. 400. 401. 402. 403. 404. 405.\n",
      " 406. 407. 408. 409. 410. 411. 412. 413. 414. 415. 416. 417. 418. 419.\n",
      " 420. 421. 422. 423. 424. 425. 426. 427. 428. 429. 430. 431. 432. 433.\n",
      " 434. 435. 436. 437. 438. 439. 440. 441. 442. 443. 444. 445. 446. 447.\n",
      " 448. 449. 450. 451. 452. 453. 454. 455. 456. 457. 458. 459. 460. 461.\n",
      " 462. 463. 464. 465. 466. 467. 468. 469. 470. 471. 472. 473. 474. 475.\n",
      " 476. 477. 478. 479. 480. 481. 482. 483. 484. 485. 486. 487. 488. 489.\n",
      " 490. 491. 492. 493. 494. 495. 496. 497. 498. 499. 500. 501. 502. 503.\n",
      " 504. 505. 506. 507. 508. 509. 510. 511. 512. 513. 514. 515. 516. 517.\n",
      " 518. 519. 520. 521. 522. 523. 524. 525. 526. 527. 528. 529. 530. 531.\n",
      " 532. 533. 534. 535. 536. 537. 538. 539. 540. 541. 542. 543. 544. 545.\n",
      " 546. 547. 548. 549. 550. 551. 552. 553. 554. 555. 556. 557. 558. 559.\n",
      " 560. 561. 562. 563. 564. 565. 566. 567. 568. 569. 570. 571. 572. 573.\n",
      " 574. 575. 576. 577. 578. 579. 580. 581. 582. 583. 584. 585. 586. 587.\n",
      " 588. 589. 590. 591. 592. 593. 594. 595. 596. 597. 598. 599. 600. 601.\n",
      " 602. 603. 604. 605. 606. 607. 608. 609. 610. 611. 612. 613. 614. 615.\n",
      " 616. 617. 618. 619. 620. 621. 622. 623. 624. 625. 626. 627. 628. 629.\n",
      " 630. 631. 632. 633. 634. 635. 636. 637. 638. 639. 640. 641. 642. 643.\n",
      " 644. 645. 646. 647. 648. 649. 650. 651. 652. 653. 654. 655. 656. 657.\n",
      " 658. 659. 660. 661. 662. 663. 664. 665. 666. 667. 668. 669. 670. 671.\n",
      " 672. 673. 674. 675. 676. 677. 678. 679. 680. 681. 682. 683. 684. 685.\n",
      " 686. 687. 688. 689. 690. 691. 692. 693. 694. 695. 696. 697. 698. 699.\n",
      " 700. 701. 702. 703. 704. 705. 706. 707. 708. 709. 710. 711. 712. 713.\n",
      " 714. 715. 716. 717. 718. 719. 720. 721. 722. 723. 724. 725. 726. 727.\n",
      " 728. 729. 730. 731. 732. 733. 734. 735. 736. 737. 738. 739. 740. 741.\n",
      " 742. 743. 744. 745. 746. 747. 748. 749. 750. 751. 752. 753. 754. 755.\n",
      " 756. 757. 758. 759. 760. 761. 762. 763. 764. 765. 766. 767. 768. 769.\n",
      " 770. 771. 772. 773. 774. 775. 776. 777. 778. 779. 780. 781. 782. 783.\n",
      " 784. 785. 786. 787. 788. 789. 790. 791. 792. 793. 794. 795. 796. 797.\n",
      " 798. 799. 800. 801. 802. 803. 804. 805. 806. 807. 808. 809. 810. 811.\n",
      " 812. 813. 814. 815. 816. 817. 818. 819. 820. 821. 822. 823. 824. 825.\n",
      " 826. 827. 828. 829. 830. 831. 832. 833. 834. 835. 836. 837. 838. 839.\n",
      " 840. 841. 842. 843. 844. 845. 846. 847. 848. 849. 850. 851. 852. 853.\n",
      " 854. 855. 856. 857. 858. 859. 860. 861. 862. 863. 864. 865. 866. 867.\n",
      " 868. 869. 870. 871. 872. 873. 874. 875. 876. 877. 878. 879. 880. 881.\n",
      " 882. 883. 884. 885. 886. 887. 888. 889. 890. 891. 892. 893. 894. 895.\n",
      " 896. 897. 898. 899. 900. 901. 902. 903. 904. 905. 906. 907. 908. 909.\n",
      " 910. 911. 912. 913. 914. 915. 916. 917. 918. 919. 920. 921. 922. 923.\n",
      " 924. 925. 926. 927. 928. 929. 930. 931. 932. 933. 934. 935. 936. 937.\n",
      " 938. 939. 940. 941. 942. 943. 944. 945. 946. 947. 948. 949. 950. 951.\n",
      " 952. 953. 954. 955. 956. 957. 958. 959. 960. 961. 962. 963. 964. 965.\n",
      " 966. 967. 968. 969. 970. 971. 972. 973. 974. 975. 976. 977. 978. 979.\n",
      " 980. 981. 982. 983. 984. 985. 986. 987. 988. 989. 990. 991. 992. 993.\n",
      " 994. 995. 996. 997. 998. 999.]\n"
     ]
    }
   ],
   "source": [
    "embeddings_seen_arr = np.zeros((int(3*len(dataloader)/4), 2048))\n",
    "counter = 0\n",
    "for embedding in embeddings_list:\n",
    "    embeddings_seen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "\n",
    "print(embeddings_seen_arr)\n",
    "labels_seen_arr = np.zeros(int(3*len(dataloader)/4))\n",
    "counter = 0\n",
    "for i in labels_list:\n",
    "    labels_seen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(np.unique(labels_seen_arr))\n",
    "\n",
    "embeddings_unseen_arr = np.zeros((int(len(dataloader)/4), 2048))\n",
    "counter = 0\n",
    "for embedding in embeddings_unseen_list:\n",
    "    embeddings_unseen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "\n",
    "print(embeddings_unseen_arr)\n",
    "labels_unseen_arr = np.zeros(int(len(dataloader)/4))\n",
    "counter = 0\n",
    "for i in labels_unseen_list:\n",
    "    labels_unseen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(np.unique(labels_unseen_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4645602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#JUST TRY DELETE LATER\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embeddings_unseen_arr_trial = embeddings_unseen_arr[0:180,:]\n",
    "labels_unseen_arr_trial = labels_unseen_arr[0:180]\n",
    "\n",
    "#pca = PCA(n_components=2)\n",
    "#pca.fit(embeddings_unseen_arr)\n",
    "#print(pca.explained_variance_ratio_)\n",
    "\n",
    "#embeddings_reduced = pca.transform(embeddings_unseen_arr)\n",
    "#print(embeddings_reduced)\n",
    "\n",
    "u_labels = np.unique(labels_unseen_arr_trial)\n",
    "print(u_labels)\n",
    "\n",
    "embeddings_reduced = TSNE(n_components=2, learning_rate='auto',init='random', perplexity = 10.0).fit_transform(embeddings_unseen_arr_trial)\n",
    "\n",
    "for i in u_labels:\n",
    "    \n",
    "    plt.scatter(embeddings_reduced[labels_unseen_arr_trial == i , 0] , embeddings_reduced[labels_unseen_arr_trial == i , 1] , label = i)\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9146f3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53272\n",
      "Accuracy: 0.53944\n",
      "Accuracy: 0.55976\n",
      "Accuracy: 0.57976\n",
      "Accuracy: 0.58528\n",
      "Accuracy: 0.5816\n",
      "Accuracy: 0.58032\n",
      "Accuracy: 0.57672\n",
      "Accuracy: 0.53856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbours = [1, 3, 5, 10, 20, 30, 40, 50, 200]\n",
    "\n",
    "for k in n_neighbours:\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(embeddings_seen_arr, labels_seen_arr)\n",
    "    labels_predicted = knn.predict(embeddings_unseen_arr)\n",
    "\n",
    "    #print('Accuracy' + str(k) + ':', np.sum(labels_unseen_arr == labels_predicted)/len(labels_unseen_arr))\n",
    "    print('Accuracy:', knn.score(embeddings_unseen_arr, labels_unseen_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cd153ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[896   6   6 ... 213 286 750]\n",
      "0.9985277926234098\n",
      "0.48368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=1000, random_state=0).fit(embeddings_seen_arr)\n",
    "labels_predicted = kmeans.predict(embeddings_unseen_arr)\n",
    "print(labels_predicted)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.rand_score(labels_unseen_arr, labels_predicted))\n",
    "\n",
    "truth = labels_unseen_arr\n",
    "pred=labels_predicted\n",
    "print(np.sum( get_y_preds(pred, truth, 1000)[0] == truth )/len(truth) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfe03937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /local/home/bsoyuer/.cache/torch/hub/facebookresearch_vicreg_main\n"
     ]
    }
   ],
   "source": [
    "vicreg_model_pretrained = torch.hub.load('facebookresearch/vicreg:main', 'resnet50')\n",
    "torch.save(vicreg_model_pretrained.state_dict(), 'resnet50_imagenet_pretrained_vicreg.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de8edc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone, embedding = resnet.__dict__['resnet50'](zero_init_residual=True)\n",
    "state_dict = torch.load('resnet50_imagenet_pretrained_vicreg.pth', map_location=\"cpu\")\n",
    "if \"model\" in state_dict:\n",
    "    state_dict = state_dict[\"model\"]\n",
    "    state_dict = {key.replace(\"module.backbone.\", \"\"): value for (key, value) in state_dict.items()}\n",
    "backbone.load_state_dict(state_dict, strict=False)\n",
    "backbone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e55c550d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding)\n",
    "backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "297bb401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n",
      "22000\n",
      "22500\n",
      "23000\n",
      "23500\n",
      "24000\n",
      "24500\n",
      "25000\n",
      "25500\n",
      "26000\n",
      "26500\n",
      "27000\n",
      "27500\n",
      "28000\n",
      "28500\n",
      "29000\n",
      "29500\n",
      "30000\n",
      "30500\n",
      "31000\n",
      "31500\n",
      "32000\n",
      "32500\n",
      "33000\n",
      "33500\n",
      "34000\n",
      "34500\n",
      "35000\n",
      "35500\n",
      "36000\n",
      "36500\n",
      "37000\n",
      "37500\n",
      "38000\n",
      "38500\n",
      "39000\n",
      "39500\n",
      "40000\n",
      "40500\n",
      "41000\n",
      "41500\n",
      "42000\n",
      "42500\n",
      "43000\n",
      "43500\n",
      "44000\n",
      "44500\n",
      "45000\n",
      "45500\n",
      "46000\n",
      "46500\n",
      "47000\n",
      "47500\n",
      "48000\n",
      "48500\n",
      "49000\n",
      "49500\n"
     ]
    }
   ],
   "source": [
    "labels_list = []\n",
    "embeddings_list = []\n",
    "\n",
    "labels_unseen_list = []\n",
    "embeddings_unseen_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        \n",
    "        #if i == 50000:\n",
    "            #break\n",
    "            \n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        if i%4 == 0:\n",
    "            embedding = backbone(inputs.to(device))\n",
    "            embeddings_unseen_list.append(embedding)\n",
    "            labels_unseen_list.append(labels)\n",
    "            \n",
    "        else:\n",
    "            embedding = backbone(inputs.to(device))\n",
    "            embeddings_list.append(embedding)\n",
    "            labels_list.append(labels)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c94851cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.32019001e-02 2.03139648e-01 0.00000000e+00 ... 5.02995670e-01\n",
      "  4.88817133e-02 7.30931992e-03]\n",
      " [0.00000000e+00 6.48183823e-02 0.00000000e+00 ... 7.67225176e-02\n",
      "  1.58267841e-02 9.64324921e-02]\n",
      " [2.01363154e-02 1.22714536e-02 1.40573538e-03 ... 4.91771623e-02\n",
      "  0.00000000e+00 5.51568251e-03]\n",
      " ...\n",
      " [0.00000000e+00 2.44694144e-01 0.00000000e+00 ... 0.00000000e+00\n",
      "  5.88626252e-04 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  1.56977966e-01 3.45519948e+00]\n",
      " [6.10989749e-01 6.81949407e-02 0.00000000e+00 ... 2.88817417e-02\n",
      "  5.01507483e-02 3.71309780e-02]]\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "  84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n",
      " 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n",
      " 126. 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139.\n",
      " 140. 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153.\n",
      " 154. 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167.\n",
      " 168. 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181.\n",
      " 182. 183. 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195.\n",
      " 196. 197. 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209.\n",
      " 210. 211. 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223.\n",
      " 224. 225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237.\n",
      " 238. 239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251.\n",
      " 252. 253. 254. 255. 256. 257. 258. 259. 260. 261. 262. 263. 264. 265.\n",
      " 266. 267. 268. 269. 270. 271. 272. 273. 274. 275. 276. 277. 278. 279.\n",
      " 280. 281. 282. 283. 284. 285. 286. 287. 288. 289. 290. 291. 292. 293.\n",
      " 294. 295. 296. 297. 298. 299. 300. 301. 302. 303. 304. 305. 306. 307.\n",
      " 308. 309. 310. 311. 312. 313. 314. 315. 316. 317. 318. 319. 320. 321.\n",
      " 322. 323. 324. 325. 326. 327. 328. 329. 330. 331. 332. 333. 334. 335.\n",
      " 336. 337. 338. 339. 340. 341. 342. 343. 344. 345. 346. 347. 348. 349.\n",
      " 350. 351. 352. 353. 354. 355. 356. 357. 358. 359. 360. 361. 362. 363.\n",
      " 364. 365. 366. 367. 368. 369. 370. 371. 372. 373. 374. 375. 376. 377.\n",
      " 378. 379. 380. 381. 382. 383. 384. 385. 386. 387. 388. 389. 390. 391.\n",
      " 392. 393. 394. 395. 396. 397. 398. 399. 400. 401. 402. 403. 404. 405.\n",
      " 406. 407. 408. 409. 410. 411. 412. 413. 414. 415. 416. 417. 418. 419.\n",
      " 420. 421. 422. 423. 424. 425. 426. 427. 428. 429. 430. 431. 432. 433.\n",
      " 434. 435. 436. 437. 438. 439. 440. 441. 442. 443. 444. 445. 446. 447.\n",
      " 448. 449. 450. 451. 452. 453. 454. 455. 456. 457. 458. 459. 460. 461.\n",
      " 462. 463. 464. 465. 466. 467. 468. 469. 470. 471. 472. 473. 474. 475.\n",
      " 476. 477. 478. 479. 480. 481. 482. 483. 484. 485. 486. 487. 488. 489.\n",
      " 490. 491. 492. 493. 494. 495. 496. 497. 498. 499. 500. 501. 502. 503.\n",
      " 504. 505. 506. 507. 508. 509. 510. 511. 512. 513. 514. 515. 516. 517.\n",
      " 518. 519. 520. 521. 522. 523. 524. 525. 526. 527. 528. 529. 530. 531.\n",
      " 532. 533. 534. 535. 536. 537. 538. 539. 540. 541. 542. 543. 544. 545.\n",
      " 546. 547. 548. 549. 550. 551. 552. 553. 554. 555. 556. 557. 558. 559.\n",
      " 560. 561. 562. 563. 564. 565. 566. 567. 568. 569. 570. 571. 572. 573.\n",
      " 574. 575. 576. 577. 578. 579. 580. 581. 582. 583. 584. 585. 586. 587.\n",
      " 588. 589. 590. 591. 592. 593. 594. 595. 596. 597. 598. 599. 600. 601.\n",
      " 602. 603. 604. 605. 606. 607. 608. 609. 610. 611. 612. 613. 614. 615.\n",
      " 616. 617. 618. 619. 620. 621. 622. 623. 624. 625. 626. 627. 628. 629.\n",
      " 630. 631. 632. 633. 634. 635. 636. 637. 638. 639. 640. 641. 642. 643.\n",
      " 644. 645. 646. 647. 648. 649. 650. 651. 652. 653. 654. 655. 656. 657.\n",
      " 658. 659. 660. 661. 662. 663. 664. 665. 666. 667. 668. 669. 670. 671.\n",
      " 672. 673. 674. 675. 676. 677. 678. 679. 680. 681. 682. 683. 684. 685.\n",
      " 686. 687. 688. 689. 690. 691. 692. 693. 694. 695. 696. 697. 698. 699.\n",
      " 700. 701. 702. 703. 704. 705. 706. 707. 708. 709. 710. 711. 712. 713.\n",
      " 714. 715. 716. 717. 718. 719. 720. 721. 722. 723. 724. 725. 726. 727.\n",
      " 728. 729. 730. 731. 732. 733. 734. 735. 736. 737. 738. 739. 740. 741.\n",
      " 742. 743. 744. 745. 746. 747. 748. 749. 750. 751. 752. 753. 754. 755.\n",
      " 756. 757. 758. 759. 760. 761. 762. 763. 764. 765. 766. 767. 768. 769.\n",
      " 770. 771. 772. 773. 774. 775. 776. 777. 778. 779. 780. 781. 782. 783.\n",
      " 784. 785. 786. 787. 788. 789. 790. 791. 792. 793. 794. 795. 796. 797.\n",
      " 798. 799. 800. 801. 802. 803. 804. 805. 806. 807. 808. 809. 810. 811.\n",
      " 812. 813. 814. 815. 816. 817. 818. 819. 820. 821. 822. 823. 824. 825.\n",
      " 826. 827. 828. 829. 830. 831. 832. 833. 834. 835. 836. 837. 838. 839.\n",
      " 840. 841. 842. 843. 844. 845. 846. 847. 848. 849. 850. 851. 852. 853.\n",
      " 854. 855. 856. 857. 858. 859. 860. 861. 862. 863. 864. 865. 866. 867.\n",
      " 868. 869. 870. 871. 872. 873. 874. 875. 876. 877. 878. 879. 880. 881.\n",
      " 882. 883. 884. 885. 886. 887. 888. 889. 890. 891. 892. 893. 894. 895.\n",
      " 896. 897. 898. 899. 900. 901. 902. 903. 904. 905. 906. 907. 908. 909.\n",
      " 910. 911. 912. 913. 914. 915. 916. 917. 918. 919. 920. 921. 922. 923.\n",
      " 924. 925. 926. 927. 928. 929. 930. 931. 932. 933. 934. 935. 936. 937.\n",
      " 938. 939. 940. 941. 942. 943. 944. 945. 946. 947. 948. 949. 950. 951.\n",
      " 952. 953. 954. 955. 956. 957. 958. 959. 960. 961. 962. 963. 964. 965.\n",
      " 966. 967. 968. 969. 970. 971. 972. 973. 974. 975. 976. 977. 978. 979.\n",
      " 980. 981. 982. 983. 984. 985. 986. 987. 988. 989. 990. 991. 992. 993.\n",
      " 994. 995. 996. 997. 998. 999.]\n",
      "[[0.1083823  0.5119893  0.         ... 0.14421898 0.21808861 0.37895536]\n",
      " [0.         0.48182708 0.         ... 0.37127405 0.58374625 0.11539906]\n",
      " [0.30017835 0.03712829 0.         ... 0.31976345 0.17241618 0.        ]\n",
      " ...\n",
      " [0.62789184 0.28935218 0.         ... 0.         0.         0.03577495]\n",
      " [0.58555347 1.1735611  0.         ... 0.44488284 0.23781224 0.02560199]\n",
      " [0.02999908 0.22788562 0.         ... 0.09933098 0.02034439 0.29357272]]\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "  84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n",
      " 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n",
      " 126. 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139.\n",
      " 140. 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153.\n",
      " 154. 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167.\n",
      " 168. 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181.\n",
      " 182. 183. 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195.\n",
      " 196. 197. 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209.\n",
      " 210. 211. 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223.\n",
      " 224. 225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237.\n",
      " 238. 239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251.\n",
      " 252. 253. 254. 255. 256. 257. 258. 259. 260. 261. 262. 263. 264. 265.\n",
      " 266. 267. 268. 269. 270. 271. 272. 273. 274. 275. 276. 277. 278. 279.\n",
      " 280. 281. 282. 283. 284. 285. 286. 287. 288. 289. 290. 291. 292. 293.\n",
      " 294. 295. 296. 297. 298. 299. 300. 301. 302. 303. 304. 305. 306. 307.\n",
      " 308. 309. 310. 311. 312. 313. 314. 315. 316. 317. 318. 319. 320. 321.\n",
      " 322. 323. 324. 325. 326. 327. 328. 329. 330. 331. 332. 333. 334. 335.\n",
      " 336. 337. 338. 339. 340. 341. 342. 343. 344. 345. 346. 347. 348. 349.\n",
      " 350. 351. 352. 353. 354. 355. 356. 357. 358. 359. 360. 361. 362. 363.\n",
      " 364. 365. 366. 367. 368. 369. 370. 371. 372. 373. 374. 375. 376. 377.\n",
      " 378. 379. 380. 381. 382. 383. 384. 385. 386. 387. 388. 389. 390. 391.\n",
      " 392. 393. 394. 395. 396. 397. 398. 399. 400. 401. 402. 403. 404. 405.\n",
      " 406. 407. 408. 409. 410. 411. 412. 413. 414. 415. 416. 417. 418. 419.\n",
      " 420. 421. 422. 423. 424. 425. 426. 427. 428. 429. 430. 431. 432. 433.\n",
      " 434. 435. 436. 437. 438. 439. 440. 441. 442. 443. 444. 445. 446. 447.\n",
      " 448. 449. 450. 451. 452. 453. 454. 455. 456. 457. 458. 459. 460. 461.\n",
      " 462. 463. 464. 465. 466. 467. 468. 469. 470. 471. 472. 473. 474. 475.\n",
      " 476. 477. 478. 479. 480. 481. 482. 483. 484. 485. 486. 487. 488. 489.\n",
      " 490. 491. 492. 493. 494. 495. 496. 497. 498. 499. 500. 501. 502. 503.\n",
      " 504. 505. 506. 507. 508. 509. 510. 511. 512. 513. 514. 515. 516. 517.\n",
      " 518. 519. 520. 521. 522. 523. 524. 525. 526. 527. 528. 529. 530. 531.\n",
      " 532. 533. 534. 535. 536. 537. 538. 539. 540. 541. 542. 543. 544. 545.\n",
      " 546. 547. 548. 549. 550. 551. 552. 553. 554. 555. 556. 557. 558. 559.\n",
      " 560. 561. 562. 563. 564. 565. 566. 567. 568. 569. 570. 571. 572. 573.\n",
      " 574. 575. 576. 577. 578. 579. 580. 581. 582. 583. 584. 585. 586. 587.\n",
      " 588. 589. 590. 591. 592. 593. 594. 595. 596. 597. 598. 599. 600. 601.\n",
      " 602. 603. 604. 605. 606. 607. 608. 609. 610. 611. 612. 613. 614. 615.\n",
      " 616. 617. 618. 619. 620. 621. 622. 623. 624. 625. 626. 627. 628. 629.\n",
      " 630. 631. 632. 633. 634. 635. 636. 637. 638. 639. 640. 641. 642. 643.\n",
      " 644. 645. 646. 647. 648. 649. 650. 651. 652. 653. 654. 655. 656. 657.\n",
      " 658. 659. 660. 661. 662. 663. 664. 665. 666. 667. 668. 669. 670. 671.\n",
      " 672. 673. 674. 675. 676. 677. 678. 679. 680. 681. 682. 683. 684. 685.\n",
      " 686. 687. 688. 689. 690. 691. 692. 693. 694. 695. 696. 697. 698. 699.\n",
      " 700. 701. 702. 703. 704. 705. 706. 707. 708. 709. 710. 711. 712. 713.\n",
      " 714. 715. 716. 717. 718. 719. 720. 721. 722. 723. 724. 725. 726. 727.\n",
      " 728. 729. 730. 731. 732. 733. 734. 735. 736. 737. 738. 739. 740. 741.\n",
      " 742. 743. 744. 745. 746. 747. 748. 749. 750. 751. 752. 753. 754. 755.\n",
      " 756. 757. 758. 759. 760. 761. 762. 763. 764. 765. 766. 767. 768. 769.\n",
      " 770. 771. 772. 773. 774. 775. 776. 777. 778. 779. 780. 781. 782. 783.\n",
      " 784. 785. 786. 787. 788. 789. 790. 791. 792. 793. 794. 795. 796. 797.\n",
      " 798. 799. 800. 801. 802. 803. 804. 805. 806. 807. 808. 809. 810. 811.\n",
      " 812. 813. 814. 815. 816. 817. 818. 819. 820. 821. 822. 823. 824. 825.\n",
      " 826. 827. 828. 829. 830. 831. 832. 833. 834. 835. 836. 837. 838. 839.\n",
      " 840. 841. 842. 843. 844. 845. 846. 847. 848. 849. 850. 851. 852. 853.\n",
      " 854. 855. 856. 857. 858. 859. 860. 861. 862. 863. 864. 865. 866. 867.\n",
      " 868. 869. 870. 871. 872. 873. 874. 875. 876. 877. 878. 879. 880. 881.\n",
      " 882. 883. 884. 885. 886. 887. 888. 889. 890. 891. 892. 893. 894. 895.\n",
      " 896. 897. 898. 899. 900. 901. 902. 903. 904. 905. 906. 907. 908. 909.\n",
      " 910. 911. 912. 913. 914. 915. 916. 917. 918. 919. 920. 921. 922. 923.\n",
      " 924. 925. 926. 927. 928. 929. 930. 931. 932. 933. 934. 935. 936. 937.\n",
      " 938. 939. 940. 941. 942. 943. 944. 945. 946. 947. 948. 949. 950. 951.\n",
      " 952. 953. 954. 955. 956. 957. 958. 959. 960. 961. 962. 963. 964. 965.\n",
      " 966. 967. 968. 969. 970. 971. 972. 973. 974. 975. 976. 977. 978. 979.\n",
      " 980. 981. 982. 983. 984. 985. 986. 987. 988. 989. 990. 991. 992. 993.\n",
      " 994. 995. 996. 997. 998. 999.]\n"
     ]
    }
   ],
   "source": [
    "embeddings_seen_arr = np.zeros((int(3*len(dataloader)/4), 2048))\n",
    "counter = 0\n",
    "for embedding in embeddings_list:\n",
    "    embeddings_seen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "\n",
    "print(embeddings_seen_arr)\n",
    "labels_seen_arr = np.zeros(int(3*len(dataloader)/4))\n",
    "counter = 0\n",
    "for i in labels_list:\n",
    "    labels_seen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(np.unique(labels_seen_arr))\n",
    "\n",
    "embeddings_unseen_arr = np.zeros((int(len(dataloader)/4), 2048))\n",
    "counter = 0\n",
    "for embedding in embeddings_unseen_list:\n",
    "    embeddings_unseen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "\n",
    "print(embeddings_unseen_arr)\n",
    "labels_unseen_arr = np.zeros(int(len(dataloader)/4))\n",
    "counter = 0\n",
    "for i in labels_unseen_list:\n",
    "    labels_unseen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(np.unique(labels_unseen_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a74e58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4236\n",
      "Accuracy: 0.40752\n",
      "Accuracy: 0.43192\n",
      "Accuracy: 0.45488\n",
      "Accuracy: 0.46232\n",
      "Accuracy: 0.46424\n",
      "Accuracy: 0.45984\n",
      "Accuracy: 0.45752\n",
      "Accuracy: 0.43152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbours = [1, 3, 5, 10, 20, 30, 40, 50, 200]\n",
    "\n",
    "for k in n_neighbours:\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(embeddings_seen_arr, labels_seen_arr)\n",
    "    labels_predicted = knn.predict(embeddings_unseen_arr)\n",
    "\n",
    "    #print('Accuracy' + str(k) + ':', np.sum(labels_unseen_arr == labels_predicted)/len(labels_unseen_arr))\n",
    "    print('Accuracy:', knn.score(embeddings_unseen_arr, labels_unseen_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67aa0a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#JUST TRY DELETE LATER\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embeddings_unseen_arr_trial = embeddings_unseen_arr[0:180,:]\n",
    "labels_unseen_arr_trial = labels_unseen_arr[0:180]\n",
    "\n",
    "#pca = PCA(n_components=2)\n",
    "#pca.fit(embeddings_unseen_arr)\n",
    "#print(pca.explained_variance_ratio_)\n",
    "\n",
    "#embeddings_reduced = pca.transform(embeddings_unseen_arr)\n",
    "#print(embeddings_reduced)\n",
    "\n",
    "u_labels = np.unique(labels_unseen_arr_trial)\n",
    "print(u_labels)\n",
    "\n",
    "embeddings_reduced = TSNE(n_components=2, learning_rate='auto',init='random', perplexity = 10.0).fit_transform(embeddings_unseen_arr_trial)\n",
    "\n",
    "for i in u_labels:\n",
    "    \n",
    "    plt.scatter(embeddings_reduced[labels_unseen_arr_trial == i , 0] , embeddings_reduced[labels_unseen_arr_trial == i , 1] , label = i)\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f01ae5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[712 954 531 ... 327 867 709]\n",
      "0.998001260900872\n",
      "0.31464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=1000, random_state=36).fit(embeddings_seen_arr)\n",
    "labels_predicted = kmeans.predict(embeddings_unseen_arr)\n",
    "print(labels_predicted)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.rand_score(labels_unseen_arr, labels_predicted))\n",
    "\n",
    "truth = labels_unseen_arr\n",
    "pred=labels_predicted\n",
    "print(np.sum( get_y_preds(pred, truth, 1000)[0] == truth )/len(truth) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d54fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings_seen_arr.shape)\n",
    "print(embeddings_unseen_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8382c4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

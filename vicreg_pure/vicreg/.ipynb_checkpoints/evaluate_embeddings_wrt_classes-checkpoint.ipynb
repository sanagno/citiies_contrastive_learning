{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34444cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from geopy.geocoders import Nominatim\n",
    "import re\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sklearn\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import math\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb4d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import signal\n",
    "import sys\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import resnet\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "\n",
    "import glob\n",
    "from geopy.geocoders import Nominatim\n",
    "import re\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import math\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True   #OTHERWISE TRUNCATED IMAGE FILE ERROR SOMEWHERE IN ENUMERATE(DATALOADER)!!!!\n",
    "\n",
    "import resnet\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from munkres import Munkres\n",
    "\n",
    "import augmentations as aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4290e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "077e6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SN7Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, transform=None, train=True):\n",
    "        \n",
    "        if train == True:\n",
    "            self.img_ids_labels = pd.read_csv(\"../../ids_and_labels_train_repeated.csv\", header = None) \n",
    "        else:\n",
    "            self.img_ids_labels = pd.read_csv(\"../../ids_and_labels_val_repeated.csv\", header = None)\n",
    "            \n",
    "        self.img_dir = '/local/home/stuff/datasets/Challenge_7/train'\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #print(self.img_ids_labels.iloc[idx, 0])\n",
    "        image_id, patch_id = self.img_ids_labels.iloc[idx, 0].split(\"!\")[1],self.img_ids_labels.iloc[idx, 0].split(\"!\")[0]\n",
    "        pattern = \"mosaic_(.*?).tif\"\n",
    "        location_id = re.search(pattern, image_id).group(1)\n",
    "        #print(image_id)\n",
    "        #print(location_id)\n",
    "        img_path = os.path.join(self.img_dir, location_id, 'images', image_id )\n",
    "        image = torchvision.transforms.ToTensor()(Image.open(img_path))[0:3,:,:]  #TAKE RGB CHANNELS ONLY FOR RESNET COMPATIBILITY!!!\n",
    "        \n",
    "        image_padded = torch.nn.functional.pad(image, pad=(0, 1024 - image.shape[2], 0, 1024 - image.shape[1]))\n",
    "        patches = image_padded.unfold(1, 256, 256).unfold(2, 256, 256)\n",
    "        patches = patches.reshape(3, -1, 256, 256)\n",
    "        patches = patches.permute(1,0,2,3)\n",
    "        \n",
    "        image = patches[int(patch_id)]\n",
    "        \n",
    "        label = torch.from_numpy(np.asarray(self.img_ids_labels.iloc[idx, 3])).type(torch.LongTensor)\n",
    "        \n",
    "        #patches = patches.view(-1, 3, 256, 256)\n",
    "        #print(patches.shape)\n",
    "        #label = label.flatten()\n",
    "        #label = label.type(torch.LongTensor)\n",
    "        \n",
    "        \n",
    "        image = self.transform(image)\n",
    "                \n",
    "            \n",
    "        #if self.target_transform:\n",
    "            #label = self.target_transform(label)\n",
    "            \n",
    "        \n",
    "        return image, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.img_ids_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee23f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform = transforms.Compose([ transforms.Resize(224), torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "seen_transforms = transforms.Compose(\n",
    "            [   \n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                #transforms.Resize(224),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "#seen_transforms = aug.TrainTransform()\n",
    "\n",
    "unseen_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.CenterCrop(224),\n",
    "                #transforms.Resize(224),\n",
    "                normalize,\n",
    "            ])\n",
    "\n",
    "#unseen_transforms = seen_transforms\n",
    "                \n",
    "test_seen_dataset = SN7Dataset(train=True, transform = seen_transforms)\n",
    "test_unseen_dataset = SN7Dataset(train=False, transform = unseen_transforms)\n",
    "\n",
    "test_seen_loader = DataLoader(dataset=test_seen_dataset, batch_size = batch_size, shuffle = False)\n",
    "test_unseen_loader = DataLoader(dataset=test_unseen_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ba3e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12268863488, 12806062080)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.current_device()\n",
    "torch.cuda.set_device(0)\n",
    "print(torch.cuda.mem_get_info(torch.cuda.current_device()))\n",
    "device = torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5226e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JUST TRY LOADING MODEL LIKE THIS\n",
    "#backbone, embedding = resnet.__dict__['resnet18'](zero_init_residual=True)\n",
    "#backbone.load_state_dict(torch.load('exp/resnet18_2.pth'))\n",
    "#backbone.to(device)\n",
    "#backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fba5a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone, embedding = resnet.__dict__['resnet18'](zero_init_residual=True)\n",
    "state_dict = torch.load('exp/resnet18_100_newest.pth', map_location=\"cpu\")\n",
    "if \"model\" in state_dict:\n",
    "    state_dict = state_dict[\"model\"]\n",
    "    state_dict = {key.replace(\"module.backbone.\", \"\"): value for (key, value) in state_dict.items()}\n",
    "backbone.load_state_dict(state_dict, strict=False)\n",
    "backbone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7052870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding)\n",
    "backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f1c147a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n"
     ]
    }
   ],
   "source": [
    "labels_list = []\n",
    "embeddings_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_seen_loader):\n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "        #print(inputs[1].shape)\n",
    "        embedding = backbone(inputs.to(device))\n",
    "        embeddings_list.append(embedding)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d799060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.53983128 0.54795808 0.27252766 ... 0.29875013 0.16310503 0.22738017]\n",
      " [0.53195357 0.13980401 0.5106355  ... 0.41844964 0.72829115 0.37403846]\n",
      " [0.5615235  0.08370534 0.32428011 ... 0.32268718 0.21639995 0.36758411]\n",
      " ...\n",
      " [0.54552406 0.14738317 0.26720205 ... 0.42164382 0.15712205 0.73964763]\n",
      " [0.53182334 0.40778467 0.17200832 ... 0.35401446 0.27519652 0.30566347]\n",
      " [0.61640412 0.16220683 0.2620295  ... 0.37796444 0.94469869 0.35040313]]\n",
      "[18. 11.  5. ... 27. 29. 29.]\n"
     ]
    }
   ],
   "source": [
    "embeddings_seen_arr = np.zeros((len(test_seen_loader), 512))\n",
    "counter = 0\n",
    "for embedding in embeddings_list:\n",
    "    embeddings_seen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "#embeddings_unseen_arr = torch.tensor(embeddings_unseen_list)\n",
    "#labels_unseen_arr = np.array(labels_unseen_list)\n",
    "\n",
    "print(embeddings_seen_arr)\n",
    "labels_seen_arr = np.zeros(len(test_seen_loader))\n",
    "counter = 0\n",
    "for i in labels_list:\n",
    "    labels_seen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(labels_seen_arr)\n",
    "\n",
    "#np.savetxt(\"seen_embeddings.csv\", embeddings_seen_arr, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea68cfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n"
     ]
    }
   ],
   "source": [
    "labels_unseen_list = []\n",
    "embeddings_unseen_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_unseen_loader):\n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "        embedding = backbone(inputs.to(device))\n",
    "        embeddings_unseen_list.append(embedding)\n",
    "        labels_unseen_list.append(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a6c59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_unseen_arr = np.zeros((len(test_unseen_loader), 512))\n",
    "counter = 0\n",
    "for embedding in embeddings_unseen_list:\n",
    "    embeddings_unseen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "#embeddings_unseen_arr = torch.tensor(embeddings_unseen_list)\n",
    "#labels_unseen_arr = np.array(labels_unseen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "263a5862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.43907893 1.37631691 0.17793465 ... 0.33623528 0.1934571  0.58030421]\n",
      " [0.64923054 0.411511   0.37103271 ... 0.45536307 0.37993309 0.20725022]\n",
      " [0.54243964 0.24759918 0.14132416 ... 0.50793034 0.22103356 0.33757913]\n",
      " ...\n",
      " [0.63299286 0.05053458 0.39243385 ... 0.42576808 0.46963429 0.41839343]\n",
      " [0.50223041 0.47213566 0.18570133 ... 0.5056321  0.36583915 0.30388379]\n",
      " [0.60591632 0.15927012 0.72320771 ... 0.42825732 0.31578121 0.26874015]]\n",
      "[ 7. 29. 18. ... 29. 29.  8.]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_unseen_arr)\n",
    "labels_unseen_arr = np.zeros(len(test_unseen_loader))\n",
    "counter = 0\n",
    "for i in labels_unseen_list:\n",
    "    labels_unseen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(labels_unseen_arr)\n",
    "\n",
    "#np.savetxt(\"unseen_embeddings.csv\", embeddings_unseen_arr, delimiter=\",\", fmt='%s')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48b4c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(embeddings_seen_arr.shape[0]):\n",
    "    if len(np.unique(embeddings_seen_arr[i,:]))==1:\n",
    "        print('yes')\n",
    "for i in range(embeddings_unseen_arr.shape[0]):\n",
    "    if len(np.unique(embeddings_unseen_arr[i,:]))==1:\n",
    "        print('yes_unseen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4645602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  9. 10. 13. 14. 15. 16. 17. 18. 19. 20.\n",
      " 22. 23. 24. 25. 26. 27. 28. 29.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAoaElEQVR4nO3df3DU5b0v8PcnybLJgbgxJTQbAsUgRaymB2/6w1p6qmnBlpMTj0wdOp2rx3NmOJ2ht8iIU6lTDoeOg3PFIq2eOZfb05ae6y2XEQvm0l60gVYqVkWxURoikKok2RSVsvxoEjfJc//Y/Ybd5Pvd3e/u9/e+XzMM5NlN9tkkfPa7n+fzfB5RSoGIiIKpzO0JEBGRfRjkiYgCjEGeiCjAGOSJiAKMQZ6IKMAq3J5AupkzZ6p58+a5PQ0iIl955ZVX3lNK1end5qkgP2/ePBw5csTtaRAR+YqIvG10G9M1REQBxiBPRBRgRQd5EakUkZdE5PcickxE/jU1Xisiz4rIidTfVxY/XSIiMsOKK/kRALcopT4O4K8B3CoinwZwP4BOpdQCAJ2pj4mIyEFFB3mVdDH1YSj1RwFoB7AjNb4DwG3FPhYREZljSXWNiJQDeAXA1QAeV0q9KCIfVkrFAEApFRORWQafuwrAKgCYO3euFdMhCqyuri50dnYiHo8jEomgtbUVAKaMNTc3uzxT8gqxsguliNQA+DmA/wbgt0qpmrTb/qyUypqXb2lpUSyhJNLX1dWFjo4OJBKJibHy8nIopTA+Pj4xFgqF0NbWxkBfQkTkFaVUi95tllbXKKXOAfg1gFsB/ElEoqkJRAGcsfKxiEpNZ2dnRoAHgLGxsYwADwCJRAKdnZ1OTo08zIrqmrrUFTxEpArAFwAcB/A0gLtSd7sLwN5iH4uolMXjcVvuS8FmRU4+CmBHKi9fBmCXUur/isgLAHaJyD8BeAfAVyx4LKKSFYlE8g7ekUjE5tmQXxQd5JVSXQAW64y/D6C12K9PREmtra155+S1BVkiT/WuISJj2kIqq2vIDAZ5Ih9pbm7WDeAM6mSEvWuIiAKMQZ6IKMAY5ImIAoxBnogowBjkiYgCjEGeiCjAGOSJiAKMQZ6IKMC4GYp8Ta+/OjcGEV3GIE++Nbm/ejweR0dHBwDuACXSMF1DvqXXX5291IkyMciTbxm13WUvdaLLGOTJt4x6prOXOtFlDPLkW62trQiFQhljoVAItdfXYumTS9G8oxlLn1yKfb37XJohkfu48Eq+pddfvfb6Wjw2+BiGx4YBALFLMWw8vBEAsLxpuVtTJXINgzz52uT+6kufXDoR4DXDY8PY9uo2BnkqSUzXUKAMXho0NU4UdAzyFCj10+tNjRMFHYM8BcqaG9agsrwyY6yyvBJrbljj0oyI3MWcPAWKlnff9uo2DF4aRP30eqy5YQ0+H/8EYg+9hLFzIyivCeOKZfMwffEsl2dLZD8GeQqc5U3LMxZZLx09g3NPnYBKjAMAxs6N4NxTJwCAgZ4Cj+kaCrzz+9+aCPAalRjH+f1vuTMhIgcxyFPgjZ0bMTVOFCQM8hR45TVhU+NEQcIgT4F3xbJ5kFDmr7qEynDFsnkTH+8ePIuWw8cQPfgaWg4fw+7Bsw7PksgeXHilwNMWV8/vf0u3umb34Fms6zmNoXEFAOgbSWBdz2kAwIr6WncmTWQRBnkqCdMXzzKspNncG5sI8JqhcYXNvTEGefI9pmuo5PWPJEyNE/lJ0UFeROaIyEER6RaRYyKyJjVeKyLPisiJ1N9XFj9dIuvNDodMjRP5iRVX8qMA7lVKLQLwaQCrReRaAPcD6FRKLQDQmfqYyHPWN0VRVSYZY1VlgvVNUZdm5AwuNpeGooO8UiqmlHo19e8LALoBzAbQDmBH6m47ANxW7GMR2WFFfS22LJyDxnAIAqAxHMKWhXMCnY/XFpv7RhJQuLzYrAX6fb37ePBKQIhSKve98v1iIvMAPAfgOgDvKKVq0m77s1JqSspGRFYBWAUAc+fO/S9vv/22ZfMhIn0th4+hT2fNoTEcwr/Wv4WNhzdm9OWvLK/Exs9sZE9+jxKRV5RSLXq3WbbwKiIzAOwGcI9S6ny+n6eU2q6UalFKtdTV1Vk1HSLKItti87ZXtxkevEL+Y0mQF5EQkgH+CaXUU6nhP4lINHV7FMAZKx6LiIqXbbGZB68EixXVNQLgPwB0K6W+l3bT0wDuSv37LgB7i30sIrJGtsVmHrwSLFZcyd8E4L8CuEVEXkv9+TKAhwB8UUROAPhi6mMi8oBsi808eCVYit7xqpT6LQAxuLm12K9PRPZYUV+rW0FkdPAKF139iW0NiGiKyQevkH+xrQERUYAxyBMRBRjTNVSw7kMHcWjnT3Hh/fdQ/aGZWLLyTixacrPb0yKiNAzyVJDuQwfxzPbHMPpB8gi9C++9i2e2PwYADPREHsIgTwU5tPOnEwFeM/rBCA7t/KmjQf7S0TOGh4EQEYM8FejC+++ZGrfDpaNncO6pE1CJcQDJg7nPPXUCABjoiVK48EoFqf7QTFPjdji//62JAK9RiXGc3/+WY3Mg8joGeSrIkpV3omJaOGOsYloYS1be6dgcxs6NmBonKkVM11BBtLy7W9U1l44a97srrwkb3kZUahjkqWCLltzsWiVNtpTMFcvmOTYPIq9jkKeCuVknny0lw0VXf4t3dODM1kcxGouhIhrFrLX3INLW5va0fIs5eSqIVid/4b13AaUm6uS7Dx105PGNUjJ+TdXEOzpw4pZWdC+6FiduaUW8o8PtKbki3tGB2Hc2YHRgAFAKowMDiH1nQ8l+P6zAIE8FyVYn74Qrls2DhDJ/fSVUZl+qpmsXsPU6YGNN8u+uXVnvHhvci+efX4LOA1fj+eeXIDZofJwCA9tlZ7Y+CjWceSqVGh7Gma2PujOhAGCQp4K4XSc/ffEs1Ny+YOLKvbwmjJrbF9iTqunaBXR8E4ifBqCSf3d80zDQxwb34vjxBzA8MgBAYXhkAMePP2AY6BnYLhuNxUyNU27MydulaxfQuQmI9wGRRqB1A9B8h9uzskz1h2YmUzU6406ZvniWM/n3zk1AYihzLDGUHNf5mfae2oLx8cz7j48PoffUFkTr26fcn4HtsopoNPmORmecCsMreTuYvPLzIy/UyTsm3mdqfHhEPzgbjRsFsFIMbDP+5nOmxik3Bnk7ZLvyC4hFS27G0lXfQPXMOkAE1TPrsHTVNyaqa7oPHcT21XfjkZVt2L76bscWZG0RaTQ1XhnWD85G47PW3gOpzDxuTyorMWvtPXlPMSgu/uY5U+OUG9M1k1mRZjF55edl2cokjerkA9ehsnVD8p1Y+gt3qCo5rqNp/jocP/5ARsqmrKwKTfPX6d5fKw9k2SBTV3ZgkE+npVm0/8xamgUwF+gjjalUjc64jxQarL3SodIy2s8+zxd/Le/ee2oLhkdiqAxH0TR/nW4+XhNpayvJoD4Zc/LWY5BPZ3KBzZDJKz+vKjRYu115Y4vmO0z9DkTr27MGddI3a+09iH1nQ0a1UammrqzCIJ+uiDTL5LTG8r/5Omb3P+nr6ppCg3W+lTfc2Rg8scG9pt7BTMbUlfUY5NMVmGbRS2s82XEeS1f9wJ/piZRCyySXrLwz4/sBTK280TYAaVds2gYgAPwP7VPa/gBtLULbHwDAdKDn74B1WF2TrnVDMq2SLo80i9u7P+1SaJlkrsobgBuAgijb/gByD6/k05lcYNMEMgeN4toJ5+pQySqK4DG7P4CcwSA/Wb4LbGmllqsWVOK5wbk4fj5z96WTuz/tYlc7YTNVFG52u/Q7J793leFoqpXD1HEjPKPXfkzXFGLSjtbq8iEsjZ7ANVdcPshiSlrDZIOroMt3A5Db3S79zOnvXdP8dSgry0x3ZtsfoJ3Rq7WN1s7ozXYgDJnHIF8InVLLUNk4Plf/jn4OugTaHJgVaWtD9LubUNHQAIigoqEB0e9umrLgFtT1Dic4/b2L1rfjmmseRGW4AYCgMtyAa6550HDRlWf0OoPpmkIYlFRWlw/j3p067WGtqr8PmHyqKIK63uEEN753ZvYH2HVGL9N7mRjkC2G21DJAbQ6c5oVul35l9nvndHAsrwnrBnQzB79MnnPT4k/g2G86g9NSwwJM1xTCbKmlyQZXdJlful168WQnM987N9Y+ij34RW/Ov3/2F0zvTWJJkBeRH4nIGRF5I22sVkSeFZETqb+vtOKxPKH5DqDt+0BkDgBJ/t32fePUS4H195RfzX0+9hztx00PHcBV9+/DTQ8dwJ6j/ZbN0asnO5n53rmx9lHswS96czZSyuk9UUoV/0VEPgfgIoCfKqWuS439dwBnlVIPicj9AK5USn0r29dpaWlRR44cKXo+nhTwQ0S8bM/Rfqx/6nUMJcYmxqpC5dh8+/W4bfHsor/+iVta9ctBGxqw4EBn0V/fCY+sbAP0YoGI/jqTBxjOWUf1zDqsevzHNs/IPSLyilKqRe82S3LySqnnRGTepOF2AJ9P/XsHgF8DyBrkA81kgyuyzsP7ezICPAAMJcbw8P4eS4J8EDZ2+XHtw2jOk3kxveckO3PyH1ZKxQAg9bfuezARWSUiR0TkyLvv5v6BEZk1cG7I1LhZQTjZyS9rH+mM5vzxL3656PRekLheXaOU2g5gO5BM17g8HQqghpoq9OsE9IaaKp17X5ZvtUkQ2uMW08LCLX6csxvsDPJ/EpGoUiomIlEA3MZGrrhv2ULdnPx9yxYafo6ZA1OC0h7XrhYWdvLjnJ1mZ5B/GsBdAB5K/b3XxsciMqTl3R/e34OBc0NoqKnCfcsWZs3Hmz0whe1xCQD29e7Dtle3YfDSIOqn12PNDWuwvGm5q3OyJMiLyM+QXGSdKSJ9AP4FyeC+S0T+CcA7AL5ixWMRFeK2xbNNLbJypy2Zta93HzYe3ojhsWTaLnYpho2HNwKAq4Hequqarxrc1GrF1ydymh+rTchd217dNhHgNcNjw9j26jZXgzx3vBLp8GO1Cblr8NKgqXGnuF5dQ85wu2mTF3OV2dhRueH2zyAodg+exebeGPpHEpgdDmF9UxQr6mvdnhbqp9cjdmnq3oj66fUuzOYyBvkSYKZSxA5ezVXmYmXlhlM/g6Afjr578CzW9ZzG0Hiy2rpvJIF1PclmgW4H+jU3rMn4PQeAyvJKrLlhjYuzYrqmJLjdkz1brtIuXmsY5sTPwK0eOm++OIgd334ej3/9AHZ8+3m8+aJ96YnNvbGJAK8ZGlfY3Ov+7uLlTcux8TMbEZ0ehUAQnR7Fxs9sdP1ChlfyJcDtShGnc5VasNM2J2nBDoBrV7VO/AyyHY5u1/N+88VBHHziOEY/SB7+cfHsCA4+cRwA8NFPWZ+m6B9JmBp32vKm5a4H9cl4JV8CjCpCjMatvjIzyknalavMFuzcYvZnUIj0Xjn9NTNwYNFc/KK5Cc9EKmxrGfzC3lMTAX5iHh+M44W9p2x5vNnhkKlxp3ntHSTAIF8SzFSKaFdmF88mUwvalVkxgX7NDWtQWZ55nquduUovNgxzolpH65XTXzMDr8+pw/C0ECCC4Wkh23rDa78n+Y4Xa31TFFVlkjFWVSZY3+R+nyCvtpxmkC8BZvqK23Flli1XGRvci+efX4LOA1fj+eeXIDZY/MZoKxqGdR86iO2r78YjK9uwffXdRQdIq/riZ6Mdjt4TrcV4WeZ/bbvWYGbU6p/iZDRerBX1tdiycA4awyEIgMZwCFsWznF90RXw5jtIgDn5kpFvpYhdV2Z6ucrY4F4cP/4AxseTzcOGRwZw/PgDAJD3OaF69BqGjZWVAV9amtfn21UJY3efFS3vPvyf/657ux1rMDe2z8/IyQNAxbQy3Ng+3/LH0qyor/VEUJ/M8B3kwADiHR2urQfxSp4yOHll1ntqy0SA14yPD6H31Jaivm6krQ3qaysxNK0CCsBfQhXomj0Tz3S9lNcVudvVSMWItLWhuk7/ZCU7dut++MzLuObt3QgPvw8ohelV47j5a9fYsujqddneKbqZtmGQpww3ts9HxbQyjI50Yzj+PzH85+9hJP5DzPmo9b3+h0f0r3yMxs049NZxHFz0Efzy4/Px62s/glhtdd6B2u5KmH29+7D0yaVo3tGMpU8uxb7efZZ8XY1Tu3W1HPSsnl/hpt9twC2/+QY+ffA+fPjMy5Y+jl9o6TI9bqZtGOQpw0c/VY8FN5zD6NCzwPgFAIAaP4/XO//T8oW7yrD+lY/RuBnFBGo7K2G0jWGxSzEoqImNYVYGeify/4B3c9BuibS1IfrdTYa3G6Vz7K7IYZCnKU6+vBdQoxljdqQrmuavQ1lZ5sEdZWVVaJq/ruivXUyg1rsSHitXmHFLc9Hzcmpj2KIlN2PV4z/GvTs7sOrxH9uyFuDFKia3RdraUNHQoHubXjrHiYocBnmawqnNU9H6dlxzzYOoDDcAEFSGG3DNNQ8WteiqKSZlsWjJzai77bO4VDUGBYWLlaP47XXvYevQ/y76iturTawKEYRjD+2gl7YxOinMiXdDgamu2XO039ShEGTMyTa70fp2S4L6ZMU2GPuJ+iViN0+6Ih1D0W1jvdrEqhBBOPbQDmZOCnPi3VAggvyeo/0Zx7v1nxvC+qdeBwAG+gIsWXlnRgkh4O02u0bdHYspWbTriturTawK4ZVjD73Y3TPfk8IqotFkqkZn3CqBSNc8vL8n4/xOABhKjOHh/T0uzcjfnFq4s4JW037hvXcBpSZq2otdJLarFYNXm1gVKtLWhgUHOlH+kwM4/OlN+F/7phu2wrBjgdGun79TzKR2ChWIK/n+c0O64wMG45SbXw5INnsWa77svOL2YhOrYuTTpMyupnF2/fyd4sS7Id8H+T1H+yEAlM5tDTVVOqMUJHYtEmtB2KmDTvy8ppStFYYW5IvpkJktHeN2h1Ur2H0IvO+D/MP7e3QDvAC4b9lCp6dTktzMidq5SOzUFbff15TyaYVR6AJjrhYTPIs3N9/n5I1SMgr++A/id27nRINwFqvf15TyaYVRaLllrhYTQfj52833Qd4oJTObqRpHuN3nxU+LxEaMLlT8sqaktcJIN7lJWaELjLnSMUH4+dvN9+ma+5YtzHirCwBVoXKmakwoJt3ihZyoXxaJjTTUVOkWD/hlTUnLu7+w9xQunh3BjNowbmyfn9GkrNAFxnzSMX7/+dvN90FeS8k4vWi1r3efY4tydiq2rS5zosULwoXKRz9Vn7PzZCELjH7bs+FFopTesqU7Wlpa1JEjR9yeRk5ak6nJ5XXtV7fjub7nfBX4t6++Wz9Iz6zDqsd/nPPzJ79IAMn/hHzLbE4h1TVeu9CwawHei5udvEZEXlFKtejexiBv3tInl+puTZ+ssryyqI0uTvxyP7KyDdD7HRDBvTvz26zC/4T22D14Fpt7Y+gfSWB2OIT1TdGJwzKMLjTc2ljFF3t3ZQvyvk/XuCHfre1ad8FC/tPZdTrRZFakW6zIicYG96L31BYMj8RQGY6iaf46W3raaLq6utDZ2Yl4PI5IJILW1lY0NxffZdIquwfPYl3PaQyNJ1+A+0YSWNdzGkDyZKRs3SzdCPJ+35QUZL6vrnGDma3thfY6capqxQslaNoxgMMjAwDUxDGAVpz3qqerqwsdHR2Ix+MAgHg8jo6ODnR1ddnyeIXY3BubCPCaoXGFzb3Jd5Be62bphQV40scgX4A1N6xBZbn+CTCTFdrrxKn/NF4oQbPrGEAjnZ2dSCQSGWOJRAKdnZ2WP9aeo/246aEDuOr+fbjpoQPYc7Q/r8/rH0lkHbert06h7DxohYrDdE0B9La8f67xc9h7cq9lvU6crFpxuwTNzmMA9WhX8PmOF6qYnayzwyH06QT62eEQAO91s2QVjHfZHuRF5FYA2wCUA/ihUuohux/TCXpb3hfPWmxZtUMp/aepDEdTqZqp43aIRCK6AT0SiVj6ONl2suYK8uubohk5eQCoKhOsb0p+T5zurZNLsf37yT62VteISDmANwF8EUAfgJcBfFUp9Qe9+/ulusYppVK1ouXkx8eHcPbEFYi9VIfExRD+6spqfP5r/2z5c9Zy8ukpm1AohLa2NksXX6+6f59hX6U/PpQ7GGerriFrBOX/mJvVNZ8EcFIp1ZuayE4A7QB0gzxlcjuN4hStiubFX2zD6ecqoUaTS0V/+fNFWyqKtEBud3VNsTtZV9TXMqhbaHJAb1r8CRz7TaftFWxuszvIzwZwOu3jPgCfSr+DiKwCsAoA5s6da/N0yKui9e0488oeqNHMdQi7yvCam5ttL5kMwk7WoNArSf79s7+Ycr8gln3aHeRFZyzjHaxSajuA7UAyXWPzfMjD3CjDs/PtulstN4DkQR7ZesmUGr2SZCNBK/u0O8j3AZiT9nEjgKkrbERwvg+OExvObls82/GW1/mc1FRqzATuoJV92l0n/zKABSJylYhMA7ASwNM2Pyb5lNMbs9xuk2yXbCc1lap8A3cQK9hsDfJKqVEA3wCwH0A3gF1KqWN2Pib5l9Mbs4K6SzOfk5pKjdEFxMe/+OXA96K3vU5eKfULAFNXOMjX7MplO1lRFNQ2yTNqw7oB3egEp1JQynX83PFKAMwFbaeap9ktqBvObmyfn5GTB6ae1BRkRi2YS6UkeTIGeTIdtIPScdD1q7uuXUDnJiDeB0QagdYNQPMdRX/ZfE5qCqrJLZhjl2LYeHgjAHj+bAe7MMiT6aBtmMvWSX24Jd93Jq5d3XXtAjq+CSRSm6Xip5MfA5YF+lII6pN5rQWzFzDIe5hTW67NLkAa5bKB5JydDJp63yMA3k8ndW66HOA1iaHkuAVBvlR5rQWzF7DVsEdpKZQL770LKDURqLoPHbT8scy2ic2Ws3ay/NDoe3Rgx3bvl0bG+8yNU1681oLZCxjkPcrJGm6z9enZroadLD80+h4NX7ige39PlUZGGs2NU170znpwswWzFzBd41FO1nAXsgBZPbPO9fJDs98LO3fOmk6rtW7IzMkDQKgqOU4F81oLZi9gkPeIyYEiPH0GRi5OvSK1K1CZXYD0Qvmh0dpAeEY1xj74wJG5FVxOquXdbaiusYpRKaLX6Z31UMoY5D1AL1CUVVRAysuhxi53MPRSDbfr5YcwfqFp/YdVjs2tqHLS5js8FdTTsRQxOGw9NMSsUj00ZPvqu3WvSCurqxEKV5bcDj0AedeQu33owyMr2wC9/0MiuHdnh2PzsNrSJ5cidmnq8YtlUgallK+u7EuBm4eGUB6McsvDFy9i9Q9/5vBsPMBEDbnbuxiD2hrBqORwXCV30fLK3j9YXeMBPOl+kmw15B6TT2VS96GD2L76bjyysg3bV99tSxms1fIpOdQ2GZG3Mch7gNMtdj3P4hpyO4Nsrs6ZTu53sJJeKaKeUt5k5BdM13iAFxYxPSXSmEzR6I2b5EQztWwpI7v6/Ow52m/riVOTSxFFZCJVk66UNxn5BYO8R7idW/YUC2vI3W6mZsd+hz1H+zPOju0/N4T1T70OAJYHei3YT662AbjJyC+YriHvab4DaPs+EJkDQJJ/t32/oHJDtw8GsWO95eH9PRmHgwPAUGIMD+/vKfhr5rK8aTk2fmYjotOjEAii06PY+JmNXHT1AV7JkzdZVEPudvWLHZvGBs4NmRq3CjcZ+RODPBXF7Tr1XNzemWvHektDTRX6dQJ6Q01VwV+Tgouboahgkxc1gWQA9do5mekvRFUzrkR51Wcxmrjat4dpTM7JA0BVqBybb7/e0pw8+Qc3Q5Et3F7UzJe2qP3mi4MZx+JdPDuCg08cB4C8Av2bLw5aftpSvKMDZ7Y+itFYDBXRKGatvQeRtrasn6MFcjurayg4GOSpYG4vapr1wt5TGeeeAsDoB+N4Ye+pnMG62BcIPfGODsS+swFqOFmxMjowgNh3khVE+QR6BnXKB6trqGB+26l78eyIqfF02V4gCnVm66MTAV6jhodxZuujBX9NoskY5KlgftupO6M2bGo8XTEvEEZGY1MbgGUbJyoEgzwVLNeWfq+5sX0+KqZl/spXTCvDje3zc35uMS8QRiqiUVPjRIVgTp5M6+rqQmdnJ+LxOCKRCFr/eS2am5vdnlZOWu68kMXTG9vnZ+TkgfxfIIzMWntPRk4eAKQCmDX3GLD1Os8dIkL+xCBPpnR1daGjowOJRAIAEI/H0dGR7Jvul0BfyEJpMS8QRrTF1WR1zQAq/moMs64/j8i8oaztlYnMYJ08mbJ161bE4/Ep45FIBGvXrnVhRgGx9TqDpmxzgLVvOD8f8pVsdfLMyZMpegE+2zjlyeL2ykQapms8opBNMW6IRCKGV/Ju83qLhawsbK9MlI5X8h6gbYoZHRgAlJrYFBPv8N4Zoa2trQiFQhljoVAIra2tLs0oya+Hc0xo3ZBsp5yuwPbKROmKCvIi8hUROSYi4yLSMum29SJyUkR6RGRZcdMMNj9timlubkZbWxuqP/gLpp/oQnX3EdS81Y1Q/H1X55WtxYIvWNhemShdsemaNwDcDuB/pA+KyLUAVgL4GIAGAL8SkY8qpcamfonSoneiz0KfbYoJxd9HxelTGB39AAAwfP6c5actmeW3Fgu6LGqvTJSuqCt5pVS3UkrvpIJ2ADuVUiNKqT8COAngk8U8VhBo3QP7zw1B4fKJPokP1ene36ubYty4as51TqvfWiwQOcWunPxsAOmrSH2psSlEZJWIHBGRI+++O/VwhyAxOtHnJ4u+BKnMPDRZKisxa+09Ds4uf05fNeeTb/dbiwUip+QM8iLyKxF5Q+dPe7ZP0xnTLchXSm1XSrUopVrq6vSvaIPC6OSen3/oekS/uwkVDQ2ACCoaGhD97iZPVtcAzl815/POwW8tFoickjMnr5T6QgFftw/AnLSPGwEMFPB1AiXbiT6Rtls8G9Qnc/q0pXzfOfAwdKKp7ErXPA1gpYiEReQqAAsAvGTTY/nGfcsWoipUnjFWFSrHfcsWujSjwjh91cx8O1HhiqquEZG/B/ADAHUA9onIa0qpZUqpYyKyC8AfAIwCWM3KmmCd6OPkVbOj7xy6dgGdm5I7TSONbBJGvsfeNeQLjuxm7dqVbAqWSEuphapYr06el613DYM8kaaEm4T5uiUE8SBvorxMagbWHa/DoTPzcGE0jOrVdwc28Gklqlo6TCtRBdzb3EbWYZAn0qQ1CeuO1+GZ2AKMquRCeZADX64SVV7h+xsblBFp0pqEHTozbyLAa3zVC8cEwxLV1Aubb5u+EQAGeaLL0pqEXRjVP7vVV71w8mRUiiplZf5u+kYAGOSJMjXfAax9A9UzZ+neHMTafKOWEGp8XPf+QXyhCzIGeSIdpdQLx2hzW/VM/TYjVrzQ7R48i5bDxxA9+BpaDh/D7sGzRX9N0seFVyId2uJiqSw6Gm1us2MT2u7Bs1jXcxpD48ny7b6RBNb1nMZL8YvofP8C+kcSmB0OYX1TFCvqa4t6LGKdPBFlYUf9fMvhY+gbSUwZF2R2MawqE2xZOIeBPg+skyeajO0L8mJH+4p+nQAPTG1TOzSusLk3xiBfJObkqfRo7QvipwGo5N8d30yOk+1mh0O575Ri9IJA+WOQp9LTuSmzPw2Q/LhzkzvzKTHrm6KoKss8ckLvAArA3AsC6WOQp9IzqX1BznGy1Ir6WmxZOAeN4RAEQGM4hDsbaqcE/qoywfombx6B6SfMyZOn2dI4K619wZRxcsSK+topufZPRmZgc2+M1TUWY5Anz7KtcVbrBv2Wwq0bipkuFUkv8FPxGOTJMyZftSdGhg231RcV5LUqGlbXUAlgkCdP0LtqN2LJtvrmOxjUqSRw4ZU8Qa/drZEg9o8hsguDPHlCvlfnQe0fQ2QXBnnyBKOr8/CM6imNs4LaP4bIDszJkycsWXmnbjOs1n9YxaBOVAQGefKEUuv6SOQUBnnyDDuaYRGVOubkiYgCjEGeiCjAGOSJiAKMQZ6IKMAY5ImIAozVNRQotrQmJvIxBnkKDNtaExP5GNM1FBh6Tc601sREpaqoIC8iD4vIcRHpEpGfi0hN2m3rReSkiPSIyLKiZ0qUg1GTM0taExP5VLFX8s8CuE4p1QzgTQDrAUBErgWwEsDHANwK4N9EpLzIxyLKyqjJGVsTUykrKsgrpZ5RSo2mPvwdAO2QzHYAO5VSI0qpPwI4CeCTxTwWUS5LVt6JimnhjDG2JqZSZ+XC6z8C+D+pf89GMuhr+lJjU4jIKgCrAGDu3LkWTodKjVeanOWq8Nk9eJYHVpNjcgZ5EfkVgHqdmx5QSu1N3ecBAKMAntA+Tef+Su/rK6W2A9gOAC0tLbr3IcqX203OclX47B48i3U9pzE0nvxV7xtJYF3PaQDIGej1XhwA8AWDssoZ5JVSX8h2u4jcBeBvAbQqpbQg3QdgTtrdGgEMFDpJIr/IVuGzaMnN2NwbmwjwmqFxhc29sazBWe/F4Z7udwARJJT5FwwqHcVW19wK4FsA/k4p9Ze0m54GsFJEwiJyFYAFAF4q5rGI/CBXhU//SEL3dqNxjd6LQwKYCPAa7QWDSFNsdc1jAKoBPCsir4nIvwOAUuoYgF0A/gDg/wFYrZQaK/KxiDwvV4XP7HBI93ajcU2uF4FC70vBV2x1zdVKqTlKqb9O/fl62m0PKqXmK6UWKqV+WfxUibwvV4XP+qYoqsoyl6yqymQiv24k14tAofel4OOOVyILLVpyM5au+obh4eMr6muxZeEcNIZDEACN4RC2LJyTM4eu9+IQAhAS8y8YVFpEKe8UtLS0tKgjR464PQ0iT2J1DRkRkVeUUi16t7FBGZFPrKiv1Q3gDOqUDdM1REQBxiBPRBRgDPJERAHGIE9EFGAM8kREAeapEkoReRfA227Po0gzAZTaKRWl9pz5fIPPb8/5I0qpOr0bPBXkg0BEjhjVqwZVqT1nPt/gC9JzZrqGiCjAGOSJiAKMQd56292egAtK7Tnz+QZfYJ4zc/JERAHGK3kiogBjkCciCjAGeYuIyMMiclxEukTk5yJSk3bbehE5KSI9IrLMxWlaRkS+IiLHRGRcRFom3Ra45wskj7tMPaeTInK/2/Oxg4j8SETOiMgbaWO1IvKsiJxI/X2lm3O0kojMEZGDItKd+n1ekxoPzHNmkLfOswCuU0o1A3gTwHoAEJFrAawE8DEAtwL4NxEpd22W1nkDwO0AnksfDOrzTT2HxwF8CcC1AL6aeq5B8xMkf27p7gfQqZRaAKAz9XFQjAK4Vym1CMCnAaxO/VwD85wZ5C2ilHpGKTWa+vB3ABpT/24HsFMpNaKU+iOAkwA+6cYcraSU6lZK9ejcFMjni+RzOKmU6lVKfQBgJ5LPNVCUUs8BODtpuB3AjtS/dwC4zck52UkpFVNKvZr69wUA3QBmI0DPmUHeHv8IQDvXdjaA02m39aXGgiqozzeozysfH1ZKxYBkUAQwy+X52EJE5gFYDOBFBOg582QoE0TkVwDqdW56QCm1N3WfB5B8C/iE9mk69/dF3Wo+z1fv03TGfPF8cwjq8yIAIjIDwG4A9yilzovo/bj9iUHeBKXUF7LdLiJ3AfhbAK3q8gaEPgBz0u7WCGDAnhlaK9fzNeDb55tDUJ9XPv4kIlGlVExEogDOuD0hK4lICMkA/4RS6qnUcGCeM9M1FhGRWwF8C8DfKaX+knbT0wBWikhYRK4CsADAS27M0SFBfb4vA1ggIleJyDQkF5efdnlOTnkawF2pf98FwOhdnO9I8pL9PwB0K6W+l3ZTYJ4zd7xaREROAggDeD819Dul1NdTtz2AZJ5+FMm3g7/U/yr+ISJ/D+AHAOoAnAPwmlJqWeq2wD1fABCRLwN4FEA5gB8ppR50d0bWE5GfAfg8kq12/wTgXwDsAbALwFwA7wD4ilJq8uKsL4nIZwEcAvA6gPHU8LeRzMsH4jkzyBMRBRjTNUREAcYgT0QUYAzyREQBxiBPRBRgDPJERAHGIE9EFGAM8kREAfb/AUQamMWG9OdJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#JUST TRY DELETE LATER\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embeddings_unseen_arr_trial = embeddings_unseen_arr[0:60,:]\n",
    "labels_unseen_arr_trial = labels_unseen_arr[0:60]\n",
    "\n",
    "#pca = PCA(n_components=2)\n",
    "#pca.fit(embeddings_unseen_arr)\n",
    "#print(pca.explained_variance_ratio_)\n",
    "\n",
    "#embeddings_reduced = pca.transform(embeddings_unseen_arr)\n",
    "#print(embeddings_reduced)\n",
    "\n",
    "u_labels = np.unique(labels_unseen_arr_trial)\n",
    "print(u_labels)\n",
    "\n",
    "embeddings_reduced = TSNE(n_components=2, learning_rate='auto',init='random', perplexity = 10.0).fit_transform(embeddings_unseen_arr_trial)\n",
    "\n",
    "for i in u_labels:\n",
    "    \n",
    "    plt.scatter(embeddings_reduced[labels_unseen_arr_trial == i , 0] , embeddings_reduced[labels_unseen_arr_trial == i , 1] , label = i)\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9146f3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.986953455571227\n",
      "Accuracy: 0.9839562764456982\n",
      "Accuracy: 0.985719322990127\n",
      "Accuracy: 0.9830747531734838\n",
      "Accuracy: 0.9702045133991537\n",
      "Accuracy: 0.9449929478138223\n",
      "Accuracy: 0.9049717912552891\n",
      "Accuracy: 0.8457334273624824\n",
      "Accuracy: 0.5153385049365303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbours = [1, 3, 5, 10, 20, 30, 40, 50,200]\n",
    "\n",
    "for k in n_neighbours:\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(embeddings_seen_arr, labels_seen_arr)\n",
    "    labels_predicted = knn.predict(embeddings_unseen_arr)\n",
    "\n",
    "    #print('Accuracy' + str(k) + ':', np.sum(labels_unseen_arr == labels_predicted)/len(labels_unseen_arr))\n",
    "    print('Accuracy:', knn.score(embeddings_unseen_arr, labels_unseen_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4314106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_preds(cluster_assignments, y_true, n_clusters):\n",
    "    '''\n",
    "    Computes the predicted labels, where label assignments now\n",
    "    correspond to the actual labels in y_true (as estimated by Munkres)\n",
    "\n",
    "    cluster_assignments:    array of labels, outputted by kmeans\n",
    "    y_true:                 true labels\n",
    "    n_clusters:             number of clusters in the dataset\n",
    "\n",
    "    returns:    a tuple containing the accuracy and confusion matrix,\n",
    "                in that order\n",
    "    '''\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_true, cluster_assignments, labels=None)\n",
    "    # compute accuracy based on optimal 1:1 assignment of clusters to labels\n",
    "    cost_matrix = calculate_cost_matrix(confusion_matrix, n_clusters)\n",
    "    indices = Munkres().compute(cost_matrix)\n",
    "    kmeans_to_true_cluster_labels = get_cluster_labels_from_indices(indices)\n",
    "    y_pred = kmeans_to_true_cluster_labels[cluster_assignments]\n",
    "    return y_pred, confusion_matrix \n",
    "\n",
    "def calculate_cost_matrix(C, n_clusters):\n",
    "    cost_matrix = np.zeros((n_clusters, n_clusters))\n",
    "\n",
    "    # cost_matrix[i,j] will be the cost of assigning cluster i to label j\n",
    "    for j in range(n_clusters):\n",
    "        s = np.sum(C[:,j]) # number of examples in cluster i\n",
    "        for i in range(n_clusters):\n",
    "            t = C[i,j]\n",
    "            cost_matrix[j,i] = s-t\n",
    "    return cost_matrix\n",
    "\n",
    "def get_cluster_labels_from_indices(indices):\n",
    "    n_clusters = len(indices)\n",
    "    clusterLabels = np.zeros(n_clusters)\n",
    "    for i in range(n_clusters):\n",
    "        clusterLabels[i] = indices[i][1]\n",
    "    return clusterLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cd153ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Afteer Hungarian Assignment: 0.16114245416078984\n",
      "(22688,)\n",
      "Accuracy Afteer Hungarian Assignment: 0.1469058533145275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "#labels_predicted = AgglomerativeClustering(n_clusters = 20).fit_predict(embeddings_unseen_arr)\n",
    "\n",
    "#truth = labels_unseen_arr\n",
    "#pred = labels_predicted\n",
    "#print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )\n",
    "\n",
    "#print(sklearn.metrics.rand_score(labels_unseen_arr, labels_predicted))\n",
    "\n",
    "whole_test_set = np.concatenate((embeddings_seen_arr,embeddings_unseen_arr), axis=0)\n",
    "whole_labels = np.concatenate((labels_seen_arr, labels_unseen_arr))\n",
    "\n",
    "labels_predicted = AgglomerativeClustering(n_clusters = 31).fit_predict(whole_test_set)\n",
    "\n",
    "truth = whole_labels\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 31)[0] == truth )/len(truth) )\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#kmeans = KMeans(n_clusters=20, random_state=36).fit(embeddings_seen_arr)\n",
    "#labels_predicted = kmeans.predict(embeddings_unseen_arr)\n",
    "#print(labels_predicted.shape)\n",
    "\n",
    "#truth = labels_unseen_arr\n",
    "#pred = labels_predicted\n",
    "#print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )\n",
    "\n",
    "kmeans = KMeans(n_clusters=31, random_state=36).fit(whole_test_set)\n",
    "labels_predicted = kmeans.predict(whole_test_set)\n",
    "print(whole_labels.shape)\n",
    "\n",
    "truth = whole_labels\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 31)[0] == truth )/len(truth) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b70a10f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "\n",
    "seen_transforms = transforms.Compose(\n",
    "            [   \n",
    "                #transforms.RandomResizedCrop(224),\n",
    "                #transforms.RandomHorizontalFlip(),\n",
    "                transforms.Resize(224),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "unseen_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.CenterCrop(224),\n",
    "                #transforms.Resize(224),\n",
    "                normalize,\n",
    "            ])\n",
    "\n",
    "test_seen_dataset = SN7Dataset(train=True, transform = seen_transforms)\n",
    "test_unseen_dataset = SN7Dataset(train=False, transform = unseen_transforms)\n",
    "\n",
    "test_seen_loader = DataLoader(dataset=test_seen_dataset, batch_size = batch_size, shuffle = False)\n",
    "test_unseen_loader = DataLoader(dataset=test_unseen_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de8edc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####FOR SUPERVSED MODEL!!!!\n",
    "\n",
    "backbone, embedding = resnet.__dict__['resnet50'](zero_init_residual=True)\n",
    "#state_dict = torch.load('../../Supervised_Model.pth', map_location=\"cpu\")\n",
    "state_dict = torch.load('../../Supervised_Model_Resnet50_Scheduler_3.pth', map_location=\"cpu\")\n",
    "if \"model\" in state_dict:\n",
    "    state_dict = state_dict[\"model\"]\n",
    "    state_dict = {key.replace(\"module.backbone.\", \"\"): value for (key, value) in state_dict.items()}\n",
    "backbone.load_state_dict(state_dict, strict=False)\n",
    "backbone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e55c550d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding)\n",
    "backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "297bb401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n"
     ]
    }
   ],
   "source": [
    "labels_list = []\n",
    "embeddings_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_seen_loader):\n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "        embedding = backbone(inputs.to(device))\n",
    "        embeddings_list.append(embedding)\n",
    "        labels_list.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c94851cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.35032326 2.06549621 0.42783338 ... 1.1723547  0.30932936 1.23909795]\n",
      " [0.94152844 0.99079067 1.6137706  ... 0.72333962 3.47263527 0.16361734]\n",
      " [0.13797015 0.54201233 0.24887271 ... 0.00878565 0.23420666 0.12703854]\n",
      " ...\n",
      " [1.74649823 0.15475015 0.22735029 ... 0.15124875 0.13775522 0.19115451]\n",
      " [1.11867118 0.07065032 2.10205579 ... 1.35179043 0.41330904 1.2248801 ]\n",
      " [0.779212   0.38801453 1.29889631 ... 0.62448919 0.1448952  1.82425857]]\n",
      "[18. 11.  5. ... 27. 29. 29.]\n"
     ]
    }
   ],
   "source": [
    "embeddings_seen_arr = np.zeros((len(test_seen_loader), 512))\n",
    "counter = 0\n",
    "for embedding in embeddings_list:\n",
    "    embeddings_seen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "#embeddings_unseen_arr = torch.tensor(embeddings_unseen_list)\n",
    "#labels_unseen_arr = np.array(labels_unseen_list)\n",
    "\n",
    "print(embeddings_seen_arr)\n",
    "labels_seen_arr = np.zeros(len(test_seen_loader))\n",
    "counter = 0\n",
    "for i in labels_list:\n",
    "    labels_seen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(labels_seen_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83c131d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n"
     ]
    }
   ],
   "source": [
    "labels_unseen_list = []\n",
    "embeddings_unseen_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_unseen_loader):\n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "        embedding = backbone(inputs.to(device))\n",
    "        embeddings_unseen_list.append(embedding)\n",
    "        labels_unseen_list.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b3de7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11262194 4.66052628 0.9667685  ... 0.04916208 0.76474029 0.23259388]\n",
      " [0.16098268 0.20799835 0.61079466 ... 2.96329856 0.5274967  1.05316317]\n",
      " [1.07519698 1.39229608 0.2308854  ... 0.41463381 0.07793288 1.25232983]\n",
      " ...\n",
      " [2.01059008 0.63771003 1.9256984  ... 2.52048445 2.7248323  0.72420555]\n",
      " [0.79220629 0.65308005 1.17284143 ... 3.36003113 1.24718118 1.4966855 ]\n",
      " [0.59548122 1.15680647 2.84711242 ... 0.94763601 0.02894997 2.22440743]]\n",
      "[ 7. 29. 18. ... 29. 29.  8.]\n"
     ]
    }
   ],
   "source": [
    "embeddings_unseen_arr = np.zeros((len(test_unseen_loader), 512))\n",
    "counter = 0\n",
    "for embedding in embeddings_unseen_list:\n",
    "    embeddings_unseen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "#embeddings_unseen_arr = torch.tensor(embeddings_unseen_list)\n",
    "#labels_unseen_arr = np.array(labels_unseen_list)\n",
    "\n",
    "print(embeddings_unseen_arr)\n",
    "labels_unseen_arr = np.zeros(len(test_unseen_loader))\n",
    "counter = 0\n",
    "for i in labels_unseen_list:\n",
    "    labels_unseen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(labels_unseen_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fd6f04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  5.  6.  7.  9. 10. 13. 14. 15. 16. 17. 18. 22. 23. 25. 26.\n",
      " 27. 29.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#JUST TRY DELETE LATER\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embeddings_unseen_arr_trial = embeddings_unseen_arr[0:60,:]\n",
    "labels_unseen_arr_trial = labels_unseen_arr[0:60]\n",
    "\n",
    "#pca = PCA(n_components=2)\n",
    "#pca.fit(embeddings_unseen_arr)\n",
    "#print(pca.explained_variance_ratio_)\n",
    "\n",
    "#embeddings_reduced = pca.transform(embeddings_unseen_arr)\n",
    "#print(embeddings_reduced)\n",
    "\n",
    "u_labels = np.unique(labels_unseen_arr_trial)\n",
    "print(u_labels)\n",
    "\n",
    "embeddings_reduced = TSNE(n_components=2, learning_rate='auto',init='random', perplexity = 10.0).fit_transform(embeddings_unseen_arr_trial)\n",
    "\n",
    "for i in u_labels:\n",
    "    \n",
    "    plt.scatter(embeddings_reduced[labels_unseen_arr_trial == i , 0] , embeddings_reduced[labels_unseen_arr_trial == i , 1] , label = i)\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a74e58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9084978843441467\n",
      "Accuracy: 0.9150211565585331\n",
      "Accuracy: 0.9157263751763046\n",
      "Accuracy: 0.9160789844851904\n",
      "Accuracy: 0.9074400564174894\n",
      "Accuracy: 0.9000352609308886\n",
      "Accuracy: 0.8961565585331452\n",
      "Accuracy: 0.8896332863187588\n",
      "Accuracy: 0.8413258110014105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbours = [1, 3, 5, 10, 20, 30, 40, 50, 200]\n",
    "\n",
    "for k in n_neighbours:\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(embeddings_seen_arr, labels_seen_arr)\n",
    "    labels_predicted = knn.predict(embeddings_unseen_arr)\n",
    "\n",
    "    #print('Accuracy' + str(k) + ':', np.sum(labels_unseen_arr == labels_predicted)/len(labels_unseen_arr))\n",
    "    print('Accuracy:', knn.score(embeddings_unseen_arr, labels_unseen_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d051c32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Afteer Hungarian Assignment: 0.5900916784203103\n",
      "(22688,)\n",
      "Accuracy Afteer Hungarian Assignment: 0.5744005641748943\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "#labels_predicted = AgglomerativeClustering(n_clusters = 20).fit_predict(embeddings_unseen_arr)\n",
    "\n",
    "#truth = labels_unseen_arr\n",
    "#pred = labels_predicted\n",
    "#print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )\n",
    "\n",
    "#print(sklearn.metrics.rand_score(labels_unseen_arr, labels_predicted))\n",
    "\n",
    "whole_test_set = np.concatenate((embeddings_seen_arr,embeddings_unseen_arr), axis=0)\n",
    "whole_labels = np.concatenate((labels_seen_arr, labels_unseen_arr))\n",
    "\n",
    "labels_predicted = AgglomerativeClustering(n_clusters = 31).fit_predict(whole_test_set)\n",
    "\n",
    "truth = whole_labels\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 31)[0] == truth )/len(truth) )\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#kmeans = KMeans(n_clusters=20, random_state=36).fit(embeddings_seen_arr)\n",
    "#labels_predicted = kmeans.predict(embeddings_unseen_arr)\n",
    "#print(labels_predicted.shape)\n",
    "\n",
    "#truth = labels_unseen_arr\n",
    "#pred = labels_predicted\n",
    "#print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )\n",
    "\n",
    "kmeans = KMeans(n_clusters=31, random_state=36).fit(whole_test_set)\n",
    "labels_predicted = kmeans.predict(whole_test_set)\n",
    "print(whole_labels.shape)\n",
    "\n",
    "truth = whole_labels\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 31)[0] == truth )/len(truth) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c213cf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Afteer Hungarian Assignment: 0.5599435825105783\n",
      "0.9169372844146313\n",
      "(5672,)\n",
      "Accuracy Afteer Hungarian Assignment: 0.53737658674189\n",
      "0.9148088199706571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "labels_predicted = AgglomerativeClustering(n_clusters = 31).fit_predict(embeddings_unseen_arr)\n",
    "\n",
    "truth = labels_unseen_arr\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 31)[0] == truth )/len(truth) )\n",
    "\n",
    "print(sklearn.metrics.rand_score(labels_unseen_arr, labels_predicted))\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=31, random_state=36).fit(embeddings_seen_arr)\n",
    "labels_predicted = kmeans.predict(embeddings_unseen_arr)\n",
    "print(labels_predicted.shape)\n",
    "\n",
    "truth = labels_unseen_arr\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 31)[0] == truth )/len(truth) )\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.rand_score(labels_unseen_arr, labels_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f01ae5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 22 27 ...  1 22 25]\n",
      "0.9148088199706571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=31, random_state=36).fit(embeddings_seen_arr)\n",
    "labels_predicted = kmeans.predict(embeddings_unseen_arr)\n",
    "print(labels_predicted)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.rand_score(labels_unseen_arr, labels_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "98d54fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17024, 512)\n",
      "(5664, 512)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_seen_arr.shape)\n",
    "print(embeddings_unseen_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8382c4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34444cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from geopy.geocoders import Nominatim\n",
    "import re\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sklearn\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import sklearn\n",
    "import math\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
    "from munkres import Munkres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb4d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import signal\n",
    "import sys\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import resnet\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "\n",
    "import glob\n",
    "from geopy.geocoders import Nominatim\n",
    "import re\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import math\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True   #OTHERWISE TRUNCATED IMAGE FILE ERROR SOMEWHERE IN ENUMERATE(DATALOADER)!!!!\n",
    "\n",
    "import resnet\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc235c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_preds(cluster_assignments, y_true, n_clusters):\n",
    "    '''\n",
    "    Computes the predicted labels, where label assignments now\n",
    "    correspond to the actual labels in y_true (as estimated by Munkres)\n",
    "\n",
    "    cluster_assignments:    array of labels, outputted by kmeans\n",
    "    y_true:                 true labels\n",
    "    n_clusters:             number of clusters in the dataset\n",
    "\n",
    "    returns:    a tuple containing the accuracy and confusion matrix,\n",
    "                in that order\n",
    "    '''\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_true, cluster_assignments, labels=None)\n",
    "    # compute accuracy based on optimal 1:1 assignment of clusters to labels\n",
    "    cost_matrix = calculate_cost_matrix(confusion_matrix, n_clusters)\n",
    "    indices = Munkres().compute(cost_matrix)\n",
    "    kmeans_to_true_cluster_labels = get_cluster_labels_from_indices(indices)\n",
    "    y_pred = kmeans_to_true_cluster_labels[cluster_assignments]\n",
    "    return y_pred, confusion_matrix \n",
    "\n",
    "def calculate_cost_matrix(C, n_clusters):\n",
    "    cost_matrix = np.zeros((n_clusters, n_clusters))\n",
    "\n",
    "    # cost_matrix[i,j] will be the cost of assigning cluster i to label j\n",
    "    for j in range(n_clusters):\n",
    "        s = np.sum(C[:,j]) # number of examples in cluster i\n",
    "        for i in range(n_clusters):\n",
    "            t = C[i,j]\n",
    "            cost_matrix[j,i] = s-t\n",
    "    return cost_matrix\n",
    "\n",
    "def get_cluster_labels_from_indices(indices):\n",
    "    n_clusters = len(indices)\n",
    "    clusterLabels = np.zeros(n_clusters)\n",
    "    for i in range(n_clusters):\n",
    "        clusterLabels[i] = indices[i][1]\n",
    "    return clusterLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f652d93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "truth = np.array([0,0,0,1,1,1,2,2,2,3,3,3])\n",
    "pred=np.array([1,1,1,1,3,3,2,2,2,2,0,0])\n",
    "print(np.sum( get_y_preds(pred, truth, 4)[0] == truth )/len(truth) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4290e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "077e6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SN7Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, transform=None, train=True):\n",
    "        \n",
    "        if train == True:\n",
    "            self.img_ids_labels = pd.read_csv(\"../../ids_and_labels_test_seen_filtered.csv\", header = None) \n",
    "        else:\n",
    "            self.img_ids_labels = pd.read_csv(\"../../ids_and_labels_test_unseen_filtered.csv\", header = None)\n",
    "            \n",
    "        self.img_dir = '/local/home/stuff/datasets/Challenge_7/test_public'\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #print(self.img_ids_labels.iloc[idx, 0])\n",
    "        image_id, patch_id = self.img_ids_labels.iloc[idx, 0].split(\"!\")[1],self.img_ids_labels.iloc[idx, 0].split(\"!\")[0]\n",
    "        pattern = \"mosaic_(.*?).tif\"\n",
    "        location_id = re.search(pattern, image_id).group(1)\n",
    "        #print(image_id)\n",
    "        #print(location_id)\n",
    "        img_path = os.path.join(self.img_dir, location_id, 'images_masked', image_id )\n",
    "        image = torchvision.transforms.ToTensor()(Image.open(img_path))[0:3,:,:]  #TAKE RGB CHANNELS ONLY FOR RESNET COMPATIBILITY!!!\n",
    "        \n",
    "        image_padded = torch.nn.functional.pad(image, pad=(0, 1024 - image.shape[2], 0, 1024 - image.shape[1]))\n",
    "        patches = image_padded.unfold(1, 256, 256).unfold(2, 256, 256)\n",
    "        patches = patches.reshape(3, -1, 256, 256)\n",
    "        patches = patches.permute(1,0,2,3)\n",
    "        \n",
    "        image = patches[int(patch_id)]\n",
    "        \n",
    "        label = torch.from_numpy(np.asarray(self.img_ids_labels.iloc[idx, 1])).type(torch.LongTensor)\n",
    "        \n",
    "        #patches = patches.view(-1, 3, 256, 256)\n",
    "        #print(patches.shape)\n",
    "        #label = label.flatten()\n",
    "        #label = label.type(torch.LongTensor)\n",
    "        \n",
    "        \n",
    "        image = self.transform(image)\n",
    "                \n",
    "            \n",
    "        #if self.target_transform:\n",
    "            #label = self.target_transform(label)\n",
    "            \n",
    "        \n",
    "        return image, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.img_ids_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee23f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform = transforms.Compose([ transforms.Resize(224), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) ])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "seen_transforms = transforms.Compose(\n",
    "            [   \n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.Resize(224),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "unseen_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.Resize(224),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "test_seen_dataset = SN7Dataset(train=True, transform = seen_transforms)\n",
    "test_unseen_dataset = SN7Dataset(train=False, transform = unseen_transforms)\n",
    "\n",
    "test_seen_loader = DataLoader(dataset=test_seen_dataset, batch_size = batch_size, shuffle = False)\n",
    "test_unseen_loader = DataLoader(dataset=test_unseen_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f78389b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33ba3e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12268863488, 12806062080)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.current_device()\n",
    "torch.cuda.set_device(0)\n",
    "print(torch.cuda.mem_get_info(torch.cuda.current_device()))\n",
    "device = torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fba5a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone, embedding = resnet.__dict__['resnet18'](zero_init_residual=True)\n",
    "#state_dict = torch.load('exp/resnet18_3.pth', map_location=\"cpu\")\n",
    "state_dict = torch.load('exp/resnet18_new_4096_200.pth', map_location=\"cpu\")\n",
    "if \"model\" in state_dict:\n",
    "    state_dict = state_dict[\"model\"]\n",
    "    state_dict = {key.replace(\"module.backbone.\", \"\"): value for (key, value) in state_dict.items()}\n",
    "backbone.load_state_dict(state_dict, strict=False)\n",
    "backbone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7052870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding)\n",
    "backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f1c147a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "labels_list = []\n",
    "embeddings_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_seen_loader):\n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "        embedding = backbone(inputs.to(device))\n",
    "        embeddings_list.append(embedding)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d799060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.84933168 1.82074761 0.36314702 ... 0.02030466 1.05495846 0.8029868 ]\n",
      " [0.33743006 1.45069015 0.43104547 ... 0.         1.5972333  0.54106802]\n",
      " [0.07839289 1.38415754 0.48859432 ... 0.15185308 0.88183391 0.27680403]\n",
      " ...\n",
      " [1.35910797 1.25444186 0.14902294 ... 0.08052941 0.69892234 1.07364929]\n",
      " [0.79495215 1.35501564 0.26626402 ... 0.27075168 0.98436499 0.46327376]\n",
      " [0.08317486 1.36209786 0.22185789 ... 0.26150912 0.88535386 0.17182502]]\n",
      "(5462, 512)\n",
      "[ 3.  3.  3. ... 15. 15. 15.]\n"
     ]
    }
   ],
   "source": [
    "embeddings_seen_arr = np.zeros((len(test_seen_loader), 512))\n",
    "counter = 0\n",
    "for embedding in embeddings_list:\n",
    "    embeddings_seen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "#embeddings_unseen_arr = torch.tensor(embeddings_unseen_list)\n",
    "#labels_unseen_arr = np.array(labels_unseen_list)\n",
    "\n",
    "print(embeddings_seen_arr)\n",
    "print(embeddings_seen_arr.shape)\n",
    "labels_seen_arr = np.zeros(len(test_seen_loader))\n",
    "counter = 0\n",
    "for i in labels_list:\n",
    "    labels_seen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(labels_seen_arr)\n",
    "\n",
    "#np.savetxt(\"seen_embeddings.csv\", embeddings_seen_arr, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea68cfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "labels_unseen_list = []\n",
    "embeddings_unseen_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_unseen_loader):\n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "        embedding = backbone(inputs.to(device))\n",
    "        embeddings_unseen_list.append(embedding)\n",
    "        labels_unseen_list.append(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a6c59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_unseen_arr = np.zeros((len(test_unseen_loader), 512))\n",
    "counter = 0\n",
    "for embedding in embeddings_unseen_list:\n",
    "    embeddings_unseen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "#embeddings_unseen_arr = torch.tensor(embeddings_unseen_list)\n",
    "#labels_unseen_arr = np.array(labels_unseen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "263a5862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03378766 2.22987199 1.73538339 ... 0.         0.71346271 0.41021493]\n",
      " [0.97294807 1.97263789 1.47781682 ... 0.         0.64721411 0.44616655]\n",
      " [1.6592083  1.36460984 0.55589473 ... 0.00904335 1.22592342 0.61254567]\n",
      " ...\n",
      " [0.70913774 1.37493384 0.64981061 ... 0.         1.11687827 1.28246403]\n",
      " [1.03908455 1.21448815 0.35309085 ... 0.         0.70105791 1.26898956]\n",
      " [0.24488375 1.27737582 1.02940226 ... 0.         0.99306214 0.45140457]]\n",
      "(1794, 512)\n",
      "[19. 19. 19. ... 16. 16. 16.]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_unseen_arr)\n",
    "print(embeddings_unseen_arr.shape)\n",
    "labels_unseen_arr = np.zeros(len(test_unseen_loader))\n",
    "counter = 0\n",
    "for i in labels_unseen_list:\n",
    "    labels_unseen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(labels_unseen_arr)\n",
    "\n",
    "#np.savetxt(\"unseen_embeddings.csv\", embeddings_unseen_arr, delimiter=\",\", fmt='%s')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64711a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_seen_arr = torch.nn.functional.normalize(torch.Tensor(embeddings_seen_arr), dim=1, p=2)\n",
    "embeddings_unseen_arr = torch.nn.functional.normalize(torch.Tensor(embeddings_unseen_arr), dim=1, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4645602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  2. 14. 19.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#JUST TRY DELETE LATER\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embeddings_unseen_arr_trial = embeddings_unseen_arr[0:60,:]\n",
    "labels_unseen_arr_trial = labels_unseen_arr[0:60]\n",
    "\n",
    "#pca = PCA(n_components=2)\n",
    "#pca.fit(embeddings_unseen_arr)\n",
    "#print(pca.explained_variance_ratio_)\n",
    "\n",
    "#embeddings_reduced = pca.transform(embeddings_unseen_arr)\n",
    "#print(embeddings_reduced)\n",
    "\n",
    "u_labels = np.unique(labels_unseen_arr_trial)\n",
    "print(u_labels)\n",
    "\n",
    "embeddings_reduced = TSNE(n_components=2, learning_rate='auto',init='random', perplexity = 10.0).fit_transform(embeddings_unseen_arr_trial)\n",
    "\n",
    "for i in u_labels:\n",
    "    \n",
    "    plt.scatter(embeddings_reduced[labels_unseen_arr_trial == i , 0] , embeddings_reduced[labels_unseen_arr_trial == i , 1] , label = i)\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9146f3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9754738015607581\n",
      "Accuracy: 0.9704570791527313\n",
      "Accuracy: 0.9671125975473801\n",
      "Accuracy: 0.9548494983277592\n",
      "Accuracy: 0.9297658862876255\n",
      "Accuracy: 0.8913043478260869\n",
      "Accuracy: 0.8639910813823858\n",
      "Accuracy: 0.830546265328874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbours = [1, 3, 5, 10, 20, 30, 40, 50]\n",
    "\n",
    "for k in n_neighbours:\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(embeddings_seen_arr, labels_seen_arr)\n",
    "    labels_predicted = knn.predict(embeddings_unseen_arr)\n",
    "\n",
    "    #print('Accuracy' + str(k) + ':', np.sum(labels_unseen_arr == labels_predicted)/len(labels_unseen_arr))\n",
    "    print('Accuracy:', knn.score(embeddings_unseen_arr, labels_unseen_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e5e1dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Afteer Hungarian Assignment: 0.2684674751929438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "#labels_predicted = AgglomerativeClustering(n_clusters = 20).fit_predict(embeddings_unseen_arr)\n",
    "\n",
    "#truth = labels_unseen_arr\n",
    "#pred = labels_predicted\n",
    "#print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )\n",
    "\n",
    "#print(sklearn.metrics.rand_score(labels_unseen_arr, labels_predicted))\n",
    "\n",
    "whole_test_set = np.concatenate((embeddings_seen_arr,embeddings_unseen_arr), axis=0)\n",
    "whole_labels = np.concatenate((labels_seen_arr, labels_unseen_arr))\n",
    "\n",
    "labels_predicted = AgglomerativeClustering(n_clusters = 20).fit_predict(whole_test_set)\n",
    "\n",
    "truth = whole_labels\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cd153ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7256,)\n",
      "Accuracy Afteer Hungarian Assignment: 0.2909316427783903\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#kmeans = KMeans(n_clusters=20, random_state=36).fit(embeddings_seen_arr)\n",
    "#labels_predicted = kmeans.predict(embeddings_unseen_arr)\n",
    "#print(labels_predicted.shape)\n",
    "\n",
    "#truth = labels_unseen_arr\n",
    "#pred = labels_predicted\n",
    "#print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )\n",
    "\n",
    "kmeans = KMeans(n_clusters=20, random_state=36).fit(whole_test_set)\n",
    "labels_predicted = kmeans.predict(whole_test_set)\n",
    "print(whole_labels.shape)\n",
    "\n",
    "truth = whole_labels\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "742bef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "\n",
    "seen_transforms = transforms.Compose(\n",
    "            [   \n",
    "                #transforms.RandomResizedCrop(224),\n",
    "                #transforms.RandomHorizontalFlip(),\n",
    "                transforms.Resize(224),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "unseen_transforms = transforms.Compose(\n",
    "            [\n",
    "                #transforms.CenterCrop(224),\n",
    "                transforms.Resize(224),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "test_seen_dataset = SN7Dataset(train=True, transform = seen_transforms)\n",
    "test_unseen_dataset = SN7Dataset(train=False, transform = unseen_transforms)\n",
    "\n",
    "test_seen_loader = DataLoader(dataset=test_seen_dataset, batch_size = batch_size, shuffle = False)\n",
    "test_unseen_loader = DataLoader(dataset=test_unseen_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de8edc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####FOR SUPERVİSED MODEL!!!!\n",
    "\n",
    "backbone_supervised, embedding = resnet.__dict__['resnet18'](zero_init_residual=True)\n",
    "state_dict = torch.load('../../Supervised_Model.pth', map_location=\"cpu\")\n",
    "if \"model\" in state_dict:\n",
    "    state_dict = state_dict[\"model\"]\n",
    "    state_dict = {key.replace(\"module.backbone.\", \"\"): value for (key, value) in state_dict.items()}\n",
    "backbone_supervised.load_state_dict(state_dict, strict=False)\n",
    "backbone_supervised.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e55c550d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding)\n",
    "backbone_supervised.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "297bb401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "labels_list_supervised = []\n",
    "embeddings_list_supervised = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_seen_loader):\n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "        embedding = backbone_supervised(inputs.to(device))\n",
    "        embeddings_list_supervised.append(embedding)\n",
    "        labels_list_supervised.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c94851cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98990053 1.18434203 1.19734979 ... 0.98103726 1.14045954 0.97316587]\n",
      " [0.07901664 0.33444253 0.29753384 ... 0.97941011 0.29413813 1.05486298]\n",
      " [0.37780041 1.05143428 0.37437317 ... 1.13477325 0.25137791 1.51236057]\n",
      " ...\n",
      " [0.51421666 0.85863733 3.15439558 ... 0.76025057 3.37689042 0.3032504 ]\n",
      " [0.45767251 0.93023998 1.78231907 ... 0.8590706  2.81070995 0.5458802 ]\n",
      " [0.3215214  1.87477493 1.50748575 ... 0.47254413 5.23996973 0.11050321]]\n",
      "[ 3.  3.  3. ... 15. 15. 15.]\n"
     ]
    }
   ],
   "source": [
    "embeddings_seen_arr_supervised = np.zeros((len(test_seen_loader), 512))\n",
    "counter = 0\n",
    "for embedding in embeddings_list_supervised:\n",
    "    embeddings_seen_arr_supervised[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "#embeddings_unseen_arr = torch.tensor(embeddings_unseen_list)\n",
    "#labels_unseen_arr = np.array(labels_unseen_list)\n",
    "\n",
    "print(embeddings_seen_arr_supervised)\n",
    "labels_seen_arr_supervised = np.zeros(len(test_seen_loader))\n",
    "counter = 0\n",
    "for i in labels_list_supervised:\n",
    "    labels_seen_arr_supervised[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(labels_seen_arr_supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83c131d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "labels_unseen_list_supervised = []\n",
    "embeddings_unseen_list_supervised = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_unseen_loader):\n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "        embedding = backbone_supervised(inputs.to(device))\n",
    "        embeddings_unseen_list_supervised.append(embedding)\n",
    "        labels_unseen_list_supervised.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b3de7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.77482378 1.13795292 0.56594765 ... 0.81937766 0.47618365 1.10676646]\n",
      " [0.69428414 0.59353715 1.15964222 ... 0.71401119 0.21334901 1.49167025]\n",
      " [0.07418514 0.29301873 1.92800593 ... 0.39384639 0.12489521 2.4191699 ]\n",
      " ...\n",
      " [1.48141778 0.69018739 1.13396478 ... 1.11372292 0.7536543  1.26525307]\n",
      " [1.47372377 0.45799524 1.76863265 ... 1.54155707 1.17285073 1.04124689]\n",
      " [0.77819401 0.84592283 1.7089448  ... 1.47475302 1.30193305 1.01947498]]\n",
      "[19. 19. 19. ... 16. 16. 16.]\n"
     ]
    }
   ],
   "source": [
    "embeddings_unseen_arr_supervised = np.zeros((len(test_unseen_loader), 512))\n",
    "counter = 0\n",
    "for embedding in embeddings_unseen_list_supervised:\n",
    "    embeddings_unseen_arr_supervised[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "#embeddings_unseen_arr = torch.tensor(embeddings_unseen_list)\n",
    "#labels_unseen_arr = np.array(labels_unseen_list)\n",
    "\n",
    "print(embeddings_unseen_arr_supervised)\n",
    "labels_unseen_arr_supervised = np.zeros(len(test_unseen_loader))\n",
    "counter = 0\n",
    "for i in labels_unseen_list_supervised:\n",
    "    labels_unseen_arr_supervised[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(labels_unseen_arr_supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86a70ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  2. 14. 19.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#JUST TRY DELETE LATER\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embeddings_unseen_arr_trial = embeddings_unseen_arr_supervised[0:60,:]\n",
    "labels_unseen_arr_trial = labels_unseen_arr_supervised[0:60]\n",
    "\n",
    "#pca = PCA(n_components=2)\n",
    "#pca.fit(embeddings_unseen_arr)\n",
    "#print(pca.explained_variance_ratio_)\n",
    "\n",
    "#embeddings_reduced = pca.transform(embeddings_unseen_arr)\n",
    "#print(embeddings_reduced)\n",
    "\n",
    "u_labels = np.unique(labels_unseen_arr_trial)\n",
    "print(u_labels)\n",
    "\n",
    "embeddings_reduced = TSNE(n_components=2, learning_rate='auto',init='random', perplexity = 10.0).fit_transform(embeddings_unseen_arr_trial)\n",
    "\n",
    "for i in u_labels:\n",
    "    \n",
    "    plt.scatter(embeddings_reduced[labels_unseen_arr_trial == i , 0] , embeddings_reduced[labels_unseen_arr_trial == i , 1] , label = i)\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a74e58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8366778149386845\n",
      "Accuracy: 0.8299888517279822\n",
      "Accuracy: 0.8333333333333334\n",
      "Accuracy: 0.8205128205128205\n",
      "Accuracy: 0.802675585284281\n",
      "Accuracy: 0.7948717948717948\n",
      "Accuracy: 0.7842809364548495\n",
      "Accuracy: 0.7714604236343366\n",
      "Accuracy: 0.7028985507246377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbours = [1, 3, 5, 10, 20, 30, 40, 50, 200]\n",
    "\n",
    "for k in n_neighbours:\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(embeddings_seen_arr_supervised, labels_seen_arr_supervised)\n",
    "    labels_predicted = knn.predict(embeddings_unseen_arr_supervised)\n",
    "\n",
    "    #print('Accuracy' + str(k) + ':', np.sum(labels_unseen_arr == labels_predicted)/len(labels_unseen_arr))\n",
    "    print('Accuracy:', knn.score(embeddings_unseen_arr_supervised, labels_unseen_arr_supervised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f01ae5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5462, 512)\n",
      "(1794, 512)\n",
      "[ 3  3  3 ... 10 10 10]\n",
      "Accuracy Afteer Hungarian Assignment: 0.4455622932745314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "print(embeddings_seen_arr_supervised.shape)\n",
    "print(embeddings_unseen_arr_supervised.shape)\n",
    "\n",
    "whole_test_set = np.concatenate((embeddings_seen_arr_supervised,embeddings_unseen_arr_supervised), axis=0)\n",
    "whole_labels = np.concatenate((labels_seen_arr_supervised, labels_unseen_arr_supervised))\n",
    "\n",
    "kmeans = KMeans(n_clusters=20, random_state=36).fit(whole_test_set)\n",
    "labels_predicted = kmeans.predict(whole_test_set)\n",
    "print(labels_predicted)\n",
    "\n",
    "truth = whole_labels\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d54fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

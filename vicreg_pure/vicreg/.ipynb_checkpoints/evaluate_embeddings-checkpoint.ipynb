{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34444cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from geopy.geocoders import Nominatim\n",
    "import re\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sklearn\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import sklearn\n",
    "import math\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
    "from munkres import Munkres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb4d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import signal\n",
    "import sys\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import resnet\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "\n",
    "import glob\n",
    "from geopy.geocoders import Nominatim\n",
    "import re\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import math\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True   #OTHERWISE TRUNCATED IMAGE FILE ERROR SOMEWHERE IN ENUMERATE(DATALOADER)!!!!\n",
    "\n",
    "import resnet\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc235c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_preds(cluster_assignments, y_true, n_clusters):\n",
    "    '''\n",
    "    Computes the predicted labels, where label assignments now\n",
    "    correspond to the actual labels in y_true (as estimated by Munkres)\n",
    "\n",
    "    cluster_assignments:    array of labels, outputted by kmeans\n",
    "    y_true:                 true labels\n",
    "    n_clusters:             number of clusters in the dataset\n",
    "\n",
    "    returns:    a tuple containing the accuracy and confusion matrix,\n",
    "                in that order\n",
    "    '''\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_true, cluster_assignments, labels=None)\n",
    "    # compute accuracy based on optimal 1:1 assignment of clusters to labels\n",
    "    cost_matrix = calculate_cost_matrix(confusion_matrix, n_clusters)\n",
    "    indices = Munkres().compute(cost_matrix)\n",
    "    kmeans_to_true_cluster_labels = get_cluster_labels_from_indices(indices)\n",
    "    y_pred = kmeans_to_true_cluster_labels[cluster_assignments]\n",
    "    return y_pred, confusion_matrix \n",
    "\n",
    "def calculate_cost_matrix(C, n_clusters):\n",
    "    cost_matrix = np.zeros((n_clusters, n_clusters))\n",
    "\n",
    "    # cost_matrix[i,j] will be the cost of assigning cluster i to label j\n",
    "    for j in range(n_clusters):\n",
    "        s = np.sum(C[:,j]) # number of examples in cluster i\n",
    "        for i in range(n_clusters):\n",
    "            t = C[i,j]\n",
    "            cost_matrix[j,i] = s-t\n",
    "    return cost_matrix\n",
    "\n",
    "def get_cluster_labels_from_indices(indices):\n",
    "    n_clusters = len(indices)\n",
    "    clusterLabels = np.zeros(n_clusters)\n",
    "    for i in range(n_clusters):\n",
    "        clusterLabels[i] = indices[i][1]\n",
    "    return clusterLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f652d93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "truth = np.array([0,0,0,1,1,1,2,2,2,3,3,3])\n",
    "pred=np.array([1,1,1,1,3,3,2,2,2,2,0,0])\n",
    "print(np.sum( get_y_preds(pred, truth, 4)[0] == truth )/len(truth) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4290e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "077e6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SN7Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, transform=None, train=True):\n",
    "        \n",
    "        if train == True:\n",
    "            self.img_ids_labels = pd.read_csv(\"../../ids_and_labels_test_seen_filtered.csv\", header = None) \n",
    "        else:\n",
    "            self.img_ids_labels = pd.read_csv(\"../../ids_and_labels_test_unseen_filtered.csv\", header = None)\n",
    "            \n",
    "        self.img_dir = '/local/home/stuff/datasets/Challenge_7/test_public'\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #print(self.img_ids_labels.iloc[idx, 0])\n",
    "        image_id, patch_id = self.img_ids_labels.iloc[idx, 0].split(\"!\")[1],self.img_ids_labels.iloc[idx, 0].split(\"!\")[0]\n",
    "        pattern = \"mosaic_(.*?).tif\"\n",
    "        location_id = re.search(pattern, image_id).group(1)\n",
    "        #print(image_id)\n",
    "        #print(location_id)\n",
    "        img_path = os.path.join(self.img_dir, location_id, 'images_masked', image_id )\n",
    "        image = torchvision.transforms.ToTensor()(Image.open(img_path))[0:3,:,:]  #TAKE RGB CHANNELS ONLY FOR RESNET COMPATIBILITY!!!\n",
    "        \n",
    "        image_padded = torch.nn.functional.pad(image, pad=(0, 1024 - image.shape[2], 0, 1024 - image.shape[1]))\n",
    "        patches = image_padded.unfold(1, 256, 256).unfold(2, 256, 256)\n",
    "        patches = patches.reshape(3, -1, 256, 256)\n",
    "        patches = patches.permute(1,0,2,3)\n",
    "        \n",
    "        image = patches[int(patch_id)]\n",
    "        \n",
    "        label = torch.from_numpy(np.asarray(self.img_ids_labels.iloc[idx, 1])).type(torch.LongTensor)\n",
    "        \n",
    "        #patches = patches.view(-1, 3, 256, 256)\n",
    "        #print(patches.shape)\n",
    "        #label = label.flatten()\n",
    "        #label = label.type(torch.LongTensor)\n",
    "        \n",
    "        \n",
    "        image = self.transform(image)\n",
    "                \n",
    "            \n",
    "        #if self.target_transform:\n",
    "            #label = self.target_transform(label)\n",
    "            \n",
    "        \n",
    "        return image, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.img_ids_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee23f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform = transforms.Compose([ transforms.Resize(224), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) ])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "seen_transforms = transforms.Compose(\n",
    "            [   \n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.Resize(224),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "unseen_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.Resize(224),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "test_seen_dataset = SN7Dataset(train=True, transform = seen_transforms)\n",
    "test_unseen_dataset = SN7Dataset(train=False, transform = unseen_transforms)\n",
    "\n",
    "test_seen_loader = DataLoader(dataset=test_seen_dataset, batch_size = batch_size, shuffle = False)\n",
    "test_unseen_loader = DataLoader(dataset=test_unseen_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91cbe298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33ba3e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12268863488, 12806062080)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.current_device()\n",
    "torch.cuda.set_device(2)\n",
    "print(torch.cuda.mem_get_info(torch.cuda.current_device()))\n",
    "device = torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fba5a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone, embedding = resnet.__dict__['resnet50'](zero_init_residual=True)\n",
    "#state_dict = torch.load('exp/resnet18_3.pth', map_location=\"cpu\")\n",
    "#state_dict = torch.load('exp/resnet18_new_4096_200.pth', map_location=\"cpu\")\n",
    "#state_dict = torch.load('exp/resnet18_100_newest.pth', map_location=\"cpu\")\n",
    "state_dict = torch.load('exp/resnet50_100epochs_16_factor.pth', map_location=\"cpu\")\n",
    "if \"model\" in state_dict:\n",
    "    state_dict = state_dict[\"model\"]\n",
    "    state_dict = {key.replace(\"module.backbone.\", \"\"): value for (key, value) in state_dict.items()}\n",
    "backbone.load_state_dict(state_dict, strict=False)\n",
    "backbone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7052870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding)\n",
    "backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f1c147a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "labels_list = []\n",
    "embeddings_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_seen_loader):\n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "        embedding = backbone(inputs.to(device))\n",
    "        embeddings_list.append(embedding)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d799060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20853068 0.19437198 0.57276505 ... 0.36167705 0.08574956 0.59034353]\n",
      " [0.45979378 0.03575213 0.52442002 ... 0.44226626 0.11973569 0.41065681]\n",
      " [0.15951581 0.08635496 0.74822384 ... 0.35065997 0.08699681 0.45331398]\n",
      " ...\n",
      " [0.18252598 0.15111955 0.62263113 ... 0.37130108 0.1961395  0.40427911]\n",
      " [0.12181438 0.19928093 0.55614281 ... 0.32079893 0.09676545 0.40473664]\n",
      " [0.14527759 0.         0.64794964 ... 0.39010319 0.14751256 0.38890183]]\n",
      "(5462, 2048)\n",
      "[ 3.  3.  3. ... 15. 15. 15.]\n"
     ]
    }
   ],
   "source": [
    "embeddings_seen_arr = np.zeros((len(test_seen_loader), 2048))\n",
    "counter = 0\n",
    "for embedding in embeddings_list:\n",
    "    embeddings_seen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "#embeddings_unseen_arr = torch.tensor(embeddings_unseen_list)\n",
    "#labels_unseen_arr = np.array(labels_unseen_list)\n",
    "\n",
    "print(embeddings_seen_arr)\n",
    "print(embeddings_seen_arr.shape)\n",
    "labels_seen_arr = np.zeros(len(test_seen_loader))\n",
    "counter = 0\n",
    "for i in labels_list:\n",
    "    labels_seen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(labels_seen_arr)\n",
    "\n",
    "#np.savetxt(\"seen_embeddings.csv\", embeddings_seen_arr, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea68cfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "labels_unseen_list = []\n",
    "embeddings_unseen_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_unseen_loader):\n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "        embedding = backbone(inputs.to(device))\n",
    "        embeddings_unseen_list.append(embedding)\n",
    "        labels_unseen_list.append(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_unseen_arr = np.zeros((len(test_unseen_loader), 2048))\n",
    "counter = 0\n",
    "for embedding in embeddings_unseen_list:\n",
    "    embeddings_unseen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "#embeddings_unseen_arr = torch.tensor(embeddings_unseen_list)\n",
    "#labels_unseen_arr = np.array(labels_unseen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263a5862",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings_unseen_arr)\n",
    "print(embeddings_unseen_arr.shape)\n",
    "labels_unseen_arr = np.zeros(len(test_unseen_loader))\n",
    "counter = 0\n",
    "for i in labels_unseen_list:\n",
    "    labels_unseen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(labels_unseen_arr)\n",
    "\n",
    "#np.savetxt(\"unseen_embeddings.csv\", embeddings_unseen_arr, delimiter=\",\", fmt='%s')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_seen_arr = torch.nn.functional.normalize(torch.Tensor(embeddings_seen_arr), dim=1, p=2)\n",
    "#embeddings_unseen_arr = torch.nn.functional.normalize(torch.Tensor(embeddings_unseen_arr), dim=1, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4645602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JUST TRY DELETE LATER\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embeddings_unseen_arr_trial = embeddings_unseen_arr[0:60,:]\n",
    "labels_unseen_arr_trial = labels_unseen_arr[0:60]\n",
    "\n",
    "#pca = PCA(n_components=2)\n",
    "#pca.fit(embeddings_unseen_arr)\n",
    "#print(pca.explained_variance_ratio_)\n",
    "\n",
    "#embeddings_reduced = pca.transform(embeddings_unseen_arr)\n",
    "#print(embeddings_reduced)\n",
    "\n",
    "u_labels = np.unique(labels_unseen_arr_trial)\n",
    "print(u_labels)\n",
    "\n",
    "embeddings_reduced = TSNE(n_components=2, learning_rate='auto',init='random', perplexity = 10.0).fit_transform(embeddings_unseen_arr_trial)\n",
    "\n",
    "for i in u_labels:\n",
    "    \n",
    "    plt.scatter(embeddings_reduced[labels_unseen_arr_trial == i , 0] , embeddings_reduced[labels_unseen_arr_trial == i , 1] , label = i)\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9146f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbours = [1, 3, 5, 10, 20, 30, 40, 50, 200]\n",
    "\n",
    "for k in n_neighbours:\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(embeddings_seen_arr, labels_seen_arr)\n",
    "    labels_predicted = knn.predict(embeddings_unseen_arr)\n",
    "\n",
    "    #print('Accuracy' + str(k) + ':', np.sum(labels_unseen_arr == labels_predicted)/len(labels_unseen_arr))\n",
    "    print('Accuracy:', knn.score(embeddings_unseen_arr, labels_unseen_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5e1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "#labels_predicted = AgglomerativeClustering(n_clusters = 20).fit_predict(embeddings_unseen_arr)\n",
    "\n",
    "#truth = labels_unseen_arr\n",
    "#pred = labels_predicted\n",
    "#print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )\n",
    "\n",
    "#print(sklearn.metrics.rand_score(labels_unseen_arr, labels_predicted))\n",
    "\n",
    "whole_test_set = np.concatenate((embeddings_seen_arr,embeddings_unseen_arr), axis=0)\n",
    "whole_labels = np.concatenate((labels_seen_arr, labels_unseen_arr))\n",
    "\n",
    "labels_predicted = AgglomerativeClustering(n_clusters = 20).fit_predict(whole_test_set)\n",
    "\n",
    "truth = whole_labels\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd153ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#kmeans = KMeans(n_clusters=20, random_state=36).fit(embeddings_seen_arr)\n",
    "#labels_predicted = kmeans.predict(embeddings_unseen_arr)\n",
    "#print(labels_predicted.shape)\n",
    "\n",
    "#truth = labels_unseen_arr\n",
    "#pred = labels_predicted\n",
    "#print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )\n",
    "\n",
    "kmeans = KMeans(n_clusters=20, random_state=36).fit(whole_test_set)\n",
    "labels_predicted = kmeans.predict(whole_test_set)\n",
    "print(whole_labels.shape)\n",
    "\n",
    "truth = whole_labels\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "742bef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize = torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "seen_transforms = transforms.Compose(\n",
    "            [   \n",
    "                #transforms.RandomResizedCrop(224),\n",
    "                #transforms.RandomHorizontalFlip(),\n",
    "                transforms.Resize(224),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "unseen_transforms = transforms.Compose(\n",
    "            [\n",
    "                #transforms.CenterCrop(224),\n",
    "                transforms.Resize(224),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "test_seen_dataset = SN7Dataset(train=True, transform = seen_transforms)\n",
    "test_unseen_dataset = SN7Dataset(train=False, transform = unseen_transforms)\n",
    "\n",
    "test_seen_loader = DataLoader(dataset=test_seen_dataset, batch_size = batch_size, shuffle = False)\n",
    "test_unseen_loader = DataLoader(dataset=test_unseen_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de8edc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (last_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####FOR SUPERVİSED MODEL!!!!\n",
    "\n",
    "backbone_supervised, embedding = resnet.__dict__['resnet50'](zero_init_residual=True)\n",
    "#state_dict = torch.load('../../Supervised_Model.pth', map_location=\"cpu\")\n",
    "state_dict = torch.load('../../Supervised_Model_Resnet50_Scheduler_3.pth', map_location=\"cpu\")\n",
    "if \"model\" in state_dict:\n",
    "    state_dict = state_dict[\"model\"]\n",
    "    state_dict = {key.replace(\"module.backbone.\", \"\"): value for (key, value) in state_dict.items()}\n",
    "backbone_supervised.load_state_dict(state_dict, strict=False)\n",
    "backbone_supervised.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e55c550d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding)\n",
    "backbone_supervised.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "297bb401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "labels_list_supervised = []\n",
    "embeddings_list_supervised = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_seen_loader):\n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "        embedding = backbone_supervised(inputs.to(device))\n",
    "        embeddings_list_supervised.append(embedding)\n",
    "        labels_list_supervised.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c94851cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98990053 1.18434203 1.19734979 ... 0.98103726 1.14045954 0.97316587]\n",
      " [0.07901664 0.33444253 0.29753384 ... 0.97941011 0.29413813 1.05486298]\n",
      " [0.37780041 1.05143428 0.37437317 ... 1.13477325 0.25137791 1.51236057]\n",
      " ...\n",
      " [0.51421666 0.85863733 3.15439558 ... 0.76025057 3.37689042 0.3032504 ]\n",
      " [0.45767251 0.93023998 1.78231907 ... 0.8590706  2.81070995 0.5458802 ]\n",
      " [0.3215214  1.87477493 1.50748575 ... 0.47254413 5.23996973 0.11050321]]\n",
      "[ 3.  3.  3. ... 15. 15. 15.]\n"
     ]
    }
   ],
   "source": [
    "embeddings_seen_arr_supervised = np.zeros((len(test_seen_loader), 2048))\n",
    "counter = 0\n",
    "for embedding in embeddings_list_supervised:\n",
    "    embeddings_seen_arr_supervised[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "#embeddings_unseen_arr = torch.tensor(embeddings_unseen_list)\n",
    "#labels_unseen_arr = np.array(labels_unseen_list)\n",
    "\n",
    "print(embeddings_seen_arr_supervised)\n",
    "labels_seen_arr_supervised = np.zeros(len(test_seen_loader))\n",
    "counter = 0\n",
    "for i in labels_list_supervised:\n",
    "    labels_seen_arr_supervised[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(labels_seen_arr_supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83c131d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "labels_unseen_list_supervised = []\n",
    "embeddings_unseen_list_supervised = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_unseen_loader):\n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "        embedding = backbone_supervised(inputs.to(device))\n",
    "        embeddings_unseen_list_supervised.append(embedding)\n",
    "        labels_unseen_list_supervised.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b3de7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.77482378 1.13795292 0.56594765 ... 0.81937766 0.47618365 1.10676646]\n",
      " [0.69428414 0.59353715 1.15964222 ... 0.71401119 0.21334901 1.49167025]\n",
      " [0.07418514 0.29301873 1.92800593 ... 0.39384639 0.12489521 2.4191699 ]\n",
      " ...\n",
      " [1.48141778 0.69018739 1.13396478 ... 1.11372292 0.7536543  1.26525307]\n",
      " [1.47372377 0.45799524 1.76863265 ... 1.54155707 1.17285073 1.04124689]\n",
      " [0.77819401 0.84592283 1.7089448  ... 1.47475302 1.30193305 1.01947498]]\n",
      "[19. 19. 19. ... 16. 16. 16.]\n"
     ]
    }
   ],
   "source": [
    "embeddings_unseen_arr_supervised = np.zeros((len(test_unseen_loader), 2048))\n",
    "counter = 0\n",
    "for embedding in embeddings_unseen_list_supervised:\n",
    "    embeddings_unseen_arr_supervised[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "#embeddings_unseen_arr = torch.tensor(embeddings_unseen_list)\n",
    "#labels_unseen_arr = np.array(labels_unseen_list)\n",
    "\n",
    "print(embeddings_unseen_arr_supervised)\n",
    "labels_unseen_arr_supervised = np.zeros(len(test_unseen_loader))\n",
    "counter = 0\n",
    "for i in labels_unseen_list_supervised:\n",
    "    labels_unseen_arr_supervised[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(labels_unseen_arr_supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86a70ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  2. 14. 19.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#JUST TRY DELETE LATER\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embeddings_unseen_arr_trial = embeddings_unseen_arr_supervised[0:60,:]\n",
    "labels_unseen_arr_trial = labels_unseen_arr_supervised[0:60]\n",
    "\n",
    "#pca = PCA(n_components=2)\n",
    "#pca.fit(embeddings_unseen_arr)\n",
    "#print(pca.explained_variance_ratio_)\n",
    "\n",
    "#embeddings_reduced = pca.transform(embeddings_unseen_arr)\n",
    "#print(embeddings_reduced)\n",
    "\n",
    "u_labels = np.unique(labels_unseen_arr_trial)\n",
    "print(u_labels)\n",
    "\n",
    "embeddings_reduced = TSNE(n_components=2, learning_rate='auto',init='random', perplexity = 10.0).fit_transform(embeddings_unseen_arr_trial)\n",
    "\n",
    "for i in u_labels:\n",
    "    \n",
    "    plt.scatter(embeddings_reduced[labels_unseen_arr_trial == i , 0] , embeddings_reduced[labels_unseen_arr_trial == i , 1] , label = i)\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a74e58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8366778149386845\n",
      "Accuracy: 0.8299888517279822\n",
      "Accuracy: 0.8333333333333334\n",
      "Accuracy: 0.8205128205128205\n",
      "Accuracy: 0.802675585284281\n",
      "Accuracy: 0.7948717948717948\n",
      "Accuracy: 0.7842809364548495\n",
      "Accuracy: 0.7714604236343366\n",
      "Accuracy: 0.7028985507246377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbours = [1, 3, 5, 10, 20, 30, 40, 50, 200]\n",
    "\n",
    "for k in n_neighbours:\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(embeddings_seen_arr_supervised, labels_seen_arr_supervised)\n",
    "    labels_predicted = knn.predict(embeddings_unseen_arr_supervised)\n",
    "\n",
    "    #print('Accuracy' + str(k) + ':', np.sum(labels_unseen_arr == labels_predicted)/len(labels_unseen_arr))\n",
    "    print('Accuracy:', knn.score(embeddings_unseen_arr_supervised, labels_unseen_arr_supervised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f01ae5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5462, 512)\n",
      "(1794, 512)\n",
      "[ 3  3  3 ... 10 10 10]\n",
      "Accuracy Afteer Hungarian Assignment: 0.4455622932745314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "print(embeddings_seen_arr_supervised.shape)\n",
    "print(embeddings_unseen_arr_supervised.shape)\n",
    "\n",
    "whole_test_set = np.concatenate((embeddings_seen_arr_supervised,embeddings_unseen_arr_supervised), axis=0)\n",
    "whole_labels = np.concatenate((labels_seen_arr_supervised, labels_unseen_arr_supervised))\n",
    "\n",
    "kmeans = KMeans(n_clusters=20, random_state=36).fit(whole_test_set)\n",
    "labels_predicted = kmeans.predict(whole_test_set)\n",
    "print(labels_predicted)\n",
    "\n",
    "truth = whole_labels\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d54fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "class FaissKNeighbors:\n",
    "    def __init__(self, k):\n",
    "        self.index = None\n",
    "        self.y = None\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.index = faiss.IndexFlatL2(X.shape[1])\n",
    "        self.index.add(X.astype(np.float32))\n",
    "        self.y = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        distances, indices = self.index.search(X.astype(np.float32), k=self.k)\n",
    "        votes = self.y[indices]\n",
    "        predictions = np.array([np.argmax(np.bincount(x)) for x in votes.astype(np.int64)])\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285f8d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array([[1,0]])\n",
    "train_labels = np.array([0])\n",
    "\n",
    "test = np.array([[0,0]])\n",
    "\n",
    "knn = FaissKNeighbors(k=1)\n",
    "\n",
    "knn.fit(train, train_labels)\n",
    "label_predicted = knn.predict(test)\n",
    "print(label_predicted)\n",
    "\n",
    "new_data = np.array([[-0.5,0]])\n",
    "new_label = np.array([1])\n",
    "\n",
    "knn.fit(new_data, new_label)\n",
    "label_predicted = knn.predict(test)\n",
    "print(label_predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

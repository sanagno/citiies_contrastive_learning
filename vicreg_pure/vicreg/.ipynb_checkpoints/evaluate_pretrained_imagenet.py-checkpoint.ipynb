{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832e076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import signal\n",
    "import sys\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "import resnet\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "\n",
    "import glob\n",
    "from geopy.geocoders import Nominatim\n",
    "import re\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import math\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True   #OTHERWISE TRUNCATED IMAGE FILE ERROR SOMEWHERE IN ENUMERATE(DATALOADER)!!!!\n",
    "\n",
    "import resnet\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8291e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.data_dir = '/local/home/bsoyuer/vicreg_pure/vicreg/ImageNet/ILSVRC/Data/CLS-LOC'\n",
    "        self.train_percent = 1\n",
    "        #self.pretrained = './exp/resnet18.pth'\n",
    "        self.exp_dir = 'exp'\n",
    "        self.print_freq = 100\n",
    "        self.arch = 'resnet18'\n",
    "        self.epochs = 1\n",
    "        self.batch_size = 216\n",
    "        self.lr_backbone = 0.03\n",
    "        self.lr_head = 0.08\n",
    "        self.weight_decay = 0.0\n",
    "        self.weights = 'finetune'\n",
    "        self.workers = 10\n",
    "        self.rank = 0\n",
    "        self.dist_url = f\"tcp://localhost:{random.randrange(49152, 65535)}\"\n",
    "        self.world_size = 1\n",
    "        self.train_files = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b12e26b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4f87ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "425ac1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_worker(gpu, args):\n",
    "\n",
    "    torch.cuda.set_device(gpu)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    #backbone, embedding = resnet.__dict__[args.arch](zero_init_residual=True)\n",
    "    #state_dict = torch.load(args.pretrained, map_location=\"cpu\")\n",
    "    #if \"model\" in state_dict:\n",
    "        #state_dict = state_dict[\"model\"]\n",
    "        #state_dict = {\n",
    "            #key.replace(\"module.backbone.\", \"\"): value\n",
    "            #for (key, value) in state_dict.items()\n",
    "        #}\n",
    "    #backbone.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "    backbone, embedding = torch.hub.load('facebookresearch/vicreg:main', 'resnet50'), 2048\n",
    "\n",
    "    head = nn.Linear(embedding, 1000)                            #CHANGE ACCORDING TO NUMBER OF CLASSES!!!!!\n",
    "    head.weight.data.normal_(mean=0.0, std=0.01)\n",
    "    head.bias.data.zero_()\n",
    "    model = nn.Sequential(backbone, head)\n",
    "    model.cuda(gpu)\n",
    "\n",
    "    if args.weights == \"freeze\":\n",
    "        backbone.requires_grad_(False)\n",
    "        head.requires_grad_(True)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "\n",
    "    param_groups = [dict(params=head.parameters(), lr=args.lr_head)]\n",
    "    \n",
    "    if args.weights == \"finetune\":\n",
    "        param_groups.append(dict(params=backbone.parameters(), lr=args.lr_backbone))\n",
    "        \n",
    "    optimizer = optim.SGD(param_groups, 0, momentum=0.9, weight_decay=args.weight_decay)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs)\n",
    "\n",
    "    \n",
    "    start_epoch = 0\n",
    "    best_acc = argparse.Namespace(top1=0, top5=0)\n",
    "\n",
    "    # Data loading code\n",
    "    traindir = args.data_dir + '/' + \"train\"\n",
    "    valdir = args.data_dir + '/' + \"val\"\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        traindir,\n",
    "        transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        valdir,\n",
    "        transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    if args.train_percent in {1, 10}:\n",
    "        train_dataset.samples = []\n",
    "        for fname in args.train_files:\n",
    "            fname = fname.decode().strip()\n",
    "            cls = fname.split(\"_\")[0]\n",
    "            train_dataset.samples.append(\n",
    "                (traindir / cls / fname, train_dataset.class_to_idx[cls])\n",
    "            )\n",
    "\n",
    "    #train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "    kwargs = dict(\n",
    "        batch_size=args.batch_size // args.world_size,\n",
    "        num_workers=args.workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, shuffle = True, **kwargs\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, shuffle= True, **kwargs)\n",
    "\n",
    "    start_time = time.time()\n",
    "    #WEIGHT FINETUNING/TRAINIG\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    checkpoints = 30\n",
    "    n_total_steps = len(train_loader)\n",
    "    \n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        # TRAIN\n",
    "        \n",
    "        if args.weights == \"finetune\":\n",
    "            model.train()\n",
    "        elif args.weights == \"freeze\":\n",
    "            model.eval()\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "        for step, (images, target) in enumerate(\n",
    "            train_loader, start=epoch * len(train_loader)\n",
    "        ):\n",
    "            \n",
    "            output = model(images.cuda(gpu, non_blocking=True))\n",
    "            loss = criterion(output, target.cuda(gpu, non_blocking=True))\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (step+1) % checkpoints == 0:\n",
    "            \n",
    "                print (f'Epoch [{epoch+1}/{args.epochs}], Step [{step+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "                print('training_loss', running_loss/checkpoints, epoch * n_total_steps + step)\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # EVALUATE\n",
    "        \n",
    "        model.eval()\n",
    "        if args.rank == 0:\n",
    "            top1 = AverageMeter(\"Acc@1\")\n",
    "            top5 = AverageMeter(\"Acc@5\")\n",
    "            with torch.no_grad():\n",
    "                for images, target in val_loader:\n",
    "                    \n",
    "                    images = images.view(-1, 3, 224, 224)    \n",
    "                    target = target.flatten()\n",
    "                    target = target.type(torch.LongTensor)\n",
    "            \n",
    "                    output = model(images.cuda(gpu, non_blocking=True))\n",
    "                    acc1, acc5 = accuracy(\n",
    "                        output, target.cuda(gpu, non_blocking=True), topk=(1, 5)\n",
    "                    )\n",
    "                    top1.update(acc1[0].item(), images.size(0))\n",
    "                    top5.update(acc5[0].item(), images.size(0))\n",
    "            best_acc.top1 = max(best_acc.top1, top1.avg)\n",
    "            best_acc.top5 = max(best_acc.top5, top5.avg)\n",
    "            print('best_acc.top1', best_acc.top1)\n",
    "            print('best_acc.top5', best_acc.top5)\n",
    "            \n",
    "        scheduler.step()\n",
    "        \n",
    "\n",
    "def handle_sigusr1(signum, frame):\n",
    "    os.system(f'scontrol requeue {os.getenv(\"SLURM_JOB_ID\")}')\n",
    "    exit()\n",
    "\n",
    "\n",
    "def handle_sigterm(signum, frame):\n",
    "    pass\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=\":f\"):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = \"{name} {val\" + self.fmt + \"} ({avg\" + self.fmt + \"})\"\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd818159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /local/home/bsoyuer/.cache/torch/hub/facebookresearch_vicreg_main\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda:2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mmain_worker\u001b[0;34m(gpu, args)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mtrain_percent \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m}:\n\u001b[1;32m     73\u001b[0m     train_dataset\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39mtrain_files:\n\u001b[1;32m     75\u001b[0m         fname \u001b[38;5;241m=\u001b[39m fname\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m fname\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "main_worker('cuda:2', args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9effb26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34444cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from geopy.geocoders import Nominatim\n",
    "import re\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sklearn\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import math\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb4d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import signal\n",
    "import sys\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import resnet\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "\n",
    "import glob\n",
    "from geopy.geocoders import Nominatim\n",
    "import re\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import math\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True   #OTHERWISE TRUNCATED IMAGE FILE ERROR SOMEWHERE IN ENUMERATE(DATALOADER)!!!!\n",
    "\n",
    "import resnet\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from munkres import Munkres\n",
    "\n",
    "import augmentations as aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4290e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "077e6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SN7Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, transform=None, train=True):\n",
    "        \n",
    "        if train == True:\n",
    "            self.img_ids_labels = pd.read_csv(\"../../ids_and_labels_train_repeated.csv\", header = None) \n",
    "        else:\n",
    "            self.img_ids_labels = pd.read_csv(\"../../ids_and_labels_val_repeated.csv\", header = None)\n",
    "            \n",
    "        self.img_dir = '/local/home/stuff/datasets/Challenge_7/train'\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #print(self.img_ids_labels.iloc[idx, 0])\n",
    "        image_id, patch_id = self.img_ids_labels.iloc[idx, 0].split(\"!\")[1],self.img_ids_labels.iloc[idx, 0].split(\"!\")[0]\n",
    "        pattern = \"mosaic_(.*?).tif\"\n",
    "        location_id = re.search(pattern, image_id).group(1)\n",
    "        #print(image_id)\n",
    "        #print(location_id)\n",
    "        img_path = os.path.join(self.img_dir, location_id, 'images', image_id )\n",
    "        image = torchvision.transforms.ToTensor()(Image.open(img_path))[0:3,:,:]  #TAKE RGB CHANNELS ONLY FOR RESNET COMPATIBILITY!!!\n",
    "        \n",
    "        image_padded = torch.nn.functional.pad(image, pad=(0, 1024 - image.shape[2], 0, 1024 - image.shape[1]))\n",
    "        patches = image_padded.unfold(1, 256, 256).unfold(2, 256, 256)\n",
    "        patches = patches.reshape(3, -1, 256, 256)\n",
    "        patches = patches.permute(1,0,2,3)\n",
    "        \n",
    "        image = patches[int(patch_id)]\n",
    "        \n",
    "        label = torch.from_numpy(np.asarray(self.img_ids_labels.iloc[idx, 3])).type(torch.LongTensor)\n",
    "        \n",
    "        #patches = patches.view(-1, 3, 256, 256)\n",
    "        #print(patches.shape)\n",
    "        #label = label.flatten()\n",
    "        #label = label.type(torch.LongTensor)\n",
    "        \n",
    "        \n",
    "        image = self.transform(image)\n",
    "                \n",
    "            \n",
    "        #if self.target_transform:\n",
    "            #label = self.target_transform(label)\n",
    "            \n",
    "        \n",
    "        return image, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.img_ids_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee23f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform = transforms.Compose([ transforms.Resize(224), torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "seen_transforms = transforms.Compose(\n",
    "            [   \n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                #transforms.Resize(224),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "#seen_transforms = aug.TrainTransform()\n",
    "\n",
    "unseen_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.CenterCrop(224),\n",
    "                #transforms.Resize(224),\n",
    "                normalize,\n",
    "            ])\n",
    "\n",
    "#unseen_transforms = seen_transforms\n",
    "                \n",
    "test_seen_dataset = SN7Dataset(train=True, transform = seen_transforms)\n",
    "test_unseen_dataset = SN7Dataset(train=False, transform = unseen_transforms)\n",
    "\n",
    "test_seen_loader = DataLoader(dataset=test_seen_dataset, batch_size = batch_size, shuffle = False)\n",
    "test_unseen_loader = DataLoader(dataset=test_unseen_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ba3e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12268863488, 12806062080)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.current_device()\n",
    "torch.cuda.set_device(0)\n",
    "print(torch.cuda.mem_get_info(torch.cuda.current_device()))\n",
    "device = torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5226e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JUST TRY LOADING MODEL LIKE THIS\n",
    "#backbone, embedding = resnet.__dict__['resnet18'](zero_init_residual=True)\n",
    "#backbone.load_state_dict(torch.load('exp/resnet18_2.pth'))\n",
    "#backbone.to(device)\n",
    "#backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fba5a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone, embedding = resnet.__dict__['resnet18'](zero_init_residual=True)\n",
    "state_dict = torch.load('exp/resnet18_new_4096_200.pth', map_location=\"cpu\")\n",
    "if \"model\" in state_dict:\n",
    "    state_dict = state_dict[\"model\"]\n",
    "    state_dict = {key.replace(\"module.backbone.\", \"\"): value for (key, value) in state_dict.items()}\n",
    "backbone.load_state_dict(state_dict, strict=False)\n",
    "backbone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7052870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding)\n",
    "backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f1c147a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n"
     ]
    }
   ],
   "source": [
    "labels_list = []\n",
    "embeddings_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_seen_loader):\n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "        #print(inputs[1].shape)\n",
    "        embedding = backbone(inputs.to(device))\n",
    "        embeddings_list.append(embedding)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d799060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.97498846 1.84979022 0.91738659 ... 0.40757221 0.87842232 0.51643515]\n",
      " [1.14290035 1.65228736 0.35764748 ... 0.08040975 0.88332146 0.29768485]\n",
      " [0.99130917 1.17466402 0.39766425 ... 0.80379564 0.84534967 0.57678294]\n",
      " ...\n",
      " [1.26092637 1.37287033 0.68628722 ... 0.72385156 1.0004096  0.36691386]\n",
      " [0.51475954 1.33714521 0.26919994 ... 4.22808027 0.75758094 0.43955961]\n",
      " [1.51260507 1.1132704  0.11451543 ... 0.03118141 0.74916887 0.27015281]]\n",
      "[17. 17. 17. ... 13. 13. 13.]\n"
     ]
    }
   ],
   "source": [
    "embeddings_seen_arr = np.zeros((len(test_seen_loader), 512))\n",
    "counter = 0\n",
    "for embedding in embeddings_list:\n",
    "    embeddings_seen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "#embeddings_unseen_arr = torch.tensor(embeddings_unseen_list)\n",
    "#labels_unseen_arr = np.array(labels_unseen_list)\n",
    "\n",
    "print(embeddings_seen_arr)\n",
    "labels_seen_arr = np.zeros(len(test_seen_loader))\n",
    "counter = 0\n",
    "for i in labels_list:\n",
    "    labels_seen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(labels_seen_arr)\n",
    "\n",
    "#np.savetxt(\"seen_embeddings.csv\", embeddings_seen_arr, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea68cfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n"
     ]
    }
   ],
   "source": [
    "labels_unseen_list = []\n",
    "embeddings_unseen_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_unseen_loader):\n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "        embedding = backbone(inputs.to(device))\n",
    "        embeddings_unseen_list.append(embedding)\n",
    "        labels_unseen_list.append(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a6c59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_unseen_arr = np.zeros((len(test_unseen_loader), 512))\n",
    "counter = 0\n",
    "for embedding in embeddings_unseen_list:\n",
    "    embeddings_unseen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "#embeddings_unseen_arr = torch.tensor(embeddings_unseen_list)\n",
    "#labels_unseen_arr = np.array(labels_unseen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "263a5862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.03479409 1.30913615 0.74683183 ... 1.06208062 0.87807089 0.20573866]\n",
      " [0.45377734 1.48064435 2.0597415  ... 0.86971951 1.31872725 0.44348174]\n",
      " [0.04158786 1.28981805 1.01655889 ... 0.0245442  1.05954838 0.50004286]\n",
      " ...\n",
      " [0.17008395 1.81979942 0.53541595 ... 0.         0.91526169 0.37115255]\n",
      " [0.51746237 1.30284655 0.6865055  ... 0.         0.93480986 0.11341633]\n",
      " [1.06354272 1.3975687  0.7570402  ... 0.33694291 1.06167209 0.42656836]]\n",
      "[30. 30. 30. ... 17. 17. 17.]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_unseen_arr)\n",
    "labels_unseen_arr = np.zeros(len(test_unseen_loader))\n",
    "counter = 0\n",
    "for i in labels_unseen_list:\n",
    "    labels_unseen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(labels_unseen_arr)\n",
    "\n",
    "#np.savetxt(\"unseen_embeddings.csv\", embeddings_unseen_arr, delimiter=\",\", fmt='%s')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48b4c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(embeddings_seen_arr.shape[0]):\n",
    "    if len(np.unique(embeddings_seen_arr[i,:]))==1:\n",
    "        print('yes')\n",
    "for i in range(embeddings_unseen_arr.shape[0]):\n",
    "    if len(np.unique(embeddings_unseen_arr[i,:]))==1:\n",
    "        print('yes_unseen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4645602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13. 18. 23. 28. 29. 30.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#JUST TRY DELETE LATER\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embeddings_unseen_arr_trial = embeddings_unseen_arr[0:120,:]\n",
    "labels_unseen_arr_trial = labels_unseen_arr[0:120]\n",
    "\n",
    "#pca = PCA(n_components=2)\n",
    "#pca.fit(embeddings_unseen_arr)\n",
    "#print(pca.explained_variance_ratio_)\n",
    "\n",
    "#embeddings_reduced = pca.transform(embeddings_unseen_arr)\n",
    "#print(embeddings_reduced)\n",
    "\n",
    "u_labels = np.unique(labels_unseen_arr_trial)\n",
    "print(u_labels)\n",
    "\n",
    "embeddings_reduced = TSNE(n_components=2, learning_rate='auto',init='random', perplexity = 10.0).fit_transform(embeddings_unseen_arr_trial)\n",
    "\n",
    "for i in u_labels:\n",
    "    \n",
    "    plt.scatter(embeddings_reduced[labels_unseen_arr_trial == i , 0] , embeddings_reduced[labels_unseen_arr_trial == i , 1] , label = i)\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9146f3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9819915254237288\n",
      "Accuracy: 0.97704802259887\n",
      "Accuracy: 0.97704802259887\n",
      "Accuracy: 0.9721045197740112\n",
      "Accuracy: 0.9525070621468926\n",
      "Accuracy: 0.920021186440678\n",
      "Accuracy: 0.878707627118644\n",
      "Accuracy: 0.8245056497175142\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbours = [1, 3, 5, 10, 20, 30, 40, 50]\n",
    "\n",
    "for k in n_neighbours:\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(embeddings_seen_arr, labels_seen_arr)\n",
    "    labels_predicted = knn.predict(embeddings_unseen_arr)\n",
    "\n",
    "    #print('Accuracy' + str(k) + ':', np.sum(labels_unseen_arr == labels_predicted)/len(labels_unseen_arr))\n",
    "    print('Accuracy:', knn.score(embeddings_unseen_arr, labels_unseen_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4314106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_preds(cluster_assignments, y_true, n_clusters):\n",
    "    '''\n",
    "    Computes the predicted labels, where label assignments now\n",
    "    correspond to the actual labels in y_true (as estimated by Munkres)\n",
    "\n",
    "    cluster_assignments:    array of labels, outputted by kmeans\n",
    "    y_true:                 true labels\n",
    "    n_clusters:             number of clusters in the dataset\n",
    "\n",
    "    returns:    a tuple containing the accuracy and confusion matrix,\n",
    "                in that order\n",
    "    '''\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_true, cluster_assignments, labels=None)\n",
    "    # compute accuracy based on optimal 1:1 assignment of clusters to labels\n",
    "    cost_matrix = calculate_cost_matrix(confusion_matrix, n_clusters)\n",
    "    indices = Munkres().compute(cost_matrix)\n",
    "    kmeans_to_true_cluster_labels = get_cluster_labels_from_indices(indices)\n",
    "    y_pred = kmeans_to_true_cluster_labels[cluster_assignments]\n",
    "    return y_pred, confusion_matrix \n",
    "\n",
    "def calculate_cost_matrix(C, n_clusters):\n",
    "    cost_matrix = np.zeros((n_clusters, n_clusters))\n",
    "\n",
    "    # cost_matrix[i,j] will be the cost of assigning cluster i to label j\n",
    "    for j in range(n_clusters):\n",
    "        s = np.sum(C[:,j]) # number of examples in cluster i\n",
    "        for i in range(n_clusters):\n",
    "            t = C[i,j]\n",
    "            cost_matrix[j,i] = s-t\n",
    "    return cost_matrix\n",
    "\n",
    "def get_cluster_labels_from_indices(indices):\n",
    "    n_clusters = len(indices)\n",
    "    clusterLabels = np.zeros(n_clusters)\n",
    "    for i in range(n_clusters):\n",
    "        clusterLabels[i] = indices[i][1]\n",
    "    return clusterLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cd153ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Afteer Hungarian Assignment: 0.1683709449929478\n",
      "(22688,)\n",
      "Accuracy Afteer Hungarian Assignment: 0.14919781382228492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "#labels_predicted = AgglomerativeClustering(n_clusters = 20).fit_predict(embeddings_unseen_arr)\n",
    "\n",
    "#truth = labels_unseen_arr\n",
    "#pred = labels_predicted\n",
    "#print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )\n",
    "\n",
    "#print(sklearn.metrics.rand_score(labels_unseen_arr, labels_predicted))\n",
    "\n",
    "whole_test_set = np.concatenate((embeddings_seen_arr,embeddings_unseen_arr), axis=0)\n",
    "whole_labels = np.concatenate((labels_seen_arr, labels_unseen_arr))\n",
    "\n",
    "labels_predicted = AgglomerativeClustering(n_clusters = 31).fit_predict(whole_test_set)\n",
    "\n",
    "truth = whole_labels\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 31)[0] == truth )/len(truth) )\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#kmeans = KMeans(n_clusters=20, random_state=36).fit(embeddings_seen_arr)\n",
    "#labels_predicted = kmeans.predict(embeddings_unseen_arr)\n",
    "#print(labels_predicted.shape)\n",
    "\n",
    "#truth = labels_unseen_arr\n",
    "#pred = labels_predicted\n",
    "#print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )\n",
    "\n",
    "kmeans = KMeans(n_clusters=31, random_state=36).fit(whole_test_set)\n",
    "labels_predicted = kmeans.predict(whole_test_set)\n",
    "print(whole_labels.shape)\n",
    "\n",
    "truth = whole_labels\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 31)[0] == truth )/len(truth) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b70a10f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "\n",
    "seen_transforms = transforms.Compose(\n",
    "            [   \n",
    "                #transforms.RandomResizedCrop(224),\n",
    "                #transforms.RandomHorizontalFlip(),\n",
    "                transforms.Resize(224),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "unseen_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.CenterCrop(224),\n",
    "                #transforms.Resize(224),\n",
    "                normalize,\n",
    "            ])\n",
    "\n",
    "test_seen_dataset = SN7Dataset(train=True, transform = seen_transforms)\n",
    "test_unseen_dataset = SN7Dataset(train=False, transform = unseen_transforms)\n",
    "\n",
    "test_seen_loader = DataLoader(dataset=test_seen_dataset, batch_size = batch_size, shuffle = False)\n",
    "test_unseen_loader = DataLoader(dataset=test_unseen_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de8edc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####FOR SUPERVSED MODEL!!!!\n",
    "\n",
    "backbone, embedding = resnet.__dict__['resnet18'](zero_init_residual=True)\n",
    "state_dict = torch.load('../../Supervised_Model.pth', map_location=\"cpu\")\n",
    "if \"model\" in state_dict:\n",
    "    state_dict = state_dict[\"model\"]\n",
    "    state_dict = {key.replace(\"module.backbone.\", \"\"): value for (key, value) in state_dict.items()}\n",
    "backbone.load_state_dict(state_dict, strict=False)\n",
    "backbone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e55c550d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding)\n",
    "backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "297bb401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n"
     ]
    }
   ],
   "source": [
    "labels_list = []\n",
    "embeddings_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_seen_loader):\n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "        embedding = backbone(inputs.to(device))\n",
    "        embeddings_list.append(embedding)\n",
    "        labels_list.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c94851cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12317052 1.43663383 0.28230196 ... 1.80706692 0.14865744 0.87916923]\n",
      " [0.13682488 0.93744624 0.33663651 ... 3.37823725 0.28292724 1.25425076]\n",
      " [0.04704413 0.9674179  0.08414672 ... 3.42556    0.2273407  1.15283716]\n",
      " ...\n",
      " [0.02487592 0.32121474 0.15861818 ... 1.61708641 0.18078965 0.82726234]\n",
      " [0.07081281 0.41750196 0.31754136 ... 1.43292952 0.10991853 0.5478828 ]\n",
      " [0.03780255 0.66814345 0.69805986 ... 1.66296041 0.34856492 0.35852769]]\n",
      "[17. 17. 17. ... 13. 13. 13.]\n"
     ]
    }
   ],
   "source": [
    "embeddings_seen_arr = np.zeros((len(test_seen_loader), 512))\n",
    "counter = 0\n",
    "for embedding in embeddings_list:\n",
    "    embeddings_seen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "#embeddings_unseen_arr = torch.tensor(embeddings_unseen_list)\n",
    "#labels_unseen_arr = np.array(labels_unseen_list)\n",
    "\n",
    "print(embeddings_seen_arr)\n",
    "labels_seen_arr = np.zeros(len(test_seen_loader))\n",
    "counter = 0\n",
    "for i in labels_list:\n",
    "    labels_seen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(labels_seen_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83c131d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n"
     ]
    }
   ],
   "source": [
    "labels_unseen_list = []\n",
    "embeddings_unseen_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_unseen_loader):\n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "        embedding = backbone(inputs.to(device))\n",
    "        embeddings_unseen_list.append(embedding)\n",
    "        labels_unseen_list.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b3de7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04541048 0.09411345 0.13167404 ... 1.29203272 0.02067739 1.65651369]\n",
      " [0.12516052 0.08320393 0.23238413 ... 1.51393843 0.0180764  1.39519823]\n",
      " [0.12817952 0.15544313 0.15145196 ... 1.0467217  0.04106529 1.34857178]\n",
      " ...\n",
      " [0.09706418 1.06956339 0.48926908 ... 2.52267575 0.00343556 2.48549795]\n",
      " [0.43610546 1.66794229 0.87992054 ... 1.33218634 0.23914057 1.55275536]\n",
      " [0.50597411 1.05220401 0.52905434 ... 1.76076078 0.03208228 2.0385375 ]]\n",
      "[30. 30. 30. ... 17. 17. 17.]\n"
     ]
    }
   ],
   "source": [
    "embeddings_unseen_arr = np.zeros((len(test_unseen_loader), 512))\n",
    "counter = 0\n",
    "for embedding in embeddings_unseen_list:\n",
    "    embeddings_unseen_arr[counter,:] = embedding.cpu().detach().numpy()\n",
    "    counter += 1\n",
    "#embeddings_unseen_arr = torch.tensor(embeddings_unseen_list)\n",
    "#labels_unseen_arr = np.array(labels_unseen_list)\n",
    "\n",
    "print(embeddings_unseen_arr)\n",
    "labels_unseen_arr = np.zeros(len(test_unseen_loader))\n",
    "counter = 0\n",
    "for i in labels_unseen_list:\n",
    "    labels_unseen_arr[counter] = i.detach().numpy()\n",
    "    counter += 1\n",
    "print(labels_unseen_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a74e58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8320974576271186\n",
      "Accuracy: 0.8319209039548022\n",
      "Accuracy: 0.834569209039548\n",
      "Accuracy: 0.8315677966101694\n",
      "Accuracy: 0.8260946327683616\n",
      "Accuracy: 0.8206214689265536\n",
      "Accuracy: 0.8163841807909604\n",
      "Accuracy: 0.8080861581920904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbours = [1, 3, 5, 10, 20, 30, 40, 50]\n",
    "\n",
    "for k in n_neighbours:\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(embeddings_seen_arr, labels_seen_arr)\n",
    "    labels_predicted = knn.predict(embeddings_unseen_arr)\n",
    "\n",
    "    #print('Accuracy' + str(k) + ':', np.sum(labels_unseen_arr == labels_predicted)/len(labels_unseen_arr))\n",
    "    print('Accuracy:', knn.score(embeddings_unseen_arr, labels_unseen_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d051c32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Afteer Hungarian Assignment: 0.5872267277856136\n",
      "(22688,)\n",
      "Accuracy Afteer Hungarian Assignment: 0.5347760930888575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "#labels_predicted = AgglomerativeClustering(n_clusters = 20).fit_predict(embeddings_unseen_arr)\n",
    "\n",
    "#truth = labels_unseen_arr\n",
    "#pred = labels_predicted\n",
    "#print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )\n",
    "\n",
    "#print(sklearn.metrics.rand_score(labels_unseen_arr, labels_predicted))\n",
    "\n",
    "whole_test_set = np.concatenate((embeddings_seen_arr,embeddings_unseen_arr), axis=0)\n",
    "whole_labels = np.concatenate((labels_seen_arr, labels_unseen_arr))\n",
    "\n",
    "labels_predicted = AgglomerativeClustering(n_clusters = 31).fit_predict(whole_test_set)\n",
    "\n",
    "truth = whole_labels\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 31)[0] == truth )/len(truth) )\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#kmeans = KMeans(n_clusters=20, random_state=36).fit(embeddings_seen_arr)\n",
    "#labels_predicted = kmeans.predict(embeddings_unseen_arr)\n",
    "#print(labels_predicted.shape)\n",
    "\n",
    "#truth = labels_unseen_arr\n",
    "#pred = labels_predicted\n",
    "#print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 20)[0] == truth )/len(truth) )\n",
    "\n",
    "kmeans = KMeans(n_clusters=31, random_state=36).fit(whole_test_set)\n",
    "labels_predicted = kmeans.predict(whole_test_set)\n",
    "print(whole_labels.shape)\n",
    "\n",
    "truth = whole_labels\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 31)[0] == truth )/len(truth) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c213cf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Afteer Hungarian Assignment: 0.5238347457627118\n",
      "0.9149049958547455\n",
      "(5664,)\n",
      "Accuracy Afteer Hungarian Assignment: 0.4980579096045198\n",
      "0.9128087990135192\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "labels_predicted = AgglomerativeClustering(n_clusters = 31).fit_predict(embeddings_unseen_arr)\n",
    "\n",
    "truth = labels_unseen_arr\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 31)[0] == truth )/len(truth) )\n",
    "\n",
    "print(sklearn.metrics.rand_score(labels_unseen_arr, labels_predicted))\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=31, random_state=36).fit(embeddings_seen_arr)\n",
    "labels_predicted = kmeans.predict(embeddings_unseen_arr)\n",
    "print(labels_predicted.shape)\n",
    "\n",
    "truth = labels_unseen_arr\n",
    "pred = labels_predicted\n",
    "print('Accuracy Afteer Hungarian Assignment:',np.sum( get_y_preds(pred, truth, 31)[0] == truth )/len(truth) )\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.rand_score(labels_unseen_arr, labels_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f01ae5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20 24 24 ... 19  1  1]\n",
      "0.9128087990135192\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=31, random_state=36).fit(embeddings_seen_arr)\n",
    "labels_predicted = kmeans.predict(embeddings_unseen_arr)\n",
    "print(labels_predicted)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.rand_score(labels_unseen_arr, labels_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "98d54fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17024, 512)\n",
      "(5664, 512)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_seen_arr.shape)\n",
    "print(embeddings_unseen_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8382c4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
